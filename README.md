<a href="https://mc.yandex.ru/pixel/8711235002931986822?rnd=%aw_random%">
    <img src="https://mc.yandex.ru/pixel/8711235002931986822?rnd=%aw_random%" />        
  </a>&nbsp;&nbsp;
<a href="https://mc.yandex.ru/watch/92801430">
    <img src="https://mc.yandex.ru/watch/92801430" />        
  </a>&nbsp;&nbsp;

Если вам интересно мое резюме: https://github.com/DEBAGanov

# SQL
- [Sql](#sql)
  - [Что вы понимаете в распределенной транзакции?](#Что_вы_понимаете_в_распределенной_транзакции)
  - [Расскажите про ACID?](#Расскажите_про_ACID)
  - [Что такое идемпотенция и где она используется?](#Что_такое_идемпотенция_и_где_она_используется)
  - [Что такое ограниченный контекст?](#Что_такое_ограниченный_контекст)
  - [Что такое ORM?](#Что_такое_ORM)
  - [Что такое JPA?](#Что_такое_JPA)
  - [Различия JPA JDBC и Hibernate?](#Различия_JPA_JDBC_и_Hibernate)
  - [Что такое JPQL и HQL?](#Что_такое_JPQL_и_HQL)
  - [Что такое Criteria API?](#Что_такое_Criteria_API)
  - [Ккакие преимущества и недостатки Hibernate?](#Ккакие_преимущества_и_недостатки_Hibernate)
  - [Что делает DriverManager DataSource Connection?](#Что_делает_DriverManager_DataSource_Connection)
  - [В чем отличие между Statement PreparedStatement CallableStatement?](#В_чем_отличие_между_Statement_PreparedStatement_CallableStatement)
  - [Что делает ResultSet ResultSetMetaData DatabaseMetaData?](#Что_делает_ResultSet_ResultSetMetaData_DatabaseMetaData)
  - [Какие уровни изоляции транзакций поддерживаются в JDBC?](#Какие_уровни_изоляции_транзакций_поддерживаются_в_JDBC)
  - [Какие существуют блокировки в JDBC?](#Какие_существуют_блокировки_в_JDBC)
  - [Чем отличается пессимистичная и оптимистичная блокировка?](#Чем_отличается_пессимистичная_и_оптимистичная_блокировка)
  - [Как избежать deadlock в JDBC?](#Как_избежать_deadlock_in_JDBC)
  - [Чем отличается Statement от PreparedStatement?](#Чем_отличается_Statement_от_PreparedStatement)
  - [Как осуществляется запрос к базе данных и обработка результатов?](#Как_осуществляется_запрос_к_базе_данных_и_обработка_результатов)
  - [Как вызвать хранимую процедуру?](#Как_вызвать_хранимую_процедуру)
  - [Как оптимизировать вызов хранимых процедур?](#Как_оптимизировать_вызов_хранимых_процедур)
  - [Чем вызов процедуры отличается от выполнения SQL?](#Чем_вызов_процедуры_отличается_от_выполнения_SQL)
  - [Что такое Entity?](#Что_такое_Entity)
  - [Почему Entity не должен быть final?](#Почему_Entity_не_должен_быть_final)
  - [Как избежать N+1 проблемы в Entity?](#Как_избежать_N_1_проблемы_в_Entity)
  - [Может ли абстрактный класс быть Entity?](#Может_ли_абстрактный_класс_быть_Entity)
  - [Что такое POJO-класс?](#Что_такое_POJO_класс)
  - [Что такое Mapped Superclass?](#Что_такое_Mapped_Superclass)
  - [Для чего необходим EntityManagerFactory и EntityManager?](#Для_чего_необходим_EntityManagerFactory_и_EntityManager)
  - [Почему EntityManager не thread-safe?](#Почему_EntityManager_не_thread_safe)
  - [Как работает кэш первого уровня в EntityManager?](#Как_работает_кэш_первого_уровня_в_EntityManager)
  - [Зачем нужен merge(), если есть persist()?](#Зачем_нужен_merge_если_есть_persist)
  - [Какие методы операций над Entity?](#Какие_методы_операций_над_Entity)
  - [Какие методы получение данных?](#Какие_методы_получение_данных)
  - [Для чего необходим EntityTransaction?](#Для_чего_необходим_EntityTransaction)
  - [Как работает setRollbackOnly?](#Как_работает_setRollbackOnly)
  - [Какие методы есть у EntityTransaction?](#Какие_методы_есть_у_EntityTransaction)
  - [Основные классы и интерфейсы Hibernate?](#Основные_классы_и_интерфейсы_Hibernate)
  - [Способы сконфигурировать Hibernate?](#Способы_сконфигурировать_Hibernate)
  - [Жизненный цикл Entity?](#Жизненный_цикл_Entity)
  - [Влияние операций EntityManager на Entity объекты различный жизненных циклов?](#Влияние_операций_EntityManager_на_Entity_объекты_различный_жизненных_циклов)
  - [Что делает аннотация @Access?](#Что_делает_аннотация_Access)
  - [Что делает аннотация @AssociacionOverride?](#Что_делает_аннотация_AssociacionOverride)
  - [Что делает аннотация @AttibuteOverride?](#Что_делает_аннотация_AttibuteOverride)
  - [Что делает аннотация @Basic?](#Что_делает_аннотация_Basic)
  - [Что делает аннотация @CollectionTable?](#Что_делает_аннотация_CollectionTable)
  - [Что делает аннотация @ColumnResult?](#Что_делает_аннотация_ColumnResult)
  - [Что делает аннотация @ConstructorResult?](#Что_делает_аннотация_ConstructorResult)
  - [Что делает аннотация @Convert и @Converter?](#Что_делает_аннотация_Convert_и_Converter)
  - [Что делает аннотация @DiscriminatorColumn и @DisccriminatorValue?](#Что_делает_аннотация_DiscriminatorColumn_и_DisccriminatorValue)
  - [Что делает аннотация @ElementCollection?](#Что_делает_аннотация_ElementCollection)
  - [Что делает аннотация @Embeddable и @Embedded и @EmbeddedId?](#Что_делает_аннотация_Embeddable_и_Embedded_и_EmbeddedId)
  - [Что делает аннотация @EntityListeners?](#Что_делает_аннотация_EntityListeners)
  - [Что делает аннотация @EntityResult?](#Что_делает_аннотация_EntityResult)
  - [Что делает аннотация @Enumerated?](#Что_делает_аннотация_Enumerated)
  - [Что делает аннотация @FieldResult?](#Что_делает_аннотация_FieldResult)
  - [Что делает аннотация @GeneratedValue?](#Что_делает_аннотация_GeneratedValue)
  - [Что делает аннотация @Index?](#Что_делает_аннотация_Index)
  - [Что делает аннотация @Inheritance?](#Что_делает_аннотация_Inheritance)
  - [Что делает аннотация @Lob?](#Что_делает_аннотация_Lob)
  - [Что делает аннотация @MapKey?](#Что_делает_аннотация_MapKey)
  - [Что делает аннотация @MapKeyColumn?](#Что_делает_аннотация_MapKeyColumn)
  - [Что делает аннотация @NamedQuery?](#Что_делает_аннотация_NamedQuery)
  - [Что делает аннотация @PersistenceContext?](#Что_делает_аннотация_PersistenceContext)
  - [Что делает аннотация @OrderColumn?](#Что_делает_аннотация_OrderColumn)
  - [Что делает аннотация @PostPersist?](#Что_делает_аннотация_PostPersist)
  - [Что делает аннотация @Any?](#Что_делает_аннотация_Any)
  - [Что делает аннотация @BatchSize?](#Что_делает_аннотация_BatchSize)
  - [Что делает аннотация @Fetch?](#Что_делает_аннотация_Fetch)
  - [Что делает аннотация @OptimisticLock?](#Что_делает_аннотация_OptimisticLock)
  - [Что делает аннотация @OptimisticLocking?](#Что_делает_аннотация_OptimisticLocking)
  - [Назовите некоторые важные интерфейсы Hibernate?](#Назовите_некоторые_важные_интерфейсы_Hibernate)
  - [Расскажите про первый уровень кеширования в Hibernate?](#Расскажите_про_первый_уровень_кеширования_в_Hibernate)
  - [Расскажите про второй уровень кеширования в Hibernate?](#Расскажите_про_второй_уровень_кеширования_в_Hibernate)
  - [Расскажите про Стратегия параллельного доступа к объектам?](#Расскажите_про_Стратегия_параллельного_доступа_к_объектам)
  - [Для чего нужна аннотация @Cache?](#Для_чего_нужна_аннотация_Cache)
  - [Для чего нужна аннотация @Cacheable?](#Для_чего_нужна_аннотация_Cacheable)
  - [Расскажите про Hibernate proxy (lazy load)?](#Расскажите_про_Hibernate_proxy_lazy_load)
  - [Расскажите про стратегии кеширования?](#Расскажите_про_стратегии_кеширования)
  - [Стратегии загрузки объектов в Hibernate?](#Стратегии_загрузки_объектов_в_Hibernate)
  - [Для чего нужна аннотация Basic?](#Для_чего_нужна_аннотация_Basic)
  - [Для чего нужна аннотация Access?](#Для_чего_нужна_аннотация_Access)
  - [Для чего нужны аннотации @Embedded и @Embeddable?](#Для_чего_нужны_аннотации_Embedded_и_Embeddable)
  - [Для чего нужны аннотации @OrderBy и @OrderColumn?](#Для_чего_нужны_аннотации_OrderBy_и_OrderColumn)
  - [Для чего нужны callback методы в JPA?](#Для_чего_нужны_callback_методы_в_JPA)
  - [Какие видов блокировок (lock) описаны в спецификации JPA?](#Какие_видов_блокировок_lock_описаны_в_спецификации_JPA)
  - [Как можно изменить настройки fetch стратегии любых атрибутов Entity?](#Как_можно_изменить_настройки_fetch_стратегии_любых_атрибутов_Entity)
  - [Что означает полиморфизм (polymorphism) в запросах JPQL?](#Что_означает_полиморфизм_polymorphism_в_запросах_JPQL)
  - [Что происходит с таблицами при изпользовании mappedBy?](#Что_происходит_с_таблицами_при_изпользовании_mappedBy)
  - [FetchType стратегии по-умолчанию?](#FetchType_стратегии_по_умолчанию)
  - [Как мапятся даты (до Java 8 и после)?](#Как_мапятся_даты_до_Java_8_и_после)
  - [Для чего необходим PersistenceContext?](#Для_чего_необходим_PersistenceContext)
  - [Что такое Entity graph?](#Что_такое_Entity_graph)
  - [Проблема n+1 select и как ее решить?](#Проблема_n_1_select_и_как_ее_решить)
  - [Как создать составной ключ?](#Как_создать_составной_ключ)
  - [ElementCollection - Как сохранять в БД коллекции базовых типов?](#ElementCollection_Как_сохранять_в_БД_коллекции_базовых_типов)
  - [Метод unWrap()?](#Метод_unWrap)
  - [Что такое UNION и UNION ALL?](#Что_такое_UNION_и_UNION_ALL)
  - [Что такое SUBQUERY?](#Что_такое_SUBQUERY)
  - [Что такое коррелирующий запрос?](#Что_такое_коррелирующий_запрос)
  - [Что такое нормализация?](#Что_такое_нормализация)
  - [Какие виды нормализации бывают в SQL?](#Какие_виды_нормализации_бывают_в_SQL)
  - [Что такое индекс и какие виды индексов существуют?](#Что_такое_индекс_и_какие_виды_индексов_существуют)
  - [Какой вид индекса использовать для какого типа запросов?](#Какой_вид_индекса_использовать_для_какого_типа_запросов)
  - [Как создать триггер в SQL?](#Как_создать_триггер_в_SQL)
  - [Что такое ограничения (constraints) и какие они бывают?](#Что_такое_ограничения_constraints_и_какие_они_бывают)
  - [Как создать таблицу с ограничениями?](#Как_создать_таблицу_с_ограничениями)
  - [Что такое хранимая процедура и как ее создать?](#Что_такое_хранимая_процедура_и_как_ее_создать)
  - [Что такое функция и как ее создать?](#Что_такое_функция_и_как_ее_создать)
  - [Как работать с датами в SQL?](#Как_работать_с_датами_в_POSTGRESQL)
  - [Что такое оператор CASE?](#Что_такое_оператор_CASE)
  - [Что такое оператор COALESCE?](#Что_такое_оператор_COALESCE)
  - [Что такое агрегатные функции и какие они бывают?](#Что_такое_агрегатные_функции_и_какие_они_бывают)
  - [Что такое инструкция TRUNCATE?](#Что_такое_инструкция_TRUNCATE)
  - [В чем разница между инструкцией DELETE и TRUNCATE?](#В_чем_разница_между_инструкцией_DELETE_и_TRUNCATE)
  - [Что такое ключевое слово OFFSET?](#Что_такое_ключевое_слово_OFFSET)
  - [Что такое GROUP_CONCAT?](#Что_такое_GROUP_CONCAT)
  - [Что такое аналитические функции?](#Что_такое_аналитические_функции)
  - [Какие аналитические функции поддерживает SQL?](#Какие_аналитические_функции_поддерживает_SQL)
  - [Как использовать операторы BETWEEN и IN в SQL?](#Как_использовать_операторы_BETWEEN_и_IN_в_SQL)
  - [Как работать с несколькими таблицами в одном запросе?](#Как_работать_с_несколькими_таблицами_в_одном_запросе)
  - [Как работать с динамическими запросами в SQL?](#Как_работать_с_динамическими_запросами_в_SQL)
  - [Какие виды ограничений можно использовать в SQL?](#Какие_виды_ограничений_можно_использовать_в_SQL)
  - [Как работать с индексами в SQL](#Как_работать_с_индексами_в_SQL)
  - [Что такое кластеризованный и некластеризованный индекс?](#Что_такое_кластеризованный_и_некластеризованный_индекс)
  - [Какие операторы логических связок (AND, OR, NOT) существуют в SQL?](#Какие_операторы_логических_связок_AND_OR_NOT_существуют_в_SQL)
  - [Что такое подзапросы и как они работают в SQL?](#Что_такое_подзапросы_и_как_они_работают_в_SQL)
  - [Какие виды функций агрегации существуют в SQL?](#Какие_виды_функций_агрегации_существуют_в_SQL)
  - [Как использовать операторы IN и NOT IN в SQL?](#Как_использовать_операторы_IN_и_NOT_IN_в_SQL)
  - [Что такое оконные функции и как они работают в SQL?](#Что_такое_оконные_функции_и_как_они_работают_в_SQL)
  - [Как использовать операторы GROUP BY и HAVING в SQL?](#Как_использовать_операторы_GROUP_BY_и_HAVING_в_SQL)
  - [Как использовать операторы ORDER BY и LIMIT в SQL?](#Как_использовать_операторы_ORDER_BY_и_LIMIT_в_SQL)
  - [Как создать индекс на одном или нескольких столбцах в SQL?](#Как_создать_индекс_на_одном_или_нескольких_столбцах_в_SQL)
  - [Что такое таблица соединения и как она используется в SQL?](#Что_такое_таблица_соединения_и_как_она_используется_в_SQL)
  - [Как использовать оператор UNION в SQL?](#Как_использовать_оператор_UNION_в_SQL)
  - [Как использовать операторы IN и EXISTS в SQL?](#Как_использовать_операторы_IN_и_EXISTS_в_SQL)
  - [Что такое операторы ALL и ANY в SQL?](#Что_такое_операторы_ALL_и_ANY_в_SQL)
  - [Как использовать операторы EXISTS и NOT EXISTS в SQL?](#Как_использовать_операторы_EXISTS_и_NOT_EXISTS_в_SQL)
  - [Как использовать операторы CASE и WHEN в SQL?](#Как_использовать_операторы_CASE_и_WHEN_в_SQL)
  - [Что такое RDBMS?](#Что_такое_RDBMS)
  - [Что такое COMMIT и ROLLBACK?](#Что_такое_COMMIT_и_ROLLBACK)
  - [Что такое процедура (stored procedure)?](#Что_такое_процедура_stored_procedure)
  - [Как создать процедуру в SQL?](#Как_создать_процедуру_в_SQL)
  - [Как вызвать процедуру в SQL?](#Как_вызвать_процедуру_в_SQL)
  - [Что такое функция (stored function) и как ее использовать?](#Что_такое_функция_stored_function_и_как_ее_использовать)
  - [Как создать функцию в SQL?](#Как_создать_функцию_в_SQL)
  - [Как использовать подзапрос (subquery) в SQL?](#Как_использовать_подзапрос_subquery_в_SQL)
  - [Что такое оператор HAVING и как его использовать?](#Что_такое_оператор_HAVING_и_как_его_использовать)
  - [Как использовать условные операторы (CASE, IF) в SQL?](#Как_использовать_условные_операторы_CASE_IF_в_SQL)
  - [Что такое триггер (trigger) и как его использовать?](#Что_такое_триггер_trigger_и_как_его_использовать)
  - [Как создать триггер в SQL?](#Как_создать_триггер_в_SQL)
  - [Что такое ORM и какие библиотеки ORM для Java вы знаете?](#Что_такое_ORM_и_какие_библиотеки_ORM_для_Java_вы_знаете)
  - [Как улучшить производительность SQL запросов?](#Как_улучшить_производительность_SQL_запросов)
  - [Как ускорить выполнение SQL запросов?](#Как_ускорить_выполнение_SQL_запросов)
  - [Что такое индексация в базах данных?](#Что_такое_индексация_в_базах_данных)
  - [Как узнать план выполнения запроса в базе данных?](#Как_узнать_план_выполнения_запроса_в_базе_данных)
  - [Что такое deadlock и как его избежать?](#Что_такое_deadlock_и_как_его_избежать)
  - [Что такое SQL injection и как его предотвратить?](#Что_такое_SQL_injection_и_как_его_предотвратить)
  - [Как сделать backup базы данных?](#Как_сделать_backup_базы_данных)
  - [Что такое log shipping?](#Что_такое_log_shipping)
  - [Что такое репликация базы данных?](#Что_такое_репликация_базы_данных)
  - [Что такое масштабирование базы данных?](#Что_такое_масштабирование_базы_данных)
  - [Что такое шардинг?](#Что_такое_шардинг) 
  - [Как настроить шардинг в базе данных?](#Как_настроить_шардинг_в_базе_данных)
  - [Какой подход лучше для шардинга?](#Какой_подход_лучше_для_шардинга) 
  - [Что такое партиционирование таблицы?](#Что_такое_партиционирование_таблицы) 
  - [Как настроить партиционирование таблицы?](#Как_настроить_партиционирование_таблицы) 
  - [Что такое отказоустойчивость базы данных?](#Что_такое_отказоустойчивость_базы_данных) 
  - [Как обеспечить отказоустойчивость базы данных?](#Как_обеспечить_отказоустойчивость_базы_данных)
  - [Что такое резервный сервер базы данных?](#Что_такое_резервный_сервер_базы_данных)
  - [Что такое кластер базы данных?](#Что_такое_кластер_базы_данных)
  - [Что такое миграции базы данных?](#Что_такое_миграции_базы_данных)
  - [Что такое архитектура базы данных?](#Что_такое_архитектура_базы_данных)
  - [Какие принципы SOLID применяются при разработке базы данных?](#Какие_принципы_SOLID_применяются_при_разработке_базы_данных)
  - [Что такое ER-модель?](#Что_такое_ER_модель)
  - [Что такое «временная таблица»? Для чего она используется?](#Что_такое_временная_таблица_Для_чего_она_используется)
  - [Что лучше использовать JOIN или подзапросы?](#Что_лучше_использовать_JOIN_или_подзапросы)
  - [Что делает оператор MERGE?](#Что_делает_оператор_MERGE)
  - [Что такое «курсор»?](#Что_такое_курсор)
  - [Какое назначение у операторов PIVOT и UNPIVOT в Transact-SQL?](#Какое_назначение_у_операторов_PIVOT_и_UNPIVOT_в_Transact_SQL)
  - [Расскажите об основных функциях ранжирования в Transact-SQL.](#Расскажите_об_основных_функциях_ранжирования_в_Transact_SQL)
  - [Для чего используются операторы INTERSECT, EXCEPT в Transact-SQL?](#Для_чего_используются_операторы_INTERSECT_EXCEPT_в_Transact_SQL)


## Что_вы_понимаете_в_распределенной_транзакции

Распределенная транзакция - это транзакция, которая включает в себя несколько отдельных операций, выполняемых на разных 
узлах или системах. Она обеспечивает атомарность, согласованность, изолированность и долговечность (ACID) для всех 
операций, выполняемых в рамках транзакции.

Для этого используют 2PC (но он блокирующий), SAGA (компенсирующие транзакции) или TCC.
В микросервисах чаще применяют SAGA с событиями, так как 2PC плохо масштабируется.
Если система допускает eventual consistency, можно обойтись асинхронной обработкой через Kafka или RabbitMQ."

2PC (Two-Phase Commit)
"Координатор сначала запрашивает все сервисы ('готовы ли вы commit?'), и если все согласны, подтверждает транзакцию. 
Если хотя бы один отказал – откатывает. Используется в XA-транзакциях (JTA), но имеет проблемы с блокировками и 
отказоустойчивостью."

SAGA
"Вместо блокирующего 2PC используется компенсирующие транзакции. Если один шаг падает, вызываются обратные операции 
(compensating actions). Например, если оплата прошла, но доставка не подтвердилась – деньги возвращаются. Часто реализуется 
через события (Kafka, RabbitMQ)."

## Расскажите_про_ACID

ACID - это акроним, который описывает основные свойства распределенных транзакций:
1. Атомарность (Atomicity): Транзакция считается атомарной, если все ее операции выполняются как единое целое. 
   Если одна операция не может быть выполнена, то все операции отменяются и возвращается исходное состояние системы.
2. Согласованность (Consistency): Транзакция должна приводить систему из одного согласованного состояния в другое 
   согласованное состояние. Это означает, что все ограничения целостности данных должны быть соблюдены.
3. Изолированность (Isolation): Каждая транзакция должна быть изолирована от других транзакций, выполняющихся параллельно. 
   Это гарантирует, что результаты одной транзакции не будут видны другим транзакциям до ее завершения.
4. Долговечность (Durability): После успешного завершения транзакции ее результаты должны быть сохранены и доступны даже в 
   случае сбоя системы.

## Что_такое_идемпотенция_и_где_она_используется

Идемпотенность - это свойство операции, которое гарантирует, что повторное выполнение операции не приведет к изменению 
состояния системы после первого выполнения. Другими словами, если операция выполняется несколько раз, результат будет
таким же, как и при первом выполнении.

Для обеспечения идемпотентности используют:
1. Точные условия в WHERE.
2. Оптимистичные блокировки (версионирование).
3. Уникальные ограничения в таблицах.
4. Токены идемпотентности (хранение ключей запросов)."*

## Что_такое_ограниченный_контекст

Ограниченный контекст (Bounded Context) - это ключевое понятие из Domain-Driven Design (DDD), которое определяет четкую 
границу, внутри которой определенная модель предметной области (domain model) имеет единое смысловое значение и 
согласованность. Другими словами, это логическая граница, где термины, правила и бизнес-логика остаются непротиворечивыми."

Ограниченный контекст помогает разработчикам разделить сложные системы на более мелкие и понятные части, что упрощает 
разработку, тестирование и поддержку приложения. Каждый ограниченный контекст может иметь свою собственную модель данных, 
базу данных и интерфейсы для взаимодействия с другими микросервисами. Это позволяет разработчикам работать над каждым 
ограниченным контекстом независимо и эффективно масштабировать систему.

## Что_такое_ORM

ORM (Object-relational mapping) — это технология, которая позволяет работать с реляционной базой данных, используя 
объекты в коде, вместо прямого написания SQL-запросов. ORM автоматически преобразует данные между реляционной БД и 
объектной моделью приложения.
Основные задачи ORM
- Маппинг сущностей: Связывает классы Java с таблицами в БД (например, User → users).
- Управление состоянием объектов: Отслеживает изменения объектов (new, dirty, deleted).
- Генерация SQL: Автоматически создает оптимальные запросы (SELECT, INSERT, UPDATE, DELETE).
- Кеширование: Уменьшает количество запросов к БД.
- Транзакции: Предоставляет API для управления транзакциями.

Недостатки и подводные камни
- Производительность: N+1 проблема, лишние запросы.
- Сложные запросы: Для аналитических запросов ORM может быть неэффективен.
- Оверхеад: Изучение Hibernate — это отдельная наука.
- Неочевидный SQL: ORM может сгенерировать неожиданно тяжелый запрос.

## Что_такое_JPA

JPA (Java Persistence API) - это стандартный Java-интерфейс для ORM (Object-Relational Mapping), который описывает, 
как объекты Java должны сохраняться в реляционной базе данных. Это не реализация, а спецификация, которую реализуют 
такие фреймворки, как Hibernate, EclipseLink и другие.

Ключевые компоненты JPA
- Entity: Класс, отображенный на таблицу БД (аннотация @Entity).
- EntityManager: Интерфейс для CRUD-операций и управления контекстом persistence.
- Persistence Unit: Настройки подключения к БД в persistence.xml.
- Repository: В Spring Data JPA — интерфейсы для автоматического создания запросов.

## Различия_JPA_JDBC_и_Hibernate

JDBC является гораздо более низкой спецификацией, чем JPA. JDBC - это API-интерфейс для взаимодействия с базой данных 
с использованием чистого SQL - отправки запросов и получения результатов. Он не имеет понятия об объектах или иерархиях.

А в JPA вы также указываете эти детали метаданных базы данных, но с использованием аннотаций Java. 
Таким образом, JPA создает запросы на обновление для вас и управляет объектами, которые вы искали или создали / обновили (это также 
делает больше).

## Что_такое_JPQL_и_HQL

JPQL — Java Persistence Query Language. Фактически это как SQL, только запросы делаются не к таблицам, а к классам. 
JPQL основан на HQL. В отличии от SQL в запросах JPQL есть автоматический полиморфизм, то есть каждый запрос к Entity 
возвращает не только объекты этого Entity, но также объекты всех его классов-потомков, независимо от стратегии наследования.

HQL — Hibernate Query Language. Аналог SQL, но работает с сохраняемыми объектами (Persistent Objects) и
их полями (аттрибутами класса).

## Что_такое_Criteria_API

Criteria API — это программный, типобезопасный способ создания запросов к базе данных в JPA. В отличие от JPQL 
(который использует строковые запросы), Criteria API позволяет строить запросы через Java-объекты, что дает преимущества 
на этапе компиляции.

Ключевые компоненты
- CriteriaBuilder: Фабрика для создания частей запроса.
- CriteriaQuery: Основной объект запроса.
- Root: Корень запроса (аналог FROM в SQL).
- Predicate: Условия (аналог WHERE).

## Ккакие_преимущества_и_недостатки_Hibernate

1. Hibernate является одним из самых востребованных ORM фреймворков для Java. И вот почему:
2. Hibernate устраняет множество спагетти кода (повторяющегося), который постоянно преследует разработчика при работе с JDBC. Скрывает 
   от разработчика множество кода, необходимого для управления ресурсами и позволяет сосредоточиться на бизнес логике.

3. Hibernate поддерживает XML так же как и JPA аннотации, что позволяет сделать реализацию кода независимой.
4. Hibernate предоставляет собственный мощный язык запросов (HQL), который похож на SQL. Стоит отметить, что HQL полностью 
   объектно-ориентирован и понимает такие принципы, как наследование, полиморфизм и ассоциации (связи).

5. Hibernate легко интегрируется с другими Java EE фреймворками, например, Spring Framework поддерживает встроенную интеграцию с Hibernate.
6. Hibernate поддерживает ленивую инициализацию используя proxy объекты и выполняет запросы к базе данных только по необходимости.
7.  Hibernate поддерживает разные уровни cache, а следовательно может повысить производительность.
8. Важно, что Hibernate может использовать чистый SQL, а значит поддерживает возможность оптимизации запросов и работы с любым сторонним 
   вендором БД и его фичами.

Hibernate имеет ряд преимуществ перед JDBC API:
1. Hibernate удаляет множество повторяющегося кода из JDBC API, а следовательно его легче читать, писать и поддерживать.
2. Hibernate поддерживает наследование, ассоциации и коллекции, что не доступно в JDBC API.
3. Hibernate неявно использует управление транзакциями. Большинство запросов нельзя выполнить вне транзакции. При использовании JDBC API для 
   управления транзакциями нужно явно использовать commit и rollback. 
4. JDBC API throws SQLException, которое относится к проверяемым исключениям, а значит необходимо постоянно писать множество блоков try-catch. 
   В большинстве случаев это не нужно для каждого вызова JDBC и используется для управления транзакциями. Hibernate оборачивает исключения JDBC 
   через непроверяемые JDBCException или HibernateException, а значит нет необходимости проверять их в коде каждый раз. Встроенная поддержка 
   управления транзакциями в Hibernate убирает блоки try-catch.
5. Hibernate Query Language (HQL) более объектно ориентированный и близкий к Java язык запросов, чем SQL в JDBC.
6. Hibernate поддерживает кэширование, а запросы JDBC — нет, что может понизить производительность.
7. Hibernate поддерживает аннотации JPA, а значит код является переносимым на другие ORM фреймворки, реализующие стандарт, в то время как код 
   JDBC сильно привязан к приложению.

## Что_делает_DriverManager_DataSource_Connection

DriverManager - позволяет загрузить и зарегистрировать необходимый JDBC-драйвер, а затем получить соединение с базой данных.
Проблемы:
- Нет пулинга соединений (каждый вызов getConnection() создает новое подключение).
-Жесткая привязка к URL, логину и паролю в коде.
- Устарел (с Java 1.8 рекомендуется использовать DataSource).

DataSource - интерфейс, который предоставляет более гибкий способ получения подключений с поддержкой:
- Пулинга соединений (HikariCP, Tomcat JDBC Pool).
- Кеширования и балансировки

Connection - интерфейс, представляющий активное подключение к БД. Через него выполняются:
- SQL-запросы (createStatement(), prepareStatement()).
- Транзакции (setAutoCommit(false), commit(), rollback()).
- Управление метаданными (getMetaData()).

## В_чем_отличие_между_Statement_PreparedStatement_CallableStatement

1. Statement - Простейший способ выполнения SQL-запросов без параметров. Создается через Connection.createStatement()
2. PreparedStatement — защищенный и оптимизированный с поддержкой параметризованных запросов. Используется кеширование запросов.
   Защита от инъекций + кеширование.
3. CallableStatement — для хранимых процедур. Создается через Connection.prepareCall(). Для вызова хранимых процедур.
   Когда бизнес-логика реализована на стороне БД.

-------------------------------------------------------------------------------------------------------------------------------------

## Что_делает_ResultSet_ResultSetMetaData_DatabaseMetaData

ResultSet - это интерфейс в JDBC, который представляет собой таблицу данных, полученную в результате выполнения SQL-запроса.
Получается через Statement.executeQuery().
Поддерживает навигацию: next(), previous(), absolute().

ResultSetMetaData - это интерфейс, который предоставляет метаинформацию о структуре.
Получается через ResultSet.getMetaData().
Полезен для динамической обработки результатов (например, в универсальных утилитах).
Основные методы:
getColumnCount() – число колонок.
getColumnName(int column) – имя колонки.
getColumnTypeName(int column) – тип данных.

DatabaseMetaData - это интерфейс, предоставляющий информацию о самой СУБД: её версии, поддерживаемых возможностях, структуре таблиц, 
индексах и т.д.
Получается через Connection.getMetaData().
Используется для анализа базы данных на лету (например, в ORM или миграционных инструментах).
Основные методы:
getTables() – список таблиц.
getPrimaryKeys() – первичные ключи таблицы.
supportsTransactions() – поддерживает ли СУБД транзакции.

## Какие_уровни_изоляции_транзакций_поддерживаются_в_JDBC

Уровень изолированности транзакций — значение, определяющее уровень, при котором в транзакции допускаются несогласованные данные, 
то есть степень изолированности одной транзакции от другой. Более высокий уровень изолированности повышает точность данных, но при 
этом может снижаться количество параллельно выполняемых транзакций. С другой стороны, более низкий уровень изолированности позволяет 
выполнять больше параллельных транзакций, но снижает точность данных.

Уровни изоляции транзакций определены в виде констант интерфейса java.sql.Connection:
1. TRANSACTION_NONE – драйвер не поддерживает транзакции;
2. TRANSACTION_READ_UNCOMMITTED – позволяет транзакциям видеть несохраненные изменения данных: разрешает грязное, непроверяющееся и 
   фантомное чтения;
3. TRANSACTION_READ_COMMITTED – любое изменение, сделанное в транзакции, не видно вне неё, пока она не сохранена: предотвращает грязное 
   чтение, но разрешает непроверяющееся и фантомное;
4. TRANSACTION_REPEATABLE_READ – запрещает грязное и непроверяющееся, фантомное чтение разрешено;
5. TRANSACTION_SERIALIZABLE – грязное, непроверяющееся и фантомное чтения запрещены.

## Какие_существуют_блокировки_в_JDBC

1. Ручные блокировки
- SELECT FOR UPDATE – блокирует строки для изменения другими транзакциями.
`
try (Statement stmt = connection.createStatement()) {
  ResultSet rs = stmt.executeQuery("SELECT * FROM accounts WHERE id = 1 FOR UPDATE");
  // Строка заблокирована до commit/rollback
  }
`
2. LOCK TABLE (не поддерживается всеми СУБД) – блокирует всю таблицу.
`statement.execute("LOCK TABLE accounts IN EXCLUSIVE MODE");`

1. «грязное» чтение (dirty read) — это аномалия параллельного доступа к данным, при которой одна транзакция видит незафиксированные 
   изменения другой транзакции. Если эти изменения потом откатятся (rollback), первая транзакция получит некорректные данные;
Как возникает?
- Транзакция A изменяет строку, но не коммитит изменения.
- Транзакция B читает эту строку и видит промежуточные, незавершённые данные от A.
- Если A делает rollback, данные в B становятся невалидными.
Где возможно?
- Только при уровне изоляции READ_UNCOMMITTED (самом низком).
- В READ_COMMITTED и выше СУБД блокирует доступ к незафиксированным изменениям.
Как избежать?
- Использовать READ_COMMITTED или выше.
  connection.setTransactionIsolation(Connection.TRANSACTION_READ_COMMITTED);
- Пессимистичные блокировки (SELECT FOR UPDATE).
- Оптимистичные блокировки (через версии/таймстемпы).
В PostgreSQL и Oracle даже READ_UNCOMMITTED ведёт себя как READ_COMMITTED из-за архитектурных особенностей (MVCC).

2. неповторяющееся чтение (non-repeatable read) — это аномалия параллельного доступа к данным, при которой в рамках одной транзакции 
   повторное чтение одной и той же строки возвращает разные значения из-за того, что другая транзакция изменила и зафиксировала эту строку;
Как возникает?
- Транзакция A читает строку.
- Транзакция B изменяет эту же строку и фиксирует изменения (COMMIT).
- Транзакция A читает строку ещё раз и видит новые данные от B.
Где возникает?
- При уровне изоляции READ_COMMITTED (по умолчанию в PostgreSQL, Oracle, SQL Server).
- Исчезает на уровнях REPEATABLE_READ и SERIALIZABLE.
Как избежать?
- Повысить уровень изоляции
  - REPEATABLE_READ гарантирует, что прочитанные строки не изменятся до конца транзакции.
  - SERIALIZABLE полностью предотвращает аномалии, но снижает производительность.
- Использовать блокировки
  - Пессимистичная блокировка (SELECT FOR UPDATE)
  - Оптимистичная блокировка (через version)
  - Использовать SNAPSHOT ISOLATION (если СУБД поддерживает)
В PostgreSQL и Oracle REPEATABLE_READ реализован через Snapshot Isolation, что предотвращает не только Non-Repeatable Read, но и 
Phantom Read (в отличие от стандартного SQL). В MySQL InnoDB REPEATABLE_READ блокирует только прочитанные строки, но не диапазоны 
(фантомы возможны)

3. фантомное чтение (phantom reads) — это аномалия параллельного доступа, при которой в рамках одной транзакции повторное выполнение 
одного и того же запроса возвращает новые "фантомные" строки, добавленные другой транзакцией.
Как возникает?
- Транзакция A выполняет запрос с условием (например, WHERE status = 'pending').
- Транзакция B добавляет новые строки, удовлетворяющие этому условию, и фиксирует изменения (COMMIT).
- Транзакция A повторяет запрос и видит новые строки, которых не было при первом чтении.

Где возникает?
- При уровне изоляции REPEATABLE_READ (в большинстве СУБД, кроме Oracle и PostgreSQL).
- Полностью предотвращается только на уровне SERIALIZABLE.

Как избежать?
- Повысить уровень изоляции до SERIALIZABLE
- Использовать диапазонные блокировки (если СУБД поддерживает)
  - SELECT * FROM orders WHERE status = 'pending' FOR UPDATE;
- Оптимистичные блокировки (через контроль версий)
  - Добавить version или timestamp и проверять, что данные не изменились.
- Использовать SELECT ... LOCK IN SHARE MODE (в MySQL)
  - SELECT * FROM orders WHERE status = 'pending' LOCK IN SHARE MODE;
В PostgreSQL REPEATABLE_READ = SERIALIZABLE в других СУБД, так как использует MVCC (версии данных). В MySQL InnoDB REPEATABLE_READ допускает фантомы, если не использовать FOR UPDATE

## Чем_отличается_пессимистичная_и_оптимистичная_блокировка

Пессимистичная (через SELECT FOR UPDATE) – блокирует данные заранее.
Оптимистичная – проверяет конфликты при коммите (например, через version).

## Как_избежать_deadlock_in_JDBC

1. Использовать одинаковый порядок блокировок во всех транзакциях.
2. Уменьшать время удержания блокировок (быстрее коммитить).
3. Использовать tryLock с таймаутом (если СУБД поддерживает).

## Чем_отличается_Statement_от_PreparedStatement

В высоконагруженных системах мы используем PreparedStatement + пул соединений (HikariCP) для максимальной производительности. Для batch-операций — addBatch(), 
чтобы снизить нагрузку на сеть.

1. Statement: 
- Используется для простых случаев запроса без параметров.
- Запрос формируется через конкатенацию строк.
- Медленнее (каждый запрос компилируется заново).
- Уязвим к SQL-инъекциям.
- Для статичных запросов.

2. PreparedStatement: 
- предварительно компилирует запрос, который может содержать входные параметры и выполняться несколько раз с разным набором этих параметров.
- Использует параметры (?).
- Быстрее (прекомпиляция + кэширование).
- Защищает от SQL-инъекций.
- Для динамических запросов.

Как PreparedStatement предотвращает SQL-инъекции?
- Параметры передаются отдельно от SQL и экранируются драйвером.
Всегда ли PreparedStatement быстрее?
- Да, кроме случаев, когда запрос выполняется 1 раз (перекомпиляция может быть избыточной).

## Как_осуществляется_запрос_к_базе_данных_и_обработка_результатов

Выполнение запросов осуществляется при помощи вызова методов объекта, реализующего интерфейс Statement:
1. executeQuery() - для запросов, результатом которых является один набор значений, например запросов SELECT. Результатом выполнения является 
   объект класса ResultSet;
2. executeUpdate() - для выполнения операторов INSERT, UPDATE или DELETE, а также для операторов DDL (Data Definition Language). Метод 
   возвращает целое число, показывающее, сколько записей было модифицировано;
3. execute() – исполняет SQL-команды, которые могут возвращать различные результаты. Например, может использоваться для операции CREATE TABLE. 
   Возвращает true, если первый результат содержит ResultSet и false, если первый результат - это количество модифицированных записей или 
   результат отсутствует. Чтобы получить первый результат необходимо вызвать метод getResultSet() или getUpdateCount(). Остальные результаты 
   доступны через вызов getMoreResults(), который при необходимости может быть произведён многократно.

Объект с интерфейсом ResultSet хранит в себе результат запроса к базе данных - некий набор данных, внутри которого есть курсор, 
указывающий на один из элементов набора данных - текущую запись.
Используя курсор можно перемещаться по набору данных при помощи метода next().

## Как_вызвать_хранимую_процедуру

Хранимые процедуры – это именованный набор операторов SQL хранящийся на сервере. Такую процедуру можно вызвать из Java-класса с помощью 
вызова методов объекта реализующего интерфейс Statement.
1. Через CallableStatement (стандартный способ)
`
try (Connection conn = dataSource.getConnection()) {
   try (CallableStatement stmt = conn.prepareCall("{call get_user_by_id(?, ?)}")) {
        stmt.setInt(1, 123); // id пользователя
        stmt.registerOutParameter(2, Types.VARCHAR); // имя пользователя
        stmt.execute();
        String userName = stmt.getString(2);
        System.out.println("User name: " + userName);
   }
}
`
2. Для процедур, возвращающих ResultSet
`
try (CallableStatement stmt = conn.prepareCall("{call get_active_users()}")) {
   boolean hasResults = stmt.execute();
   while (hasResults) {
     try (ResultSet rs = stmt.getResultSet()) {
      while (rs.next()) {
        System.out.println(rs.getString("username"));
      }
     }
     hasResults = stmt.getMoreResults();
   }
}
`

## Как_оптимизировать_вызов_хранимых_процедур

1. Использовать пул соединений (HikariCP).
2. Для массовых операций — batch-вызовы.
3. Кэшировать CallableStatement (если соединение долгоживущее).

## Чем_вызов_процедуры_отличается_от_выполнения_SQL

- Процедуры выполняются на стороне СУБД, что снижает сетевые издержки.
- Могут содержать сложную логику, недоступную в одном SQL-запросе.

## Что_такое_Entity

Entity - класс Java, который отображается на таблицу в БД (ORM-мэппинг).
- Должен быть public-классом.
- Должен иметь пустой конструктор (для Hibernate).
- Поля должны иметь геттеры и сеттеры (или быть public в Kotlin).
- Не должен быть final (Hibernate использует прокси для ленивой загрузки).

## Почему_Entity_не_должен_быть_final

Hibernate создает прокси-объекты для ленивой загрузки (например, для @ManyToOne). Прокси требует наследования от Entity-класса, 
что невозможно, если класс final.

## Как_избежать_N_1_проблемы_в_Entity
Как избежать N+1 проблемы в Entity

1. Использовать JOIN FETCH в запросах:
`@Query("SELECT u FROM User u JOIN FETCH u.orders WHERE u.id = :id")
User findUserWithOrders(@Param("id") Long id);`

2. Настроить @BatchSize для ленивых коллекций.

В высоконагруженных системах мы избегаем возвращать Entity из REST-API, чтобы не сериализовать ленивые связи. Вместо этого используем 
DTO с явно указанными полями

## Может_ли_абстрактный_класс_быть_Entity

Абстрактный класс может быть Entity классом. Абстрактный Entity класс отличается от обычных Entity классов только тем, что нельзя создать 
объект этого класса. Имена абстрактных классов могут использоваться в запросах.

Абстрактные Entity классы используются в наследовании, когда их потомки наследуют поля абстрактного класса:
`
@Entity
@Inheritance(strategy = InheritanceType.TABLE_PER_CLASS)
public abstract class Employee {
@Id
@GeneratedValue
private long id;
private String name;
.............
}
@Entity
@Table(name = "FULL_TIME_EMP")
public class FullTimeEmployee extends Employee {
private int salary;
.............
}
@Entity
@Table(name = "PART_TIME_EMP")
public class PartTimeEmployee extends Employee {
private int hourlyRate;
.............
}
`

## Что_такое_POJO_класс

Plain Old Java Object - простой Java-объект, не унаследованный от какого-то специфического объекта и не реализующий никаких служебных 
интерфейсов сверх тех, которые нужны для бизнес-модели.

## Что_такое_Mapped_Superclass

Mapped Superclass это класс от которого наследуются Entity, он может содержать аннотации JPA, однако сам такой класс не является Entity, 
ему не обязательно выполнять все требования установленные для Entity (например, он может не содержать первичного ключа). Такой класс не 
может использоваться в операциях EntityManager или Query. Такой класс должен быть отмечен аннотацией MappedSuperclass или соответственно
описан в xml файле.

Особенности ‒ Должен быть помечен аннотацией @MappedSuperclass или описан в xml файле. ‒ Не может использоваться в операциях EntityManager
или Query, вместо этого нужно использовать классы-наследники. ‒ Не может состоять в отношениях с другими сущностями (в сущности нельзя 
создать поле с типом сопоставленного суперкласса). ‒ Может быть абстрактным. ‒ Не имеет своей таблицы в БД.

## Для_чего_необходим_EntityManagerFactory_и_EntityManager

EntityManagerFactory – это тяжеловесный объект, который создает EntityManager и управляет их пулом.
Для чего нужен?
- Инициализация JPA: Загружает настройки из persistence.xml (или конфигурации Spring).
- Создание EntityManager: Генерирует экземпляры EntityManager для работы с БД.
- Кэширование метаданных: Хранит информацию о маппинге Entity → таблицы БД.

EntityManager – это легковесный объект, который выполняет CRUD-операции с Entity и управляет их жизненным циклом.
Для чего нужен?
- Управление транзакциями:
  - entityManager.getTransaction().begin();
    entityManager.persist(user); // INSERT
    entityManager.getTransaction().commit();
  - CRUD-операции:
    - persist() — добавить новую Entity.
      find() — найти по ID.
      merge() — обновить detached-Entity.
      remove() — удалить Entity.
  - JPQL-запросы.
  - Управление состоянием Entity:
    - Переводит Entity между состояниями: Transient, Managed, Detached, Removed.

## Почему_EntityManager_не_thread_safe

EntityManager хранит состояние (например, кэш первого уровня), которое может быть повреждено при конкурентном доступе.

## Как_работает_кэш_первого_уровня_в_EntityManager

Это контекст persistence, который хранит Managed-сущности.
Повторный find() для того же ID вернет объект из кэша, а не из БД.
Кэш очищается при close() или clear().

## Зачем_нужен_merge_если_есть_persist

1. persist() — только для новых (Transient) объектов.
2. merge() — для "присоединения" Detached-объектов (например, после десериализации DTO).

## Какие_методы_операций_над_Entity

Методы операций над Entity:
1. persist (добавление Entity под управление JPA)
2. merge (обновление)
3. remove (удаления)
4. refresh (обновление данных)
5. detach (удаление из управление JPA)
6. lock (блокирование Enity от изменений в других thread).

## Какие_методы_получение_данных

Методы получение данных:
1. find (поиск и получение Entity)
2. createQuery, createNamedQuery, createNativeQuery
3. contains
4. createNamedStoredProcedureQuery, createStoredProcedureQuery

## Для_чего_необходим_EntityTransaction

EntityTransaction — это абстракция над JDBC-транзакциями, добавляющая интеграцию с JPA (кэш первого уровня, управление состояниями Entity).
Позволяет:
- Начинать транзакцию (begin()).
- Фиксировать изменения (commit()).
- Откатывать изменения (rollback()).

## Как_работает_setRollbackOnly

Это "мягкий" откат:
`transaction.begin();
try {
    someBusinessLogic();
    if (somethingWrong) {
        transaction.setRollbackOnly(); // Помечаем для отката
    }
    transaction.commit(); // Будет RollbackException, если стоит setRollbackOnly()
} catch (...) { ... }`

## Какие_методы_есть_у_EntityTransaction

Методы:
1. begin() - Начинает новую транзакцию.
2. commit() - Фиксирует изменения в БД.
3. getRollbackOnly() - Возвращает true, если транзакция помечена на откат.
4. isActive() - Проверяет, активна ли транзакция.
5. rollback() - Откатывает изменения.
6. setRollbackOnly() - 	Помечает транзакцию для отката (без немедленного rollback()).

Что происходит при вызове commit() с setRollbackOnly()?
- Будет брошено RollbackException — транзакция не может быть зафиксирована, если помечена на откат.

Когда использовать setRollbackOnly(), а не rollback()?
- setRollbackOnly() — если ошибка обработана, но транзакцию нужно завершить "тихо".
- rollback() — если нужно немедленно прервать выполнение.

## Основные_классы_и_интерфейсы_Hibernate

SessionFactory – используется для получения объектов Session, которые используются для операций с базами данных. SessionFactory отвечает
за считывание параметров конфигурации Hibernate и подключение к базе данных. Неизменяемый потокобезопасный объект с компилированным 
маппингом для одной базы данных. Необходимо инициализировать SessionFactory всего один раз.

Session – однопоточный короткоживущий объект, который предоставляет связь между объектами приложения и базой данных. Он оборачивает 
Connection и работает как фабрика для Transaction. Разработчик должен открывать сессию по необходимости и 
закрывать ее сразу после использования. Экземпляр Session является интерфейсом между кодом в java приложении и hibernate framework и 
предоставляет методы для операций CRUD. Расширяет интерфейс EntityManager

Transaction – однопоточный короткоживущий объект, используемый для атомарных операций. Это абстракция приложения от основных JDBC или 
JTA транзакций. Session может занимать несколько Transaction в определенных случаях.

Configuration - этот объект используется для создания объекта SessionFactory и конфигурирует сам Hibernate

Criteria - Используется для создания и выполнения объекто-ориентированных запроса на получение объектов.

Query - Этот объект использует HQL или SQL для чтения/записи данных из/в БД. Экземпляр запроса используется для связывания парметров 
запроса, ограничения количества результатов, которые будут возвращены и для выполнения запроса.

## Способы_сконфигурировать_Hibernate

1. используя аннотации
2. hibernate.cfg.xml
3. hibernate.properties
4. persistence.xml

Самый частый способ конфигурации: через аннотации и файл persistence.xml, что касается файлов hibernate.properties и hibernate.cfg.xml, 
то hibernate.cfg.xml главнее (если в приложение есть оба файла, то принимаются настройки из файла hibernate.cfg.xml). 
Конфигурация аннотациями, хоть и удобна, но не всегда возможна, например, если для разных баз данных или для разных ситуаций вы хотите 
иметь разные конфигурацию сущностей, то следует использовать xml файлы конфигураций. По мимо этого хибернейт можно сконфигурировать с 
использованием SessionFactory или EntityManagerFactory. При использовании JPA или Hibernate у вас есть два варианта: Вы можете загрузиться 
с помощью встроенного механизма Hibernate и создать SessionFactory. Или вы можете создать JPA EntityManagerFactory Начальная загрузка через
JPA должна быть предпочтительной.

## Жизненный_цикл_Entity

У Entity объекта существует четыре статуса жизненного цикла:
1. new (Transient) — объект создан, но при этом ещё не имеет сгенерированных первичных ключей и пока ещё не сохранен в базе данных, не 
   привязан к текущему контексту персистентности (к сессии и к кэшу первого уровня). Важно запомнить, что если генерация id для сущности 
   производится базой данных - объекты в состоянии Transient не должны содержать никиаких значений в поле id

2. managed (Persistent) — объект создан, управляется JPA, имеет сгенерированные первичные ключи. В это состояние может попасть объект из 
   абсолютно любого состояния. Что бы перевести объекты из состояния Transient в Persistenr - надо воспользоваться методом persist. Для 
   перевода Detached объекта в это состояние - надо вызвать метод merge. И если ассоциированная с объектом запись была удалена, и объект 
   находится в состоянии Removed - так же стоит вопсользоваться методом persist, чтобы снова сохранить данные в базу, а объект перевести 
   в состояния Persist.

3. detached — объект был создан, но не управляется (или больше не управляется) JPA. Объект, который до этого был привязан к контексту 
   персистентности, но теперь отделен от него. Отделение могло произойти по двум причинам: контекст персистентности был закрыт (закончилась
   тарзакция, закрылась сессия), либо объект был явно отделен методом detach или clear от ещё существующего контекста. Подобный объект 
   имеет заполненное поле id, сгенерированное базой, но контекст персистентности больше не следит за изменением этого объекта. Что бы 
   снова присоединить такой объект к контексту персистентности, и перевести его снова в Persistent надо вызвать метод merge, который 
   сравнит состояние текущего detached объекта и данные из базы

4. removed — объект создан, управляется JPA, но будет удален после commit'a транзакции. Объект, ассоциированная с которым запись была 
   удалена из базы. Такой объект так же не отслеживается контекстом персистентности и информация о нем больше не хранится в кэше первого
   уровня. Такой объект можно только сохранить в базу снова методом persist

## Влияние_операций_EntityManager_на_Entity_объекты_различный_жизненных_циклов

1. Persist
- New -> меняется на managed и объект будет сохранен в базу при commit'е транзакции или в результате flush операций,
- Managed -> операция игнорируется, однако зависимые Entity могут поменять статус на managed, если у них есть аннотации каскадных изменений,
- Removed -> то он меняется на managed,
- Detached -> будет выкинут exception сразу или на этапе commit'а транзакции,

2. Remove
- New -> операция игнорируется, однако зависимые Entity могут поменять статус на removed, если у них есть аннотации каскадных изменений и 
  они имели статус managed,
- Managed -> статус меняется на removed и запись объект в базе данных будет удалена при commit'е транзакции (так же произойдут операции 
  remove для всех каскадно зависимых объектов),
- Removed -> операция игнорируется,
- Detached -> будет выкинут exception сразу или на этапе commit'а транзакции,

3. Merge
- Detached -> то либо данные будет скопированы в существующей managed entity с тем же первичным ключом, либо создан новый managed в который 
  скопируются данные,
- New -> будет создана новый managed entity, в который будут скопированы данные прошлого объекта,
- Managed -> операция игнорируется, однако операция merge сработает на каскадно зависимые Entity, если их статус не managed,
- Removed -> будет выкинут exception сразу или на этапе commit'а транзакции,

4. Refresh
- Managed -> в результате операции будут востановлены все изменения из базы данных данного Entity, так же произойдет refresh всех каскадно 
  зависимых объектов,
- Если статус new, removed или detached, будет выкинут exception,

5. Detach
- Managed или Removed -> в результате операции статус Entity (и всех каскадно-зависимых объектов) станет detached.
- New или Detached -> операция игнорируется,

## Что_делает_аннотация_Access

@Access — аннотация используется для указания типа доступа связанного класса сущности, сопоставленного супер класса или встраиваемого
класса или атрибута сущности.

## Что_делает_аннотация_AssociacionOverride

@AssociacionOverride — аннотация используется для переопределения реляционных отношений таких как один к одному, многие к одному, 
один ко многим, многие ко многим (@OneToOne, @ManyToOne, @OneToMany, @ManyToMany) в классах унаследованных от встраиваемых (embeddable)
или сопоставляемых супер классов (mapped superclass).

## Что_делает_аннотация_AttibuteOverride

@AttibuteOverride — аннотация используется для переопределения сопоставляемых атрибутов Entity классов унаследованных от встраиваемых 
(embeddable) или сопоставляемых супер классов (mapped superclass).

## Что_делает_аннотация_Basic

@Basic — аннотация используется для сопоставления базового типа атрибута столбцу таблицы базы данных.

## Что_делает_аннотация_CollectionTable

@CollectionTable — аннотация используется для указания таблицы базы данных, в которой хранятся значения базовой или встраиваемой 
коллекции типов.

## Что_делает_аннотация_ColumnResult

@ColumnResult — аннотация @ColumnResult используется в сочетании с аннотациями @SqlResultSetMapping или @ConstructorResult для отображения 
столбца SQL для заданного запроса SELECT.

## Что_делает_аннотация_ConstructorResult

@ConstructorResult — аннотация используется в сочетании с аннотациями @SqlResultSetMapping для сопоставления столбцов заданного запроса 
SELECT определенному конструктору объекта.

## Что_делает_аннотация_Convert_и_Converter

@Convert — аннотация используется для определения реализации AttributeConverter, используемой для преобразования текущего аннотированного 
базового атрибута. Если AttributeConverter использует autoApply, все атрибуты сущностей с одним и тем же целевым типом будут автоматически
преобразованы.

@Converter — аннотирование используется, чтобы указать, что текущая реализация AttributeConverter аннотации может использоваться в качестве
конвертора основных атрибутов JPA. Если атрибуту autoApply присвоено значение true, поставщик JPA автоматически преобразует все базовые 
атрибуты с тем же типом Java, как определено текущим преобразователем.

## Что_делает_аннотация_DiscriminatorColumn_и_DisccriminatorValue

@DiscriminatorColumn — аннотация используется для указания имени столбца дискриминатора и типа дискриминатора для стратегий наследования
(Inheritance) SINGLE_TABLE и JOINED.

@DisccriminatorValue — аннотация используется для определения того, какое значение столбца дискриминатора используется для отображения 
текущего аннотированного объекта для стратегий наследования (Inheritance) SINGLE_TABLE и JOINED.

## Что_делает_аннотация_ElementCollection

@ElementCollection — аннотация используется для указания коллекции базового или встраиваемого типа.

## Что_делает_аннотация_Embeddable_и_Embedded_и_EmbeddedId

@Embeddable — аннотация используется для указания встраиваемых типов. Как и базовые типы, встраиваемые типы не имеют никакой 
идентичности, управляемой их собственностью.

@Embedded — аннотация используется, чтобы указать, что данный атрибут сущности представляет встраиваемый тип.

@EmbeddedId — аннотация используется, чтобы указать, что идентификатор объекта является встраиваемым типом.

## Что_делает_аннотация_EntityListeners

@EntityListeners — аннотация используется для указания массива классов слушателя обратного вызова, которые используются текущей 
аннотированной сущностью.

## Что_делает_аннотация_EntityResult

@EntityResult — аннотация используется с аннотацией @SqlResultSetMapping для сопоставления выбранных столбцов сущности.

## Что_делает_аннотация_Enumerated

@Enumerated — аннотация используется, чтобы указать, что атрибут entity представляет перечислимый тип.

## Что_делает_аннотация_FieldResult

@FieldResult — аннотация используется с аннотацией @EntityResult для сопоставления выбранных столбцов полям определенного объекта.

## Что_делает_аннотация_GeneratedValue

@GeneratedValue — аннотация указывает метод генерации значения идентификатора (автоматически генерируется с использованием 
столбца идентификации, последовательности базы данных или генератора таблиц). Hibernate поддерживает сопоставление @GeneratedValue 
даже для идентификаторов UUID.

## Что_делает_аннотация_Index

@Index — аннотация используется для создания индекса базы данных если включен инструмент автоматического создания и корректировки 
схемы базы данных.

## Что_делает_аннотация_Inheritance

@Inheritance — аннотирование используется для указания стратегии наследования для данной иерархии классов сущностей.

## Что_делает_аннотация_Lob

@Lob — аннотация используется, чтобы указать, что текущий аннотированный атрибут объекта представляет большой тип объекта.

## Что_делает_аннотация_MapKey

@MapKey — аннотация используется для указания ключа ассоциации java.util.Map, для которой ключ является либо первичным 
ключом, либо атрибутом объекта, который представляет значение Map.

## Что_делает_аннотация_MapKeyColumn

@MapKeyColumn — аннотация используется для указания столбца базы данных, в котором хранится ключ ассоциации java.util.Map, 
для которой ключ карты является базовым типом.

## Что_делает_аннотация_NamedQuery

@NamedQuery — аннотация используется для указания JPQL-запроса, который впоследствии можно найти по его имени.

## Что_делает_аннотация_PersistenceContext

@PersistenceContext — аннотация используется для указания EntityManager, который необходимо ввести как зависимость.

## Что_делает_аннотация_OrderColumn

@OrderColumn — аннотирование используется, чтобы указать, что текущий сборник аннотаций должен быть материализован в базе данных.

## Что_делает_аннотация_PostPersist

@PostPersist — аннотация используется для указания метода обратного вызова, который срабатывает после сохранения объекта.

## Что_делает_аннотация_Any

@Any — аннотация используется для определения связи any-to-one, которая может указывать на один из нескольких типов сущностей.

## Что_делает_аннотация_BatchSize

@BatchSize — аннотация используется, чтобы указать размер для пакетной загрузки записей ленивой коллекции.

## Что_делает_аннотация_Fetch

@Fetch — аннотация используется для указания специфического для Hibernate режима FetchMode (например, JOIN, SELECT, SUBSELECT), 
используемого для текущей аннотированной связи

## Что_делает_аннотация_OptimisticLock

@OptimisticLock — аннотация используется, чтобы указать, будет ли текущий аннотированный атрибут запускать приращение версии
объекта при изменении.

## Что_делает_аннотация_OptimisticLocking

@OptimisticLocking — аннотация используется для указания текущей аннотированной оптимизированной стратегии блокировки сущности. 
Четыре возможные стратегии определяются перечислением OptimisticLockType: NONE - неявный оптимистический механизм блокировки отключен.
VERSION - Неявный оптимистический механизм блокировки использует выделенный столбец версии. ALL - Неявный оптимистический механизм
блокировки использует все атрибуты как часть расширенного предложения WHERE для операторов UPDATE и DELETE SQL. 
DIRTY - Неявный оптимистический механизм блокировки использует грязные атрибуты (атрибуты, которые были изменены) как часть 
расширенного предложения WHERE для операторов UPDATE и DELETE SQL.

## Назовите_некоторые_важные_интерфейсы_Hibernate

1. SessionFactory (org.hibernate.SessionFactory) — неизменяемый потокобезопасный объект с компилированным маппингом для одной базы
данных. Необходимо инициализировать SessionFactory всего один раз. Экземпляр SessionFactory используется для получения объектов
Session, которые используются для операций с базами данных.
2. Session (org.hibernate.Session) — однопоточный короткоживущий объект, который предоставляет связь между объектами приложения и
базой данных. Он оборачивает JDBC java.sql.Connection и работает как фабрика для org.hibernate.Transaction. Разработчик должен
открывать сессию по необходимости и закрывать ее сразу после использования. Экземпляр Session является интерфейсом между кодом
в java приложении и hibernate framework и предоставляет методы для операций CRUD.
3. Transaction (org.hibernate.Transaction) — однопоточный короткоживущий объект, используемый для атомарных операций. Это абстракция
приложения от основных JDBC или JTA транзакций. org.hibernate.Session может занимать несколько org.hibernate.Transaction в 
определенных случаях.

## Расскажите_про_первый_уровень_кеширования_в_Hibernate

Кеш 1-го уровня — кеш первого уровня всегда привязан к объекту сессии. Hibernate всегда по умолчанию использует этот кеш и его нельзя 
отключить. При использовании методов save(), update(), saveOrUpdate(), load(), get(), list(), iterate(), scroll() всегда будет 
задействован кеш первого уровня.

При работе с БД можно использовать HQL, Criteria API или Native Query. При этом при использовании нативных запросов, они не кешируются. 
Даже кешем первого уровня, который не отключается.

Интересно поведение кэша первого уровня при использовании ленивой загрузки. При загрузке объекта методом load() или объекта с лениво 
загружаемыми полями, лениво загружаемые данные в кэш не попадут. При обращении к данным будет выполнен запрос в базу и данные будут 
загружены и в объект и в кэш. А вот следующая попытка лениво загрузить объект приведёт к тому, что объект сразу вернут из кэша и уже 
полностью загруженным.

Кэш первого уровня связан с объектом Session, а другие объекты сеанса в приложении его не видят.
Область действия объектов кэша имеет сессию. Как только сессия закрыта, кэшированные объекты исчезают навсегда.
Кэш первого уровня включен по умолчанию, и вы не можете его отключить.
Когда мы запрашиваем объект в первый раз, он извлекается из базы данных и сохраняется в кэше первого уровня, связанном с сессией хибернейта.
Если мы снова запросим тот же объект с тем же объектом сеанса, он будет загружен из кэша, и никакой SQL-запрос не будет выполнен.
Загруженный объект можно удалить из сеанса с помощью метода evict(). Следующая загрузка этого объекта снова вызовет базу данных, если она 
была удалена с помощью метода evict().
Весь кэш сеанса можно удалить с помощью метода clear(). Это удалит все сущности, хранящиеся в кэше.
Кэш первого уровня не является потокобезопасным.
Кэш первого уровня привязан к сессии и уничтожается следом за уничтожением сессии.
Из этого следует один важный вывод: кэш первого уровня не является средством оптимизации большого количества повторяющихся запросов на 
выборку со стороны клиента, т.к. каждый запрос будет обрабатываться в отдельной транзакции, на которую будет выделен новый объект 
entityManager, который связан напрямую с новой сессией. Соответственно, на 20 одинаковых запросов пользователя будет создано 20 
entityManager и 20 сессий. Будет выделено 20 транзакций, даже если запросы обрабатываются и поступают одновременно. 

Кэш первого уровня нужен: 
1. Для сохранения целостности данных 
2. Оптимизации запросов на изменение/удаление 
3. Оптимизация запросов на выборку в рамках одной транзакции В пределах жизненного цикла одной сессии и в рамках одной транзакции
мы можем изменить внутреннее состояние сущности неограниченное количество раз, каждое изменение будет вноситься в кэш первого уровня.
Но в базу запрос отправится только тогда, когда будет сделан комит транзакции. В базу отправятся те данные, которые содержит 
сущность на момент последнего изменения. До тех пор, пока транзакция не будет закончена - все изменения будут храниться в кэше. 
Даже если мы вызовем 20 раз метод setField() у любой сущности - в базу в итоге отправится только один запрос. Если же мы 
вынуждены читать в рамках одной транзакции несколько раз одни и те же данные, то, единожды загрузив данные запросом из базы мы 
будем в дальнейшем работать с данными внутри кэша, не повторяя дополнительных запросов. Например, если достать List и затем достать 
конкретного юзера с id=2, то запрос в базу не будет произведен, т.к. список всех пользователей уже лежит в кэше. Так же, если мы, 
уже после того как достали пользователя с id=2 изменили 10 раз его имя, а затем снова выберем список всех пользователей - мы и в
этом случае не получим дополнительных запросов. В описанном выше случае будет произведено только два запроса: на выборку списка 
всех пользователей в самом начала и один запрос на изменение состояния пользователя уже в конце транзакции.

evict() используется для удаления конкретного объекта из кэша, связанного с сеансом, а метод clear() используется для удаления всех 
кэшированных объектов, связанных с сеансом.

## Расскажите_про_второй_уровень_кеширования_в_Hibernate

Кеш 2-го уровня — кеш второго уровня привязан к объекту-фабрике сессий (Session Factory object). Что как бы подразумевает, что видимость 
этого кеша гораздо шире кеша первого уровня. Чтение из кеша второго уровня происходит только в том случае, если нужный объект не был найден
в кеше первого уровня. По умолчанию кеш второго уровня отключен. Для включения необходимо добавить следующие строки в Вашем конфигурационном 
файле JPA (persistence.xml):

Будут ли в нашем приложении кэшироваться сущности и связанные с ними состояния, определяется значением элемента shared-cache-mode файла 
persistence.xml (или в свойстве javax.persistence.sharedCache.mode конфигурационного файла). 
Если в файле для элемента shared-cache-mode установлено значение:
1. ENABLE_SELECTIVE (дефолтное и рекомендуемое значение): только сущности с аннотацией @Cacheable (равносильно значению по умолчанию 
   @Cacheable(value=true)) будут сохраняться в кэше второго уровня.
2. DISABLE_SELECTIVE: все сущности будут сохраняться в кэше второго уровня, за исключением сущностей, помеченных аннотацией 
   @Cacheable(value=false)как некэшируемые.
3. ALL: сущности всегда кэшируются, даже если они помечены как некэшируемые.
4. NONE: ни одна сущность не кэшируется, даже если помечена как кэшируемая. При данной опции имеет смысл вообще отключить кэш второго уровня.
5. UNSPECIFIED: применяются значения по умолчанию для кэша второго уровня, определенные Hibernate. Это эквивалентно тому, что вообще не 
   используется shared-cache-mode, так как Hibernate не включает кэш второго уровня, если используется режим UNSPECIFIED.

На самом деле, хибернейт сам не реализует кеширование как таковое. А лишь предоставляет структуру для его реализации, поэтому подключить 
можно любую реализацию, которая соответствует спецификации нашего ORM фреймворка. 

Из популярных реализаций можна выделить следующие: EHCache, OSCache, SwarmCache.

## Расскажите_про_Стратегия_параллельного_доступа_к_объектам

Проблема заключается в том, что кэш второго уровня доступен из нескольких сессий сразу и несколько потоков программы могут одновременно 
в разных транзакциях работать с одним и тем же объектом. Следовательно надо как-то обеспечивать их одинаковым представлением этого объекта.
В Hibernate существует четыре стратегии одновременного доступа к объектам в кэше:

1. READ_ONLY: Используется только для сущностей, которые никогда не изменяются (будет выброшено исключение, если попытаться обновить такую 
   сущность). Очень просто и производительно. Подходит для некоторых статических данных, которые не меняются.
2. NONSTRICT_READ_WRITE: Кэш обновляется после совершения транзакции, которая изменила данные в БД и закоммитила их. Таким образом, строгая 
   согласованность не гарантируется, и существует небольшое временное окно между обновлением данных в БД и обновлением тех же данных в кэше,
   во время которого параллельная транзакция может получить из кэша устаревшие данные.
3. READ_WRITE: Эта стратегия гарантирует строгую согласованность, которую она достигает, используя «мягкие» блокировки: когда обновляется 
   кэшированная сущность, на нее накладывается мягкая блокировка, которая снимается после коммита транзакции. Все параллельные транзакции, 
   которые пытаются получить доступ к записям в кэше с наложенной мягкой блокировкой, не смогут их прочитать или записать и отправят запрос 
   в БД. Ehcache использует эту стратегию по умолчанию.
4. TRANSACTIONAL: полноценное разделение транзакций. Каждая сессия и каждая транзакция видят объекты, как если бы только они с ним работали
   последовательно одна транзакция за другой. Плата за это — блокировки и потеря производительности.

## Для_чего_нужна_аннотация_Cache

Это аннотация Hibernate, настраивающая тонкости кэширования объекта в кэше второго уровня Hibernate. @Cache принимает три параметра:
1. include - имеет по умолчанию значение all и означающий кэширование всего объекта. Второе возможное значение - non-lazy, запрещает 
   кэширование лениво загружаемых объектов. Кэш первого уровня не обращает внимания на эту директиву и всегда кэширует лениво загружаемые
   объекты.
2. region - позволяет задать имя региона кэша для хранения сущности. Регион можно представить как разные области кэша, имеющие разные 
   настройки на уровне реализации кэша. Например, можно было бы создать в конфигурации ehcache два региона, один с краткосрочным хранением 
   объектов, другой с долгосрочным и отправлять часто изменяющиеся объекты в первый регион, а все остальные - во второй. Ehcache по умолчанию
   создает регион для каждой сущности с именем класса этой сущности, соответственно в этом регионе хранятся только эти сущности. К примеру, 
   экземпляры Foo хранятся в Ehcache в кэше с именем “com.baeldung.hibernate.cache.model.Foo”.
3. usage - задаёт стратегию одновременного доступа к объектам.

Кэш второго уровня создается в области фабрики EntityManagerFactory и доступен для использования во всех EntityManager, которые создаются
с использованием этой конкретной фабрики. Это также означает, что после закрытия фабрики весь кэш, связанный с ним, умирает, а менеджер 
кэша также закрывается. Кроме того, это также означает, что если у вас есть два экземпляра фабрики, в вашем приложении будет два менеджера
кэша, и при доступе к кэшу, хранящемуся в физическом хранилище, вы можете получить непредсказуемые результаты, такие как пропадание кеша.

Всякий раз, когда сессия пытается загрузить объект, самое первое место, где он ищет кэшированную копию объекта в кэше первого уровня.
Если кэшированная копия объекта присутствует в кэше первого уровня, она возвращается как результат метода загрузки.
Если в кэше первого уровня нет кэшированной сущности, то для кэшированной сущности ищется кэш второго уровня.
Если кэш второго уровня имеет кэшированный объект, он возвращается как результат метода load(). Но перед возвратом объекта он также 
сохраняется в кэше первого уровня, так что при следующем вызове метода загрузки объект будет возвращен из самого кэша первого уровня, 
и больше не потребуется обращаться в кэш второго уровня.
Если объект не найден в кэше первого уровня и кэше второго уровня, то выполняется запрос к базе данных, и объект сохраняется на обоих 
уровнях кэша перед возвратом в качестве ответа метода load().
Кэш второго уровня проверяет себя для измененных объектов.
Если какой-либо пользователь или процесс вносят изменения непосредственно в базу данных, то само по себе кэширование второго уровня не
может обновляться до тех пор, пока не истечет время «timeToLiveSeconds» для этой области кэша. В этом случае хорошей идеей будет сделать 
недействительным весь кеш и позволить hibernate снова построить кэш.

## Для_чего_нужна_аннотация_Cacheable

@Cacheable - аннотация JPA, используется для указания того, должна ли сущность храниться в кэше второго уровня, в случае, если в файле 
persistence.xml (или в свойстве javax.persistence.sharedCache.mode конфигурационного файла) 
для элемента shared-cache-mode установлено одно из значений:

1. ENABLE_SELECTIVE: только сущности с аннотацией @Cacheable (равносильно значению по умолчанию @Cacheable(value=true)) будут сохраняться 
   в кэше второго уровня.
2. DISABLE_SELECTIVE: все сущности будут сохраняться в кэше второго уровня, за исключением сущностей, помеченных аннотацией 
   @Cacheable(value=false)как некэшируемые.
3. ALL: сущности всегда кэшируются, даже если они помечены как некэшируемые.
4. NONE: ни одна сущность не кэшируется, даже если помечена как кэшируемая. При данной опции имеет смысл вообще отключить кэш второго уровня.
5. UNSPECIFIED: применяются значения по умолчанию для кэша второго уровня, определенные Hibernate. Это эквивалентно тому, что вообще 
   не используется shared-cache-mode, так как Hibernate не включает кэш второго уровня, если используется режим UNSPECIFIED.

Аннотация @Cacheable размещается над классом сущности. Её действие распространяется на эту сущность и её наследников, если они не 
определили другое поведение

## Расскажите_про_Hibernate_proxy_lazy_load

Hibernate использует прокси объект для поддержки отложенной загрузки. Обычно при загрузке данных из таблицы Hibernate не загружает все 
отображенные (замаппинные) объекты. Как только вы ссылаетесь на дочерний объект или ищите объект с помощью геттера, если связанная сущность
не находиться в кэше сессии, то прокси код перейдет к базе данных для загрузки связанной сущности. Для этого используется javassist, чтобы
эффективно и динамически создавать реализации подклассов ваших entity объектов.

LAZY - не грузит связанные сущности, только при обращении
EAGER - грузит сразу все связанные сущности

## Расскажите_про_стратегии_кеширования

Hibernate поддерживает три уровня кеширования:
1. Кеш первого уровня (L1 Cache) – сессионный кеш, работает в рамках одной транзакции.
2. Кеш второго уровня (L2 Cache) – общий для всех сессий, требует явной настройки (Ehcache, Infinispan и др.).
3. Кеш запросов (Query Cache) – кеширует результаты запросов, но требует кеша второго уровня.

Hibernate поддерживает несколько стратегий для L2 Cache (определяются в @Cache аннотации или hibernate.cfg.xml):
- READ_ONLY – только для чтения (например, справочники). если данные никогда не меняются (например, страны, города).
- NONSTRICT_READ_WRITE – нестрогая запись, возможна рассинхронизация при конкурентном доступе.
- READ_WRITE – строгая запись с блокировками, гарантирует консистентность. если данные изменяются, но важно избегать "грязного" чтения.

## Стратегии_загрузки_объектов_в_Hibernate

1. Lazy Loading (ленивая загрузка)
   - Загружает данные только при первом обращении.
   - Используется по умолчанию для @ManyToMany, @OneToMany.
2. Eager Loading (жадная загрузка)
   - Загружает данные сразу вместе с родительским объектом.
   - Используется по умолчанию для @ManyToOne, @OneToOne.
3. Полужадные стратегии (оптимизации)
   - если нужно оптимизировать N+1.
     - Чтобы избежать N+1, применяют:
       - @BatchSize – загружает несколько proxy-объектов одним запросом.
       - FetchMode.SUBSELECT – заменяет N+1 на один подзапрос.
       - @Fetch(FetchMode.JOIN) – загружает через JOIN (но может давать дубли).
       - EntityGraph – динамическое управление загрузкой.

## Для_чего_нужна_аннотация_Basic

Basic — указывает на простейший тип маппинга данных на колонку таблицы базы данных. Также в параметрах аннотации можно указать fetch 
стратегию доступа к полю и является ли это поле обязательным или нет.

В широком смысле Hibernate разделяет типы на две группы:
1. Типы значений (Value types).
2. Типы сущностей (Entity types).

Типы сущностей Сущности из-за своего уникального идентификатора существуют независимо от других объектов, тогда как типы значений нет. 
Экземпляры сущностей соответствуют строкам в таблице базы данных и различаются между собой благодаря уникальным идентификаторам. Например, 
две сущности могут иметь абсолютно одинаковые значения полей, но имея разные идентификаторы (первичные ключи) они будут считаться разными,
в отличие от POJO, которые при наличии абсолютно одинаковых значений полей будут считаться равными (equals вернет true). Из-за требования 
к наличию уникального идентификатора, сущности существуют независимо и определяют свой собственный жизненный цикл.

Типы значений Это данные, которые не определяют свой собственный жизненный цикл. По сути, они принадлежат сущности (entity), которая 
определяет их жизненный цикл. С другой стороны, всё состояние объекта полностью состоит из типов значений. 

В свою очередь, типы значений подразделяются на три подкатегории:
1. Базовые типы (Basic types).
2. Встраиваемые типы (Embeddable types).
3. Типы коллекций (Collection types)

Базовый тип значений Соответствует одному столбцу в БД. Hibernate предоставляет ряд встроенных базовых типов, которые соответствуют 
естественным отображениям, рекомендованным спецификациями JDBC.

Аннотация @Basic определяет 2 атрибута:
1. optional - boolean (по умолчанию true) - определяет, может ли значение поля или свойства быть null. Игнорируется для примитивных типов. 
   Но если тип поля не примитивного типа, то при попытке сохранения сущности будет выброшено исключение.
2. fetch - FetchType (по умолчанию EAGER) - определяет, должен ли этот атрибут извлекаться незамедлительно (EAGER) или лениво (LAZY). 
   Однако, это необязательное требование JPA, и провайдерам разрешено незамедлительно загружать данные, даже для которых установлена 
   ленивая загрузка.

## Для_чего_нужна_аннотация_Access

Она определяет тип доступа (access type) для класса entity, суперкласса, embeddable или отдельных атрибутов, то есть как JPA будет 
обращаться к атрибутам entity, как к полям класса (FIELD) или как к свойствам класса (PROPERTY), имеющие гетеры (getter) и сетеры (setter).

Hibernate или другой провайдер должен каким-то образом получать доступ к полям сущности. Например, при сохранении сущности в базу 
данных Hibernate должен получить доступ к состоянию сущности, то есть прочитать значения полей сущности, чтобы записать их в 
соответствующие ячейки таблицы. Аналогично при получении данных из БД и формировании из них объекта сущности, Hibernate должен создать 
этот самый объект сущности (для этого ему и нужен public или protected конструктор без параметров), а затем записать в поля этого 
объекта значения, полученные из ячеек БД, тем самым сформировав состояние сущности.

Для чтения и записи этих полей Hibernate использует два подхода:

Field access (доступ по полям). При таком способе аннотации маппинга (Id, Column, OneToMany, … ) размещаются над полями, и Hibernate 
напрямую работает с полями сущности, читая и записывая их.
Property access (доступ по свойствам). При таком способе аннотации размещаются над методами-геттерами, но никак не над сеттерами. 
Hibernate использует их и сеттеры для чтения и записи полей сущности. Но есть требование - у сущности с property access названия 
методов должны соответствовать требованиям JavaBeans. Например, если у сущности Customer есть поле с именем firstName, то у этой 
сущности должны быть определены методы getFirstName и setFirstName для чтения и записи поля firstName.
Совокупность полей и методов (свойств) сущности называется атрибутами.

Эти два подхода неявно определяют тип доступа к состоянию конкретной сущности - либо доступ по полям либо доступ по свойствам. Но 
при неявном определении типа доступа JPA требует, чтобы у всех сущностей в иерархии был единый тип доступа.

По умолчанию тип доступа определяется местом, в котором находится аннотация @Id. Если она будет над полем - это будет AccessType.FIELD,
если над геттером - это AccessType.PROPERTY.

Чтобы явно определить тип доступа у сущности, нужно использовать аннотацию @Access, которая может быть указана у сущности, Mapped 
Superclass и Embeddable class, а также над полями или методами.

Аннотация @Access позволяет в иерархии сущностей с одним единым типом доступа безболезненно определить для одной или нескольких 
сущностей другой тип доступа. То есть в иерархии, где у всех тип доступа, например, field access, можно у какой-нибудь сущности указать 
тип доступа property access и это не нарушит работу Hibernate.

Если у сущности объявлена аннотация @Access(AccessType.FIELD):

значит аннотации маппинга нужно размещать над полями;
есть возможность у любых атрибутов сущности поменять тип доступа на property access, разместив аннотацию @Access(AccessType.PROPERTY) 
над соответствующими геттерами;
разместив аннотации маппинга над методами, не имеющими @Access(AccessType.PROPERTY), получим неопределенное поведение.
Если у сущности объявлена аннотация @Access(AccessType.PROPERTY):

значит аннотации маппинга нужно размещать над геттерами;
есть возможность у любых атрибутов сущности поменять тип доступа на field access, разместив аннотацию @Access(AccessType.FIELD) над 
соответствующими полями;
разместив аннотации маппинга над полями, не имеющими @Access(AccessType.FIELD), получим неопределенное поведение.
Поля, унаследованные от суперкласса, имеют тип доступа этого суперкласса, а не дочерней сущности, даже если они не совпадают.

Когда у одной сущности определены разные типы доступа, то нужно использовать аннотацию @Transient для избежания дублирования маппинга.

## Для_чего_нужны_аннотации_Embedded_и_Embeddable

@Embeddable Аннотация JPA, размещается над классом для указания того, что класс является встраиваемым в другие классы и будет внедрен 
другими сущностями, то есть поля этого встраиваемого класса будут добавляться к полям других сущностей и будут представлять столбцы в
таблице этой сущности. Так, во встраиваемый класс мы можем выделить общие поля для разных сущностей не создавая для него таблицу. 
Встраиваемый класс сам не является сущностью.

@Embedded Аннотация JPA, используется для размещения над полем в классе-сущности для указания того, что мы внедряем встраиваемый класс.

## Для_чего_нужны_аннотации_OrderBy_и_OrderColumn

1. @OrderBy
Аннотация @OrderBy указывает порядок, в соответствии с которым должны располагаться элементы коллекций сущностей, базовых или встраиваемых
типов при их извлечении из БД. Эта аннотация может использоваться с аннотациями @ElementCollection, @OneToMany, @ManyToMany.

2. @OrderColumn
Аннотация @OrderColumn создает столбец в таблице, который используется для поддержания постоянного порядка в списке, но этот столбец не 
считается частью состояния сущности или встраиваемого класса.
Hibernate отвечает за поддержание порядка как в базе данных при помощи столбца, так и при получении сущностей и элементов из БД. 
Hibernate отвечает за обновление порядка при записи в базу данных, чтобы отразить любое добавление, удаление или иное изменение порядка, 
влияющее на список в таблице.
Аннотация @OrderColumn может использоваться с аннотациями @ElementCollection, @OneToMany, @ManyToMany - указывается на стороне отношения,
ссылающегося на коллекцию, которая должна быть упорядочена

## Для_чего_нужны_callback_методы_в_JPA

Callback - это хуки (hooks), которые вызываются автоматически на определенных этапах жизненного цикла сущности (Entity). 
Они позволяют выполнять произвольную логику до или после ключевых событий, таких как:
- Сохранение (@PrePersist, @PostPersist)
- Обновление (@PreUpdate, @PostUpdate)
- Загрузка (@PostLoad)
- Удаление (@PreRemove, @PostRemove)

Callback-методы позволяют:
✅ Инкапсулировать логику внутри сущности (вместо вынесения в сервисы).
✅ Автоматизировать рутинные операции (даты, аудит, валидация).
✅ Реагировать на события ЖЦ без явного вызова (например, очистка кеша после удаления).
✅ Избегать дублирования кода (например, обновление updatedAt в одном месте).

## Какие_видов_блокировок_lock_описаны_в_спецификации_JPA

У JPA есть шесть видов блокировок, перечислим их в порядке увеличения надежности (от самого ненадежного и быстрого, до самого 
надежного и медленного):
1. NONE — без блокировки
2. OPTIMISTIC (или синоним READ, оставшийся от JPA 1) — оптимистическая блокировка,
3. OPTIMISTIC_FORCE_INCREMENT (или синоним WRITE, оставшийся от JPA 1) — оптимистическая блокировка с принудительным увеличением поля
   версионности,
4. PESSIMISTIC_READ — пессимистичная блокировка на чтение,
5. PESSIMISTIC_WRITE — пессимистичная блокировка на запись (и чтение),
6. PESSIMISTIC_FORCE_INCREMENT — пессимистичная блокировка на запись (и чтение) с принудительным увеличением поля версионности.

Оптимистичное блокирование предполагает, что параллельно выполняющиеся транзакции редко обращаются к одним и тем же данным и позволяет 
им спокойно и свободно выполнять любые чтения и обновления данных. Но при окончании транзакции производится проверка, изменились ли 
данные в ходе выполнения данной транзакции и, если да, транзакция обрывается и выбрасывается исключение.

JPA поддерживает два типа оптимистичной блокировки:
1. LockModeType.OPTIMISTIC — блокировка на чтение, которая работает, как описано выше: если при завершении транзакции кто-то извне изменит 
   поле @Version, то транзакция автоматически будет откачена и будет выброшено OptimisticLockException.
2. LockModeType.OPTIMISTIC_FORCE_INCREMENT — блокировка на запись. Ведёт себя как и блокировка на чтение, но при этом увеличивает значение 
   поля @Version.

Пессимистичное блокирование напротив, ориентирован на транзакции, которые постоянно или достаточно часто конкурируют за одни и те же 
данные и поэтому блокирует доступ к данным превентивно, в тот момент когда читает их. Другие транзакции останавливаются, когда пытаются
обратиться к заблокированным данным и ждут снятия блокировки (или кидают исключение). Пессимистичное блокирование выполняется на уровне 
базы и поэтому не требует вмешательств в код сущности. Так же, как и в случае с оптимистичным блокированием, поддерживаются блокировки
чтения и записи:

1. LockModeType.PESSIMISTIC_READ — данные блокируются в момент чтения и это гарантирует, что никто в ходе выполнения транзакции не сможет
их изменить. Остальные транзакции, тем не менее, смогут параллельно читать эти данные. Использование этой блокировки может вызывать 
долгое ожидание блокировки или даже выкидывание PessimisticLockException.

2. LockModeType.PESSIMISTIC_WRITE — данные блокируются в момент записи и никто с момента захвата блокировки не может в них писать и не 
может их читать до окончания транзакции, владеющей блокировкой. Использование этой блокировки может вызывать долгое ожидание блокировки.

3. Кроме того, для сущностей с полем, аннотированным @Version, существует третий вариант пессимистичной блокировки: 
LockModeType.PESSIMISTIC_FORCE_INCREMENT — ведёт себя как LockModeType.PESSIMISTIC_WRITE, но в конце транзакции увеличивает значение 
поля @Version, даже если фактически сущность не изменилась. Накладываются пессимистичные блокировки так же как и оптимистичные,
вызовом метода lock():

## Как_можно_изменить_настройки_fetch_стратегии_любых_атрибутов_Entity

Для этого существует EntityGraph API, используется он так: с помощью аннотации NamedEntityGraph для Entity, создаются именованные 
EntityGraph объекты, которые содержат список атрибутов у которых нужно поменять fetchType на EAGER, а потом данное имя указывается в 
hits запросов или метода find. В результате fetchType атрибутов Entity меняется, но только для этого запроса. Существует две стандартных 
property для указания EntityGraph в hit:
`
@NamedEntityGraphs({
@NamedEntityGraph(
name = 'customer.products',
attributeNodes = {
@NamedAttributeNode("products")
}   
)
})
@Entity
@Table(name = "customer")
`
1. javax.persistence.fetchgraph — все атрибуты перечисленные в EntityGraph меняют fetchType на EAGER, все остальные на LAZY
2. javax.persistence.loadgraph — все атрибуты перечисленные в EntityGraph меняют fetchType на EAGER, все остальные сохраняют свой fetchType
(то есть если у атрибута, не указанного в EntityGraph, fetchType был EAGER, то он и останется EAGER)С помощью NamedSubgraph можно также
изменить fetchType вложенных объектов Entity.

## Что_означает_полиморфизм_polymorphism_в_запросах_JPQL

В отличии от SQL в запросах JPQL есть автоматический полиморфизм, то есть каждый запрос к Entity возвращает не только объекты этого 
Entity, но так же объекты всех его классов-потомков, независимо от стратегии наследования (например, запрос select * from Animal, 
вернет не только объекты Animal, но и объекты классов Cat и Dog, которые унаследованы от Animal). Чтобы исключить такое поведение 
используется функция TYPE в where условии (например select * from Animal a where TYPE(a) IN (Animal, Cat) уже не вернет объекты класса Dog).

## Что_происходит_с_таблицами_при_изпользовании_mappedBy

В OneToOne без mappedBy хибер явно указывает двустороннюю связь. У Юзера есть колонка с Машинами, у каждой машины есть колонка 
с Юзером. В итоге если у одного юзера 3 машины, но будут сохраненны 3 строчки разных машин у которых будет одинаковый Юзер.

При использовании mappedBy, у Машин не будет столбца Юзер, т.к. у каджого Юзера и так указываются Id Машин. Если нужно обратиться к
конкретной машине, обращение к ней идет через юзера.

При других видах связи, без использования mappedBy хибер создаёт смежную таблицу, в которой связывает значениях таблиц. Что ухудшает
производительность.

При использовании mappedBy смежных таблиц нет, т.к. хибер уже точно значет кто на что ссылается.

## FetchType_стратегии_по_умолчанию

В JPA описаны два типа fetch-стратегии:
1. LAZY — данные поля сущности будут загружены только во время первого обращения к этому полю.
2. EAGER — данные поля будут загружены немедленно вместе с сущностью.

FetchType.EAGER: Hibernate должен сразу загрузить соответствующее аннотированное поле или свойство. Это поведение по умолчанию для полей, 
аннотированных @Basic, @ManyToOne и @OneToOne (все что быстро).

FetchType.LAZY: Hibernate может загружать данные не сразу, а при первом обращении к ним, но так как это необязательное требование, то 
Hibernate имеет право изменить это поведение и загружать их сразу. Это поведение по умолчанию для полей, аннотированных @OneToMany, 
@ManyToMany и @ElementCollection (все что медленно).

## Как_мапятся_даты_до_Java_8_и_после

При работе с датами рекомендуется установить определенный часовой пояс для драйвера JDBC. Таким образом, наше приложение будет 
независимым от текущего часового пояса системы.

Другой способ - настроить свойство hibernate.jdbc.time_zone в файле свойств Hibernate, который используется для создания фабрики сессий. 
Таким образом, мы можем указать часовой пояс один раз для всего приложения.

java.sql Hibernate позволяет отображать различные классы даты/времени из Java в таблицах баз данных. Стандарт SQL определяет три типа 
даты/времени:
DATE - Представляет календарную дату путем хранения лет, месяцев и дней. Эквивалентом JDBC является java.sql.Date.
TIME - Представляет время дня и хранит часы, минуты и секунды. Эквивалентом JDBC является java.sql.Time.
TIMESTAMP - Хранит как DATE, так и TIME плюс наносекунды. Эквивалентом JDBC является java.sql.Timestamp. 
Поскольку эти типы соответствуют SQL, их сопоставление относительно простое.

java.util Точность представления времени составляет одну миллисекунду. Для большинства практических задач этого более чем достаточно, 
но иногда хочется иметь точность повыше.

Поскольку классы в данном API изменяемые (не immutable), использовать их в многопоточной среде нужно с осторожностью. В частности 
java.util.Date можно признать «эффективно» потоко-безопасным, если вы не вызываете у него устаревшие методы.

java.util.Date Тип java.util.Date содержит информацию о дате и времени с точностью до миллисекунд. Но так как классы из этого пакета 
не имели прямого соответствия типам данных SQL, приходилось использовать над полями java.util.Date аннотацию @Temporal, чтобы дать
понять SQL, с каким конкретно типом данных она работает. Для этого у аннотации @Temporal нужно было указать параметр TemporalType, 
который принимал одно из трёх значений: DATE, TIME или TIMESTAMP, что позволяло указать базе данных с какими конкретными типами данных 
она работает.

java.util.Calendar Как и в случае java.util.Date, тип java.util.Calendar может быть сопоставлен с различными типами SQL, поэтому мы 
должны указать их с помощью @Temporal. Разница лишь в том, что Hibernate не поддерживает отображение (маппинг) Calendar на TIME

java.time Начиная с Java 8, доступен новый API даты и времени для работы с временными значениями. Этот API-интерфейс устраняет многие
проблемы классов java.util.Date и java.util.Calendar. Все классы в новом API неизменяемые (immutable) и, как следствие, потоко-безопасные.
Точность представления времени составляет одну наносекунду, что в миллион раз точнее чем в пакете java.util. Типы данных из пакета 
java.time напрямую отображаются (маппятся) на соответствующие типы SQL.

## Для_чего_необходим_PersistenceContext

PersistenceContext — это контейнер (или "кэш первого уровня"), который управляет жизненным циклом сущностей (Entity) в рамках одной 
транзакции или сессии. Он отслеживает изменения сущностей и синхронизирует их с базой данных.

Основные функции PersistenceContext:
- Отслеживание изменений сущностей (Dirty Checking)
- Гарантия уникальности объекта (в рамках одного PersistenceContext)
- Оптимизация запросов к БД (автоматическая синхронизация при flush)
- Управление транзакционностью (поддержка @Transactional)

Типы PersistenceContext в JPA:
1. Transaction-scoped (по умолчанию) – живет только во время транзакции.
2. Extended-scoped – существует дольше (например, в Stateful EJB).

## Что_такое_Entity_graph

EntityGraph (граф сущностей) - механизм динамического изменения fetchType для каждого запроса. Используя аннотации можно описать то,
что будем выбирать из базы. Граф применяется на уровне SQL запроса, таким образом “лишние” данные не выбираются в Java приложение. 
Но есть одна небольшая проблема: нельзя сказать, какие атрибуты были выбраны, а какие — нет. Для проверки есть API, это делается при
помощи класса PersistenceUtil.

JPA определяет два свойства или подсказки, с помощью которых Hibernate может выбирать стратегию извлечения графа сущностей во 
время выполнения:
1. fetchgraph - из базы данных извлекаются только указанные в графе атрибуты. Поскольку мы используем Hibernate, мы можем заметить, 
что в отличие от спецификаций JPA, атрибуты, статически настроенные как EAGER, также загружаются.
2. loadgraph - в дополнение к указанным в графе атрибутам, также извлекаются атрибуты, статически настроенные как EAGER. В любом случае, 
первичный ключ и версия, если таковые имеются, всегда загружаются.

## Проблема_n_1_select_и_как_ее_решить

При загрузке сущностей с ленивыми (LAZY) ассоциациями Hibernate выполняет:
- 1 запрос для загрузки основной сущности (например, User).
- N запросов для загрузки связанных данных (например, Order для каждого User).

Подробнее:
Есть User и которого есть коллекция машин Cars. Если мы хотим получить список из 10 юзеров, то в бд полетит 11 запросов. 
1 запрос на получение самих юзеров и еще 10 запросов на получение списка их машин, отдельно для каждого User. Это приводит к
серьёзным проблемам с производительностью.

Способы решения проблемы:
1. JOIN FETCH
   Суть: Загрузка связанных данных одним запросом через JOIN.
   Когда использовать: Когда точно знаете, что связанные данные нужны сразу.
2. EntityGraph
   Суть: Динамическое определение графа загрузки (аналог JOIN FETCH).
   Не самое изящное решение для n+1 проблемы. Графы в основном нужны, когда требуется загрузить действительно большой детальный граф,
   т.е. когда нам нужно получить очень много связанной информации из базы, и такой большой запрос следует оптимизировать. Для n+1 не
   самое компактное решение, но тоже работает, однако такое решение не подойдет при использовании нативных запросов.
3. @BatchSize (ленивая загрузка батчами)
   Суть: Замена N+1 на WHERE id IN (?, ?, ...).
   Hibernate загружает orders не по одному, а пачками (например, по 50 пользователей за раз).
4. FetchMode.SUBSELECT
   Суть: Замена N+1 на подзапрос
   Хорошо для загрузки всех связанных данных.
   Неэффективно при пагинации.

## Как_создать_составной_ключ

Первый метод использования составного ключа включает класс ключа целиком в класс сущности: @EmbeddedId указывает на поле составного 
первичного ключа, а @Embeddable объявляет класс составным ключом.
Второй вариант использования оставляет поля первичного ключа непосредственно в классе сущности, а класс составного ключа служит лишь 
для поддержки: @IdClass(Passport.PassportKey.class)
@IdClass Допустим, у нас есть таблица с именем Account, и она имеет два столбца - accountNumber и accountType, которые формируют 
составной ключ. Чтобы обозначить оба этих поля как части составного ключа мы должны создать класс, например, AccountId с этими полями

## ElementCollection_Как_сохранять_в_БД_коллекции_базовых_типов

ElementCollection - стандартная аннотация JPA, означает, что коллекция не является совокупностью объектов, а представляет собой набор 
простых типов (строки и т.д.) или набор встраиваемых элементов (класс, аннотированный с помощью @Embeddable).

Это также означает, что элементы полностью принадлежат содержащим объектам: они изменяются, когда объект изменяется, удаляется при 
удалении объекта и т.д. Они не могут иметь свой собственный жизненный цикл.

@ElementCollection указывается в классе сущности над полем коллекции базовых или встраиваемых типов. Все записи коллекции хранятся в
отдельной таблице, то есть в итоге получаем две таблицы: одну для сущности, вторую для коллекции элементов. Конфигурация для таблицы
коллекции элементов указывается с помощью аннотации @CollectionTable, которая используется для указания имени таблицы коллекции и 
JoinColumn, который ссылается на первичную таблицу.

Аннотация @ElementCollection похожа на отношение @OneToMany, за исключением того, что целью являются базовые и встраиваемые типы, 
а не сущности. Можно использовать аннотации @AttributeOverrides и @AttributeOverride для настройки отображения в таблице полей 
базовых или встраиваемых типов.

Коллекции могут иметь тип java.util.Map, которые состоят из ключа и значения. Для этого типа коллекций применяются следующие правила:

Ключ или значение Map может быть базовым типом языка программирования Java, встраиваемым классом или сущностью.
Если значение Map является встраиваемым классом или базовым типом, используйте аннотацию @ElementCollection. Пример.
Если значение Map является сущностью, используйте аннотацию @OneToMany или @ManyToMany. Пример.
Использовать тип Map только на одной стороне двунаправленной связи.
Аннотация @MapKeyColumn позволяет настроить столбец «ключ» в таблице Map. Аннотация @Column позволяет настроить столбец «значение» в 
таблице Map.

Использование коллекций элементов имеет один большой недостаток:элементы коллекции не имеют идентификатора, и Hibernate не может 
обращаться индивидуально к каждому элементу коллекции. Когда мы добавляем новый объект в коллекцию или удаляем из коллекции существующий 
элемент, Hibernate удаляет все строки из таблицы элементов и вставляет новые строки по одной для каждого элемента в коллекции. То есть 
при добавлении одного элемента в коллекцио Hibernate не добавит одну строку в таблицу коллекции, а очистит её и заполнит по новой всеми
элементами.

Поэтому коллекции элементов следует использовать только для очень маленьких коллекций, чтобы Hibernate не выполнял слишком много 
операторов SQL. Во всех других случаях рекомендуется использовать коллекции сущностей с @OneToMany.

## Метод_unWrap

JPA обеспечивает легкий доступ к API базовых реализаций. EntityManager и EntityManagerFactory обеспечивают разворачивают метод, 
который возвращает соответствующие классы реализации JPA. В случае Hibernate это Session и SessionFactory.
`
Session session = em.unwrap(Session.class); SessionFactory sessionFactory = em.getEntityManagerFactory().unwrap(SessionFactory.class);
`
В первой строке я получаю текущий сеанс Hibernate от EntityManager . Поэтому я называю UnWrap метод на EntityManager и обеспечить 
сеанс класса в качестве параметра. Вторая строка выглядит очень похоже. Я получаю EntityManagerFactory для текущего EntityManager 
и вызываю метод unwrap специфичный для Hibernate класс SessionFactory.

## Что_такое_UNION_и_UNION_ALL

UNION и UNION ALL — это операторы SQL, которые объединяют результаты двух и более запросов в одну таблицу.
1. UNION:
- Объединяет результаты, удаляя дубликаты.
- Требует сортировки данных, поэтому работает медленнее, чем UNION ALL.

2. UNION ALL:
- Объединяет результаты без удаления дубликатов.
- Работает быстрее, так как не выполняет дедупликацию.

## Что_такое_SUBQUERY

Subquery (подзапрос) - это SQL-запрос, вложенный внутри другого SQL-запроса. Подзапросы могут использоваться в различных частях основного 
запроса: SELECT, FROM, WHERE, HAVING и т.д.
SELECT * FROM products WHERE price > (SELECT AVG(price) FROM products)

Основные типы подзапросов:
1. По месту использования:
   - WHERE/HAVING: SELECT * FROM users WHERE age > (SELECT AVG(age) FROM users)
   - FROM: SELECT * FROM (SELECT name, age FROM users) AS temp_table
   - SELECT: SELECT name, (SELECT COUNT(*) FROM orders WHERE orders.user_id = users.id) FROM users
2. По возвращаемому значению:
   - Скалярные (возвращают одно значение)
   - Строковые (возвращают одну строку)
   - Табличные (возвращают таблицу)


## Что_такое_коррелирующий_запрос

Коррелирующий подзапрос — это вложенный SQL-запрос, который:
1. Использует значения из внешнего запроса (т.е. зависит от него).
2. Выполняется для каждой строки внешнего запроса.
3. Часто встречается в WHERE, SELECT или HAVING условиях.
`SELECT e.name, e.department
FROM employees e
WHERE e.salary > (
    SELECT AVG(s.salary) 
    FROM salaries s 
    WHERE s.department = e.department  -- Вот эта ссылка на внешний запрос делает подзапрос коррелирующим!
);`
Минусы:
- Коррелирующие подзапросы могут быть медленными, потому что:
    - Выполняются для каждой строки внешнего запроса. 
    - Плохо оптимизируются в некоторых СУБД.
Решение:
- Замена на JOIN + GROUP BY (если возможно).
- Использование оконных функций (OVER PARTITION BY).

## Что_такое_нормализация

Нормализация — это процесс организации данных в реляционной базе для:
- Устранения дублирования данных
- Минимизации аномалий при вставке/обновлении/удалении
- Создания логичной и эффективной структуры таблиц

1НФ (Первая нормальная форма):
  - Все атрибуты атомарны (неделимы)
  - Нет повторяющихся групп данных
  - Пример нарушения: поле "Телефоны" со значением "123, 456"
2НФ (Вторая нормальная форма):
  - Уже соответствует 1НФ
  - Все неключевые атрибуты зависят от всего первичного ключа (а не от его части)
  - Пример нарушения: в таблице "Заказ-Товар" с PK (order_id, product_id) хранится product_name (зависит только от product_id)
3НФ (Третья нормальная форма):
  - Уже соответствует 2НФ
  - Нет транзитивных зависимостей (неключевые атрибуты не зависят от других неключевых атрибутов)
  - Пример нарушения: в таблице "Заказы" хранится customer_phone, который зависит от customer_id, а не напрямую от order_id

## Какие_виды_нормализации_бывают_в_SQL

1НФ (Первая нормальная форма):
- Все атрибуты атомарны (неделимы)
- Нет повторяющихся групп данных
- Пример нарушения: поле "Телефоны" со значением "123, 456"
  2НФ (Вторая нормальная форма):
- Уже соответствует 1НФ
- Все неключевые атрибуты зависят от всего первичного ключа (а не от его части)
- Пример нарушения: в таблице "Заказ-Товар" с PK (order_id, product_id) хранится product_name (зависит только от product_id)
  3НФ (Третья нормальная форма):
- Уже соответствует 2НФ
- Нет транзитивных зависимостей (неключевые атрибуты не зависят от других неключевых атрибутов)
- Пример нарушения: в таблице "Заказы" хранится customer_phone, который зависит от customer_id, а не напрямую от order_id

## Что_такое_индекс_и_какие_виды_индексов_существуют

Индекс — это специальная структура данных в БД, которая:
- Ускоряет поиск и сортировку данных
- Работает подобно оглавлению в книге
- Создается по одному или нескольким столбцам таблицы

Основные типы индексов:
1. B-дерево (B-tree)
   - Поддерживает операции: =, >, <, BETWEEN, LIKE 'pattern%'
2. Хеш-индекс
   - Только для точного совпадения (=)
   - Быстрее B-tree для равенства, но не поддерживает диапазоны
3. Составной (композитный) индекс
   - По нескольким столбцам
4. Уникальный индекс
   - Автоматически создается для PRIMARY KEY
5. Полнотекстовый индекс
   - Для полнотекстового поиска 
   - Поддерживает сложные поисковые запросы

## Какой_вид_индекса_использовать_для_какого_типа_запросов

1. B-Tree (Balanced Tree) – стандартный индекс
   Когда использовать:
     - Для равенства (=, IN).
     - Для диапазонов (>, <, BETWEEN).
     - Для сортировки (ORDER BY).
     - Для частичного поиска (если индекс покрывает префикс, например, LIKE 'abc%').
2. Hash-индекс
   Когда использовать:
     - Только для точечных запросов (=, IN).
     - Не подходит для диапазонов, сортировки или LIKE '%text'.
     - Быстрее B-Tree для точных совпадений, но не во всех СУБД (в PostgreSQL и MySQL InnoDB он используется только для отдельных типов данных).
3. Bitmap-индекс
   Когда использовать:
     - Для низкокардинальных столбцов (мало уникальных значений, например, gender, status).
     - Эффективен для AND/OR условий.
     - Используется в OLAP-системах (реже в OLTP).
4. Full-Text индекс (Inverted Index)
   Когда использовать:
     - Для полнотекстового поиска (MATCH AGAINST, LIKE '%text%').
     - Оптимизирован для поиска по словам, фразам, релевантности.
5. Composite (Составной) индекс
   Когда использовать:
     - Для запросов с несколькими условиями.
     - Порядок столбцов важен: сначала высококардинальные (уникальные) столбцы.
6. Covering Index (Покрывающий индекс)
   Когда использовать:
     - Если индекс включает все поля запроса (SELECT + WHERE), то не требуется обращение к таблице.

## Как_создать_триггер_в_SQL

Триггеры создаются для автоматического выполнения кода при изменении данных. Например, можно сделать триггер для логирования изменений в таблице users. 
В PostgreSQL синтаксис будет таким: сначала создаем функцию с логикой, затем сам триггер, который вызывает эту функцию при INSERT/UPDATE/DELETE. 
Важно учитывать, что триггеры добавляют накладные расходы, и иногда их логику лучше перенести в приложение или использовать ограничения (CONSTRAINTS).
`CREATE TRIGGER trigger_name
[BEFORE | AFTER] [INSERT | UPDATE | DELETE] ON table_name
[FOR EACH ROW | FOR EACH STATEMENT]
[WHEN (condition)]
EXECUTE FUNCTION trigger_function(); -- в PostgreSQL
-- или
BEGIN
    -- логика триггера (для MySQL)
END;`
Типы триггеров: BEFORE (проверка/изменение данных перед операцией) и AFTER (логирование/аудит после операции).
Уровень срабатывания: FOR EACH ROW (для каждой строки) или FOR EACH STATEMENT (один раз на запрос).
Доступ к данным: OLD (старые значения) и NEW (новые значения).

## Что_такое_ограничения_constraints_и_какие_они_бывают

Ограничения (constraints) в SQL - это ограничения, которые обеспечивают целостность данных. 
Основные типы: 
- PRIMARY KEY для уникальной идентификации записей, 
- FOREIGN KEY для связей между таблицами, 
- UNIQUE для уникальности значений, 
- NOT NULL для запрета пустых значений, 
- CHECK для проверки условий 
- DEFAULT для значений по умолчанию. 

Например, PRIMARY KEY автоматически создает кластерный индекс, что ускоряет поиск, 
а FOREIGN KEY гарантирует, что мы не сможем добавить запись со ссылкой на несуществующую строку в другой таблице. 
В enterprise-приложениях constraints особенно важны, так как предотвращают попадание некорректных данных в базу, 
даже если в приложении есть ошибки валидации.

## Как_создать_таблицу_с_ограничениями

Для создания таблицы с ограничениями в SQL используется команда CREATE TABLE с указанием необходимых constraints. 
Ограничения можно задавать как на уровне столбцов, так и на уровне всей таблицы.
Типы ограничений:
PRIMARY KEY - первичный ключ
FOREIGN KEY - внешний ключ
UNIQUE - уникальное значение
NOT NULL - запрет NULL значений
CHECK - проверка условия
DEFAULT - значение по умолчанию

## Что_такое_хранимая_процедура_и_как_ее_создать

Хранимая процедура (Stored Procedure) — это предварительно скомпилированный набор SQL-инструкций, хранящийся в базе данных. Она выполняет определенную логику, 
может принимать параметры и возвращать результаты.

Отличие от функции: Процедура не возвращает значение (но может изменять данные или возвращать результат через OUT-параметры/курсоры).
Транзакции: Процедуры могут содержать транзакции (BEGIN TRANSACTION, COMMIT).
Обработка исключений: Блоки TRY-CATCH в T-SQL (SQL Server) или EXCEPTION в PL/pgSQL (PostgreSQL).
Оптимизация: Хранимые процедуры кэшируются СУБД, что ускоряет выполнение.

`CREATE OR REPLACE PROCEDURE update_salary(emp_id INT, increase_amount DECIMAL)
LANGUAGE SQL
AS $$
    UPDATE employees SET salary = salary + increase_amount WHERE id = emp_id;
$$;`

## Что_такое_функция_и_как_ее_создать

Функция (Stored Function) — это именованный блок кода в СУБД, который выполняет вычисления и возвращает одно значение.
В отличие от процедуры, функция:
- Всегда имеет возвращаемое значение (через RETURN).
- Может использоваться в SQL-запросах (например, в SELECT, WHERE).
- Не может изменять данные (в большинстве СУБД, кроме PostgreSQL, где есть функции с модификатором VOLATILE).

`CREATE OR REPLACE FUNCTION get_employee_name(emp_id INT) 
RETURNS VARCHAR AS $$
DECLARE
    emp_name VARCHAR;
BEGIN
    SELECT name INTO emp_name FROM employees WHERE id = emp_id;
    RETURN emp_name;
END;
$$ LANGUAGE plpgsql;`

## Как_работать_с_датами_в_POSTGRESQL

В PostgreSQL есть несколько типов для работы с датами и временем:
- DATE — только дата (например, '2024-05-20').
- TIME — только время (например, '14:30:00').
- TIMESTAMP — дата и время без временной зоны (например, '2024-05-20 14:30:00').
- TIMESTAMPTZ (timestamp with time zone) — дата и время с учётом временной зоны.
- INTERVAL — интервал времени (например, '2 days' или '1 month').

Преобразование строки в дату:
- SELECT TO_DATE('20-05-2024', 'DD-MM-YYYY') AS date;
Преобразование даты в строку:
- SELECT TO_CHAR(NOW(), 'DD/MM/YYYY HH24:MI:SS') AS formatted_date;

## Что_такое_оператор_CASE

CASE — это условный оператор SQL, похожий на switch или if-else в Java. Он позволяет менять данные на лету в SELECT, фильтровать в WHERE и даже управлять 
сортировкой. Например, можно классифицировать пользователей по возрасту или товары по цене. Но если логика слишком сложная, лучше обрабатывать данные в 
Java, чтобы не усложнять SQL-запрос.
`SELECT 
    product_name,
    CASE category_id
        WHEN 1 THEN 'Electronics'
        WHEN 2 THEN 'Clothing'
        WHEN 3 THEN 'Food'
        ELSE 'Other'
    END AS category_name
FROM products;`

## Что_такое_оператор_COALESCE

COALESCE — это стандартный SQL-оператор, который возвращает первое ненулевое значение из списка аргументов. Если все аргументы NULL, возвращает NULL.
`SELECT name, COALESCE(phone_number, 'N/A') AS phone FROM users;`

## Что_такое_агрегатные_функции_и_какие_они_бывают

Агрегатные функции — это функции SQL, которые выполняют вычисления над набором строк и возвращают одно результирующее значение. Они используются 
в сочетании с GROUP BY для группировки данных или без него для расчёта общих статистик.

COUNT()	Подсчитывает количество строк (или не-NULL значений в колонке).	SELECT COUNT(*) FROM users;
SUM()	Суммирует значения в колонке (только для чисел).	SELECT SUM(salary) FROM employees;
AVG()	Вычисляет среднее арифметическое (для числовых данных).	SELECT AVG(rating) FROM products;
MIN()	Находит минимальное значение.	SELECT MIN(price) FROM orders;
MAX() Находит максимальное значение.

Чем COUNT(*) отличается от COUNT(column)?
COUNT(*) считает все строки, COUNT(column) — только не-NULL значения.
Как работает GROUP BY с агрегатными функциями?
Группирует данные по указанным колонкам, затем применяет функцию к каждой группе.
Когда использовать HAVING, а когда WHERE?
WHERE фильтрует строки до группировки, HAVING — после.


## Что_такое_инструкция_TRUNCATE

TRUNCATE — это команда для быстрого удаления всех данных из таблицы без удаления её структуры. Она работает быстрее, чем DELETE, 
но не поддерживает условия WHERE и не активирует триггеры.

Работает быстрее, чем DELETE, потому что:
- Не записывает удаляемые строки в журнал транзакций (в большинстве СУБД).
- Не активирует триггеры ON DELETE.
- Не проверяет ограничения FOREIGN KEY (если не указано CASCADE).

Ограничения:
- Нельзя использовать с WHERE (в отличие от DELETE).
- Требует прав DROP на таблицу (в некоторых СУБД).

## В_чем_разница_между_инструкцией_DELETE_и_TRUNCATE

delete удаляет одну запись и можно использовать с Where
truncate удаляет всю таблицу нельзя использовать с Where

## Что_такое_ключевое_слово_OFFSET

OFFSET — это ключевое слово в SQL (включая PostgreSQL), которое пропускает указанное количество строк перед началом выборки данных. 
Оно используется вместе с LIMIT для постраничного вывода (пагинации).

LIMIT 10 OFFSET 20 означает: "Пропусти первые 20 записей и верни следующие 10".

## Что_такое_GROUP_CONCAT

GROUP_CONCAT - это функция в MySQL для объединения значений строк в группе
В PostgreSQL для этого есть:
- STRING_AGG(expression, delimiter) - основной аналог
- array_agg() + array_to_string() - альтернативный вариант

## Что_такое_аналитические_функции

Аналитические функции (window functions) в SQL - это функции, которые выполняют вычисления над набором строк, 
связанных с текущей строкой, без сворачивания результатов в одну строку (в отличие от агрегатных функций).

Ключевые особенности аналитических функций:
- Они работают с окном (window) данных - определённым набором строк относительно текущей
- Не группируют результат, сохраняя все исходные строки
- Используют синтаксис с OVER() для определения окна

Основные типы аналитических функций:
- Ранжирующие: ROW_NUMBER(), RANK(), DENSE_RANK()
- Агрегатные: SUM(), AVG(), COUNT() с OVER()
- Функции смещения: LAG(), LEAD(), FIRST_VALUE(), LAST_VALUE()
- Функции распределения: NTILE(), PERCENT_RANK(), CUME_DIST()


## Какие_аналитические_функции_поддерживает_SQL

Основные типы аналитических функций:
- Ранжирующие: ROW_NUMBER(), RANK(), DENSE_RANK()
- Агрегатные: SUM(), AVG(), COUNT() с OVER()
- Функции смещения: LAG(), LEAD(), FIRST_VALUE(), LAST_VALUE()
- Функции распределения: NTILE(), PERCENT_RANK(), CUME_DIST()

## Как_использовать_операторы_BETWEEN_и_IN_в_SQL

Операторы BETWEEN и IN в SQL используются для фильтрации данных в условиях WHERE

Оператор BETWEEN
Позволяет выбирать значения из определенного диапазона (включительно) 
`SELECT * FROM employees WHERE salary BETWEEN 50000 AND 100000;`

Оператор IN
Позволяет проверить вхождение значения в список:
`SELECT * FROM employees WHERE department_id IN (10, 20, 30);`

## Как_работать_с_несколькими_таблицами_в_одном_запросе

1. JOIN-операции (основной инструмент)
   - INNER JOIN - только совпадающие строки
   - LEFT JOIN - все строки из левой таблицы + совпадения справа
   - RIGHT JOIN - все строки из правой таблицы + совпадения слева
   - FULL JOIN - все строки из обеих таблиц
   - CROSS JOIN - декартово произведение (все со всеми)
2. Подзапросы (Subqueries)
   - `SELECT name FROM employees WHERE department_id IN (SELECT id FROM departments WHERE location = 'New York')`
3. Объединение результатов (UNION, INTERSECT, EXCEPT)
   - `SELECT product_name FROM current_products UNION SELECT product_name FROM discontinued_products`

## Как_работать_с_динамическими_запросами_в_SQL

Динамические SQL-запросы — это запросы, которые формируются во время выполнения программы в зависимости от условий и входных параметров. 
В Java-разработке мы используем несколько подходов для работы с ними:

## Какие_виды_ограничений_можно_использовать_в_SQL

Основные виды ограничений
1. PRIMARY KEY (Первичный ключ).
2. FOREIGN KEY (Внешний ключ).
3. UNIQUE (Уникальное ограничение)
4. NOT NULL (Запрет NULL значений)

## Как_работать_с_индексами_в_SQL

Индексы в SQL - это специальные структуры данных, которые ускоряют операции поиска в таблицах базы данных.
Когда использовать индексы
1. Рекомендуется:
- Для столбцов в условиях WHERE
- Для столбцов в JOIN
- Для столбцов в ORDER BY
- Для первичных и внешних ключей

2. Не рекомендуется:
- Для часто изменяемых данных
- Для таблиц с небольшим объемом данных
- Для столбцов с низкой селективностью (например, пол "М/Ж")

## Что_такое_кластеризованный_и_некластеризованный_индекс

Кластеризованный индекс — это физическое упорядочивание данных в таблице (только один на таблицу).
Некластеризованный индекс — отдельная структура, хранящая ключи и ссылки на данные (много на таблицу).

Ключевые отличия:
✅ Кластеризованный (PK в большинстве СУБД):
- Данные хранятся в порядке индекса → быстрый поиск по диапазону (BETWEEN, ORDER BY)
- Вставка/обновление медленнее (данные физически перестраиваются)

✅ Некластеризованный (доп. индексы):
- Работает как "указатель" на данные → ускоряет WHERE, JOIN по не-PK полям
- Занимает доп. память, но не влияет на физический порядок данных

Оптимизация:
Кластеризованный → для частых запросов по ID или диапазонам
Некластеризованный → для поиска по email, status и т.д.

Кластеризованный индекс (Clustered Index)
Основные характеристики:
- Определяет физический порядок хранения данных в таблице
- Таблица может иметь только один кластеризованный индекс
- Данные в таблице фактически хранятся в виде B-дерева индекса
- Обычно создается на первичном ключе (но не обязательно)
`CREATE TABLE employees (id INT PRIMARY KEY CLUSTERED,  -- кластеризованный индекс name VARCHAR(100));`

Некластеризованный индекс (Non-Clustered Index)
Основные характеристики:
- Отдельная структура от данных, содержащая указатели на физические строки
- Таблица может иметь множество некластеризованных индексов
- Работает как оглавление книги - содержит указатели на страницы
- Требует дополнительного места для хранения
`CREATE INDEX idx_employee_name ON employees(name);  -- некластеризованный`

## Какие_операторы_логических_связок_AND_OR_NOT_существуют_в_SQL

AND – одновременное выполнение всех условий
`SELECT * FROM users WHERE active = true AND age > 18;`
OR – выполнение хотя бы одного условия
`SELECT * FROM products WHERE category = 'Electronics' OR price < 100;`
NOT – отрицание условия
`SELECT * FROM orders WHERE NOT status = 'Cancelled';`

## Что_такое_подзапросы_и_как_они_работают_в_SQL

Подзапрос (Subquery) — это SQL-запрос, вложенный в другой запрос. Работает как временная таблица для фильтрации, вычислений или соединений.
Основные типы подзапросов:
1. В WHERE (как условие)
2. В FROM (как временная таблица)
   `SELECT dept.name, emp_stats.avg_salary FROM departments dept JOIN (
    SELECT department_id, AVG(salary) as avg_salary FROM employees GROUP BY department_id
    ) emp_stats ON dept.id = emp_stats.department_id;`
3. В SELECT (как вычисляемое поле)
   `SELECT name, (SELECT COUNT(*) FROM orders WHERE orders.user_id = users.id) as order_count FROM users;`

Производительность: Коррелированные подзапросы могут быть медленными (выполняются для каждой строки)
Альтернативы: Часто лучше использовать JOIN или CTE (WITH)
Ограничения:
- В MySQL нельзя использовать подзапрос в LIMIT
- В Hibernate подзапросы в SELECT требуют DTO-проекций

## Какие_виды_функций_агрегации_существуют_в_SQL

Агрегатные функции в SQL — это функции, которые выполняют вычисления над набором строк и возвращают единственное значение. 
Они используются в сочетании с GROUP BY для групповой обработки данных.

COUNT()	Подсчёт количества строк
SUM()	Сумма значений
AVG()	Среднее значение
MIN()	Минимальное значение
MAX()	Максимальное значение

## Как_использовать_операторы_IN_и_NOT_IN_в_SQL

Операторы IN и NOT IN в SQL используются для фильтрации данных по набору значений. Они особенно полезны при работе с динамическими условиями в Java-приложениях.
Для подзапросов иногда лучше EXISTS/NOT EXISTS или JOIN.
`SELECT * FROM users WHERE id NOT IN (SELECT user_id FROM banned_users);`
⚠️ Если banned_users.user_id содержит NULL, запрос вернет 0 строк!
Решение: Использовать NOT EXISTS или LEFT JOIN ... WHERE IS NULL.

## Что_такое_оконные_функции_и_как_они_работают_в_SQL

Оконные функции — это мощный инструмент SQL для выполнения вычислений над набором строк, связанных с текущей строкой, 
без группировки результата. В отличие от агрегатных функций, они сохраняют все исходные строки.
Типы оконных функций:
1. Агрегатные (без изменения синтаксиса)
   `SELECT product_id, price, AVG(price) OVER (PARTITION BY category_id) AS avg_category_price FROM products;`
2. Ранжирующие
3. Смещения
   `SELECT date, revenue, LAG(revenue, 1) OVER (ORDER BY date) AS prev_day_revenue, LEAD(revenue, 1) OVER (ORDER BY date) AS next_day_revenue FROM sales;`
4. Аналитические
   `SELECT employee_id, salary,
    FIRST_VALUE(salary) OVER (PARTITION BY dep ORDER BY hire_date) AS first_hire_salary,
    PERCENT_RANK() OVER (PARTITION BY dep ORDER BY salary) AS percentile
    FROM employees;`

## Как_использовать_операторы_GROUP_BY_и_HAVING_в_SQL

Они позволяют агрегировать информацию и фильтровать результаты группировки.
GROUP BY
Назначение: Группировка строк по значениям указанных столбцов с применением агрегатных функций.
`SELECT 
    department_id,
    COUNT(*) AS employee_count,
    AVG(salary) AS avg_salary
FROM employees
GROUP BY department_id;`

HAVING
Назначение: Фильтрация результатов группировки (аналог WHERE для агрегированных данных).
`SELECT 
    department_id,
    AVG(salary) AS avg_salary
FROM employees
GROUP BY department_id
HAVING AVG(salary) > 100000;`

Индексы:
- Добавлять на колонки в GROUP BY и WHERE
- Для HAVING индексы не помогут (фильтрация после агрегации)

Альтернативы:
- Для сложной аналитики использовать оконные функции
- Вместо HAVING с подзапросами — CTE (WITH)

Ограничения:
- В HAVING нельзя использовать алиасы из SELECT
- Подзапросы в HAVING могут быть медленными

## Как_использовать_операторы_ORDER_BY_и_LIMIT_в_SQL

ORDER BY: Сортировка результатов
Назначение: Упорядочивание строк по указанным столбцам.
`SELECT id, name, salary FROM employees ORDER BY salary DESC, name ASC;`

LIMIT/OFFSET: Пагинация
`SELECT * FROM products ORDER BY price DESC LIMIT 10 OFFSET 20;`

## Как_создать_индекс_на_одном_или_нескольких_столбцах_в_SQL

Индекс на одном столбце: `CREATE INDEX idx_employee_name ON employees(last_name);`
Составной индекс (несколько столбцов): `CREATE INDEX idx_employee_dept_name ON employees(department_id, last_name);`
Уникальный индекс: `CREATE UNIQUE INDEX idx_employee_email ON employees(email);`

## Что_такое_таблица_соединения_и_как_она_используется_в_SQL

Таблица соединения (Join Table) — это специальная таблица в реляционных базах данных, которая используется для 
организации связей многие-ко-многим (Many-to-Many) между сущностями. Она содержит внешние ключи (Foreign Keys), 
ссылающиеся на первичные ключи соединяемых таблиц.

## Как_использовать_оператор_UNION_в_SQL

Оператор UNION в SQL используется для объединения результатов двух или более SELECT-запросов в одну результирующую таблицу.
UNION - Объединение с удалением дублей
UNION ALL - Объединение с сохранением дублей

`-- Найти всех сотрудников и клиентов с email-адресами
SELECT name, email FROM employees
UNION
SELECT name, email FROM customers;`

## Как_использовать_операторы_IN_и_EXISTS_в_SQL

Операторы IN и EXISTS используются для проверки вхождения данных, но работают по разным принципам.

IN — для проверки вхождения в фиксированный список
`SELECT * FROM employees WHERE department_id IN (SELECT id FROM departments WHERE active = true);`
EXISTS — для коррелированных подзапросов и проверки отношений
`SELECT * FROM employees e WHERE EXISTS (
    SELECT 1 FROM departments d 
    WHERE d.id = e.department_id AND d.budget > 100000);`

## Что_такое_операторы_ALL_и_ANY_в_SQL

Операторы ALL и ANY в SQL используются для сравнения значения с набором значений из подзапроса. 
Они особенно полезны, когда нужно сравнить значение с каждым элементом набора (ALL) или хотя бы с одним элементом (ANY/SOME).

ALL
Возвращает TRUE, если условие выполняется для всех значений подзапроса
Эквивалентен логическому "И" для всех элементов набора
`-- ALL: Зарплата больше всех указанных значений
SELECT name FROM employees
WHERE salary > ALL (50000, 60000, 70000);`

ANY/SOME
Возвращает TRUE, если условие выполняется для хотя бы одного значения подзапроса
ANY и SOME взаимозаменяемы
Эквивалентен логическому "ИЛИ" для элементов набора
`-- ANY: Зарплата больше хотя бы одного из значений
SELECT name FROM employees
WHERE salary > ANY (50000, 60000, 70000);`

## Как_использовать_операторы_EXISTS_и_NOT_EXISTS_в_SQL

Операторы EXISTS и NOT EXISTS — это ключевые инструменты для проверки наличия/отсутствия данных в подзапросе, особенно полезные при работе со связанными таблицами.
EXISTS (проверка существования)
`SELECT * FROM orders o
WHERE EXISTS (
    SELECT 1 FROM payments p 
    WHERE p.order_id = o.id AND p.amount > 100
);`

## Как_использовать_операторы_CASE_и_WHEN_в_SQL

Оператор CASE WHEN — это SQL-эквивалент условных конструкций if-else/switch-case в Java. Позволяет реализовывать сложную бизнес-логику прямо в запросах.
`SELECT 
    name,
    salary,
    CASE 
        WHEN salary > 100000 THEN 'High'
        WHEN salary > 50000 THEN 'Medium'
        ELSE 'Low'
    END AS salary_level
FROM employees;`

## Что_такое_RDBMS

RDBMS (Relational Database Management System) — это система управления реляционными базами данных, основанная на реляционной модели данных. 
Это ключевая технология для хранения структурированных данных в enterprise-приложениях.

## Что_такое_COMMIT_и_ROLLBACK

try (Session session = sessionFactory.openSession()) {
Transaction transaction = session.beginTransaction();

    try {
        Employee employee = session.get(Employee.class, 1L);
        employee.setSalary(5000);
        
        transaction.commit();
    } catch (Exception e) {
        transaction.rollback();
        throw e;
    }
}

COMMIT и ROLLBACK — это ключевые операции управления транзакциями в SQL, обеспечивающие целостность данных
COMMIT
- Фиксирует изменения транзакции в базе данных
- После COMMIT изменения становятся видимыми другим транзакциям
- Не может быть отменен

ROLLBACK
- Отменяет все изменения текущей транзакции
- Возвращает базу в состояние до начала транзакции
- Может быть вызван явно или при ошибках

`START TRANSACTION;
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
UPDATE accounts SET balance = balance + 100 WHERE id = 2;
COMMIT; -- Фиксация

-- Или при ошибке:
ROLLBACK; -- Отмена`

## Что_такое_процедура_stored_procedure

Stored Procedure (хранимая процедура) — это предкомпилированный набор SQL-инструкций, хранящийся в самой СУБД и выполняемый на сервере базы данных.
Плюсы:
- Производительность: Меньше сетевых round-trips
- Безопасность: Нет риска SQL-инъекций
- Согласованность: Единая логика для всех клиентов

Минусы:
- Сложность отладки: Требуются специфичные инструменты СУБД
- Вендор-локи: Синтаксис отличается между PostgreSQL, Oracle, MySQL
- Масштабируемость: Может стать узким местом

## Как_создать_процедуру_в_SQL

`DELIMITER //
CREATE PROCEDURE transfer_funds(
IN from_account INT,
IN to_account INT,
IN amount DECIMAL(10,2),
OUT status VARCHAR(100)
)
BEGIN
DECLARE EXIT HANDLER FOR SQLEXCEPTION
BEGIN
SET status = 'Error: ' + SQLSTATE;
ROLLBACK;
END;

    START TRANSACTION;
        UPDATE accounts SET balance = balance - amount WHERE id = from_account;
        UPDATE accounts SET balance = balance + amount WHERE id = to_account;
        SET status = 'Success';
    COMMIT;
END //
DELIMITER ;`

## Как_вызвать_процедуру_в_SQL

`CALL transfer_funds(123, 456, 100.00, @status); SELECT @status;`

## Что_такое_функция_stored_function_и_как_ее_использовать

Stored Function (хранимая функция) — это именованный блок SQL-кода, который хранится в СУБД и возвращает единственное значение. 
В отличие от хранимых процедур, функции:
- Всегда возвращают результат
- Могут использоваться в SQL-выражениях (WHERE, SELECT и т.д.)
- Не модифицируют данные (по соглашению, но не везде строго)

`CREATE OR REPLACE FUNCTION calculate_tax(price NUMERIC) 
RETURNS NUMERIC AS $$
BEGIN
    RETURN price * 0.20; -- 20% налог
END;
$$ LANGUAGE plpgsql;`

## Как_создать_функцию_в_SQL

`CREATE OR REPLACE FUNCTION имя_функции(параметры)
RETURNS тип_возвращаемого_значения
AS $$
BEGIN
    -- Логика функции
    RETURN результат;
END;
$$ LANGUAGE язык_процедурный_SQL;`

## Как_использовать_подзапрос_subquery_в_SQL

Подзапросы (Subqueries) в SQL — это вложенные запросы, которые позволяют выполнять сложные операции с данными.
`SELECT name, salary 
FROM employees
WHERE salary > (SELECT AVG(salary) FROM employees);`

## Что_такое_оператор_HAVING_и_как_его_использовать

HAVING — это оператор в SQL, который используется для фильтрации результатов группировки, заданной оператором GROUP BY. 
В отличие от WHERE, который фильтрует строки до группировки, HAVING применяется после группировки.
В HAVING можно использовать агрегатные функции (COUNT, SUM, AVG, MAX, MIN и др.), тогда как WHERE — нет.
Отличие HAVING от WHERE:
- WHERE фильтрует строки перед группировкой.
- HAVING фильтрует группы после группировки.

`SELECT customer_id, COUNT(*) as order_count
FROM orders
GROUP BY customer_id
HAVING COUNT(*) > 5;`

## Как_использовать_условные_операторы_CASE_IF_в_SQL

CASE — это условный оператор в SQL, который позволяет выполнять ветвление прямо в запросе (аналогично switch или if-else в Java).
`SELECT name,
       CASE status
           WHEN 'ACTIVE' THEN 'Работает'
           WHEN 'INACTIVE' THEN 'Неактивен'
           ELSE 'Неизвестно'
       END AS status_description
FROM users;`

В отличие от CASE, функция IF — это сокращенная форма для простых условий.
`SELECT name, IF(age >= 18, 'Взрослый', 'Ребенок') AS age_group FROM users;`

## Что_такое_триггер_trigger_и_как_его_использовать

Триггер (Trigger) — это специальная хранимая процедура в базе данных, которая автоматически выполняется при наступлении 
определенного события (например, вставка, обновление или удаление данных в таблице).
Триггеры применяются для:
- Аудита изменений (логирование кто и когда изменил данные).
- Проверки/валидации данных перед записью в БД.
- Автоматического обновления связанных данных (например, обновление суммы заказа при изменении позиций).
- Реализации сложных бизнес-правил на уровне БД.

`CREATE TRIGGER trigger_name
BEFORE/AFTER INSERT/UPDATE/DELETE ON table_name
FOR EACH ROW/STATEMENT
BEGIN
    -- Логика триггера (например, запись в лог-таблицу)
END;`

Типы триггеров:
BEFORE — выполняется до операции (полезно для валидации).
AFTER — выполняется после операции (полезно для аудита).
INSTEAD OF (в некоторых СУБД) — заменяет оригинальную операцию.

## Что_такое_ORM_и_какие_библиотеки_ORM_для_Java_вы_знаете

«ORM — это технология для работы с БД через объекты в Java. Я чаще всего использую Hibernate, 
так как он реализует JPA и снижает объем шаблонного кода.

JPA (Jakarta Persistence API) — это стандарт (интерфейсы: EntityManager, @Entity).
Hibernate — самая популярная реализация JPA (но есть и другие, например, EclipseLink).

## Как_улучшить_производительность_SQL_запросов

Структурированный ответ:
- Начинаю с диагностики (EXPLAIN, логирование запросов).
- Использую индексы для частых фильтров и JOIN.
- Оптимизирую структуру запросов (убираю SELECT *, минимизирую подзапросы).
- Для ORM применяю JOIN FETCH, DTO, кэширование.
- В сложных случаях рассматриваю денормализацию или нативный SQL.

Перед тем как углубляться в конкретные методы, важно обозначить системный подход:
1. Измеряем (профилируем запросы, находим узкие места).
2. Анализируем (смотрим план выполнения, выявляем проблемные места).
3. Оптимизируем (применяем подходящие методы).
4. Тестируем (проверяем, дала ли оптимизация результат).

Конкретные методы оптимизации:
1. Использование индексов
   - Создаем индексы на часто используемые WHERE, JOIN, ORDER BY поля.
   - Избегаем избыточных индексов (они замедляют INSERT/UPDATE).
   - Используем составные индексы (для сложных условий).
2. Оптимизация структуры запросов
   - Неэффективные JOIN, подзапросы, лишние данные.
   - Избегаем SELECT * — выбираем только нужные поля.
   - Замениваем IN на JOIN или EXISTS (если данных много).
3. Оптимизация работы с JOIN
   - Порядок JOIN имеет значение — начинаем с самой маленькой таблицы.
   - Используем INNER JOIN вместо OUTER JOIN (если возможно).
4. Кэширование запросов

## Как_ускорить_выполнение_SQL_запросов

Шаг 1: Выявление проблемных запросов (через мониторинг)
Шаг 2: Анализ плана выполнения `EXPLAIN ANALYZE SELECT * FROM orders WHERE user_id = 100;`
Шаг 3: Применение оптимизаций
Шаг 4: Валидация результатов

Избегать SELECT *
Оптимизация JOIN
Замена подзапросов

Для аналитических запросов:
- Материализованные представления (кэшированные результаты)
- Партиционирование больших таблиц по дате/региону
- Columnar storage (ClickHouse, Amazon Redshift)

## Что_такое_индексация_в_базах_данных

Индексация — это механизм ускорения поиска данных в БД, аналогичный оглавлению в книге. Индекс создает отдельную структуру данных, 
которая хранит ссылки на строки таблицы в отсортированном виде для быстрого доступа.

## Как_узнать_план_выполнения_запроса_в_базе_данных

`EXPLAIN SELECT * FROM users WHERE email = 'test@example.com';`

## Что_такое_deadlock_и_как_его_избежать

Deadlock (взаимная блокировка) — это ситуация, когда две или более транзакции блокируют друг друга, ожидая освобождения ресурсов. 
Ни одна из них не может продолжить выполнение.
Ситуация:
- В системе перевода денег между счетами возникали deadlock'и при одновременных операциях:
- Пользователь 1: перевод с A → B
- Пользователь 2: перевод с B → A

Решение:
- Ввели сортировку ID счетов: всегда сначала блокируем меньший ID.
- Добавили retry-механизм с экспоненциальной задержкой.
- Уменьшили время транзакций, вынеся логирование в отдельную асинхронную операцию.

## Что_такое_SQL_injection_и_как_его_предотвратить

SQL-инъекция (SQL Injection) — это уязвимость, позволяющая злоумышленнику выполнить произвольный SQL-код через 
некорректно обработанные пользовательские данные.
В Java мы предотвращаем это через:
- PreparedStatement для параметризованных запросов,
- Валидацию входных данных,
- ORM с именованными параметрами.

## Как_сделать_backup_базы_данных

Резервное копирование можно выполнять как нативными утилитами СУБД (например, mysqldump), так и через Java-код для небольших БД. 
В нашем проекте с PostgreSQL мы использовали комбинированный подход: ежедневные дампы через pg_dump с выгрузкой в S3 и проверкой 
целостности через Java-приложение. Для критичных данных применяли шифрование бэкапов GPG.

## Что_такое_log_shipping

Log Shipping — это метод репликации данных, при котором транзакционные логи (WAL в PostgreSQL, транзакционные журналы в SQL Server) 
автоматически копируются с основной БД (primary) на резервную (standby) и применяются там.

Как работает Log Shipping
- Основной сервер фиксирует изменения в транзакционных логах.
- Логи копируются на резервный сервер (через файловую систему или сеть).
- Резервный сервер применяет логи для синхронизации данных.

## Что_такое_репликация_базы_данных

Репликация БД — это процесс автоматического копирования и синхронизации данных между серверами баз данных, где:
- Primary (master) — основной сервер, принимающий записи
- Replica (slave) — сервер-копия, синхронизирующий данные

Можно выделить три подхода к репликации:
1. Блочная репликация на уровне системы хранения данных;
2. Физическая репликация на уровне СУБД;
3. Логическая репликация на уровне СУБД.

Блочная репликация
При блочной репликации каждая операция записи выполняется не только на основном диске, но и на резервном.
Главное назначение блочной репликации – обеспечение отказоустойчивости. Если база данных потеряна, то можно перезапустить её с использованием зеркального тома.
Блочная репликация хороша своей универсальностью, но за универсальность приходится платить:
1. Во-первых, никакой сервер не может работать с зеркальным томом, поскольку его операционная система не может управлять записью на него; с точки зрения 
   наблюдателя данные на зеркальном томе появляются сами собой. В случае аварии (отказ основного сервера или всего ЦОДа, где находится основной сервер) следует 
   остановить репликацию, размонтировать основной том и смонтировать зеркальный том.
2. Во-вторых, сама СУБД на резервном сервере может быть запущена только после монтирования диска.
3. В-третьих, после запуска на резервном сервере СУБД обнаружит, что данные на диске неконсистентны, и нужно потратить значительное время на восстановление 
   с применением журналов повторного выполнения.

Физическая репликация
Журналы (redo log или write-ahead log) содержат все изменения, которые вносятся в файлы базы данных. Идея физической репликации состоит в том, что изменения 
из журналов повторно выполняются в другой базе (реплике), и таким образом данные в реплике повторяют данные в основной базе байт-в-байт.
Физическая репликация базы данных имеет множество преимуществ перед репликацией средствами СХД:
1. объём передаваемых данных меньше за счёт того, что передаются только журналы, но не файлы с данными; эксперименты показывают уменьшение трафика в 5-7 раз;
2. переключение на резервную базу происходит значительно быстрее: экземпляр-реплика уже поднят, поэтому при переключении ему нужно лишь откатить активные 
   транзакции; более того, к моменту сбоя кеш реплики уже прогрет;
3. на реплике можно выполнять запросы, сняв тем самым часть нагрузки с основной базы. В частности, реплику можно использовать для создания резервных копий.

Запись данных в реплику невозможна, поскольку изменения в неё приходят побайтно, и реплика не может обеспечить конкурентное исполнение своих запросов.
В случае повреждения файла в основной базе можно просто скопировать соответствующий файл с реплики.
Физическая репликация может быть как синхронной, так и асинхронной. При асинхронной репликации всегда есть некий набор транзакций, которые завершены на основной базе, 
но ещё не дошли до резервной, и в случае перехода на резервную базу при сбое основной эти транзакции будут потеряны. При синхронной репликации завершение операции 
commit означает, что все журнальные записи, относящиеся к данной транзакции, переданы на реплику. Важно понимать, что получение репликой журнала не означает применения 
изменений к данным. При потере основной базы транзакции не будут потеряны, но если приложение пишет данные в основную базу и считывает их из реплики, то у него есть 
шанс получить старую версию этих данных.

Логическая репликация
Все изменения в базе данных происходят в результате вызовов её API – например, в результате выполнения SQL-запросов. Очень заманчивой кажется идея выполнять одну и 
ту же последовательность запросов на двух разных базах. Для репликации необходимо придерживаться двух правил:
1. Нельзя начинать транзакцию, пока не завершены все транзакции, которые должны закончиться раньше. Так на рисунке ниже нельзя запускать транзакцию D, пока не 
   завершены транзакции A и B.
2. Нельзя завершать транзакцию, пока не начаты все транзакции, которые должны закончиться до завершения текущей транзакции. Так на рисунке ниже даже если транзакция 
   B выполнилась мгновенно, завершить её можно только после того, как начнётся транзакция C.

Обычно для логической репликации используют детерминированные запросы. Детерминированность запроса обеспечивается двумя свойствами:
1. запрос обновляет (или вставляет, или удаляет) единственную запись, идентифицируя её по первичному (или уникальному) ключу;
2. все параметры запроса явно заданы в самом запросе.

Логическая репликация предоставляет ряд возможностей, отсутствующих в других видах репликации:
1. настройка набора реплицируемых данных на уровне таблиц (при физической репликации – на уровне файлов и табличных пространств, при блочной репликации – на уровне томов);
2. построение сложных топологий репликации – например, консолидация нескольких баз в одной или двунаправленная репликация;
3. уменьшение объёма передаваемых данных;
4. репликация между разными версиями СУБД или даже между СУБД разных производителей;
5. обработка данных при репликации, в том числе изменение структуры, обогащение, сохранение истории.

Есть и недостатки, которые не позволяют логической репликации вытеснить физическую:
1. все реплицируемые данные обязаны иметь первичные ключи;
2. логическая репликация поддерживает не все типы данных – например, возможны проблемы с BLOB’ами.
3. логическая репликация на практике не бывает полностью синхронной: время от получения изменений до их применения слишком велико, чтобы основная база могла ждать;
4. логическая репликация создаёт большую нагрузку на реплику;
5. при переключении приложение должно иметь возможность убедиться, что все изменения с основной базы, применены на реплике – СУБД зачастую сама не может этого определить, 
   так как для неё режимы реплики и основной базы эквивалентны.

Прикладная репликация
Наконец, ещё один способ репликации – формирование векторов изменений непосредственно на стороне клиента. Клиент должен формировать детерминированные запросы, 
затрагивающие единственную запись. Добиться этого можно, используя специальную библиотеку работы с базой данных, например, Borland Database Engine (BDE) или Hibernate ORM.
Когда приложение завершает транзакцию, подключаемый модуль Hibernate ORM записывает вектор изменений в очередь и выполняет транзакцию в базе данных. Специальный процесс-репликатор 
вычитывает векторы из очереди и выполняет транзакции в базе-реплике.
Этот механизм хорош для обновления отчётных систем. Может он использоваться и для обеспечения отказоустойчивости, но в этом случае в приложении должен быть реализован контроль 
состояния репликации.

Традиционно – сильные и слабые стороны данного подхода:
1. возможность репликации между разными СУБД, в том числе загрузка данных в отчётные системы;
2. возможность обработки и преобразования данных, мониторинга состояния и т. д.;
3. минимальный трафик между узлами – платформа отсекает ненужные данные и может сжимать трафик;
4. полная независимость от базы данных – как от формата, так и от внутренних механизмов.

Достоинства этого способа бесспорны, однако есть два очень серьёзных недостатка:
1. ограничения на архитектуру приложения;
2. огромный объём собственного кода, обеспечивающего репликацию.

## Что_такое_масштабирование_базы_данных

С сервера приложений поступает множество запросов на чтение, чтобы получить информацию о пользователе с определённым идентификатором. Чтобы ускорить запрос на чтение, сделайте следующее:
1. Индексирование
База данных проверяет каждую строку в таблице, чтобы найти запрашиваемые данные. Это называется полным сканированием таблицы(full table scan) и может быть медленным для больших таблиц. 
Проверка каждого идентификатора занимает O(N) времени.
При индексировании база данных использует индекс для быстрого перехода к нужным строкам, что значительно ускоряет работу.
Вы индексируете столбец «id», после чего база данных создаёт копию этого столбца «id» в структуре данных (называемой B-деревом). B-дерево используется для поиска конкретного идентификатора. 
Поиск выполняется быстрее, потому что идентификаторы хранятся в отсортированном виде, так что вы можете использовать двоичный поиск для поиска за O(logN) (прим. переводчика. 
В PostgreSQL - индекс для Primary Key создаётся автоматически)
Если вы хотите включить индексирование в каком-либо столбце, вам нужно просто добавить одну строку кода, и все операции по созданию B-деревьев и т.д. будут выполняться БД. Вам не нужно ни о чём беспокоиться.
`CREATE TABLE users (
   id SERIAL PRIMARY KEY,
   username VARCHAR(50),
   email VARCHAR(100),
   created_at TIMESTAMP NOT NULL
   );

CREATE INDEX idx_users_email ON users(email);`

2. Партиционирование
   Означает разбиение большой таблицы на несколько маленьких таблиц.
`CREATE TABLE users (
   id SERIAL,
   username VARCHAR(50),
   email VARCHAR(100),
   created_at TIMESTAMP NOT NULL
   ) PARTITION BY RANGE (created_at);

-- Партиция для данных за январь 2023 года
CREATE TABLE users_2023_01 PARTITION OF users
FOR VALUES FROM ('2023-01-01') TO ('2023-02-01');

-- Партиция для данных за февраль 2023 года
CREATE TABLE users_2023_02 PARTITION OF users
FOR VALUES FROM ('2023-02-01') TO ('2023-03-01');

-- Партиция для данных за март 2023 года
CREATE TABLE users_2023_03 PARTITION OF users
FOR VALUES FROM ('2023-03-01') TO ('2023-04-01');`
Когда ваш индекс становится очень большим, при поиске также возникают проблемы с производительностью. Теперь, после разделения на разделы, у каждой таблицы есть свой индекс, поэтому поиск в таблицах 
меньшего размера выполняется быстрее.
Вам может быть интересно, как мы определяем, из какой таблицы выполнять запрос. До этого мы могли выполнить запрос SELECT * FROM users where ID=4 . Не волнуйтесь, вы можете снова выполнить тот же запрос. 
PostgreSQL работает за кулисами. Он найдёт нужную таблицу и выдаст результат. Но вы также можете настроить это на уровне приложения, если хотите.

3. Архитектура ведущего-ведомого устройства (Master-Slave)
Используйте её, если даже после индексирования, партиционирования и вертикального масштабирования ваши запросы выполняются медленно или ваша база данных не может обрабатывать 
дальнейшие запросы на одном сервере.
Суть подхода заключается в репликации данных на несколько серверов.
При выполнении любого запроса на чтение (запросы SELECT) он будет перенаправлен на наименее загруженный сервер. Таким образом вы распределяете нагрузку.
Но все запросы на запись (INSERT, UPDATE, DELETE) будут обрабатываться только одним сервером.
Узел/сервер/нода, который обрабатывает запрос на запись, называется главным узлом(master).
Узлы, которые принимают запросы на чтение, называются подчиненными узлами(slaves).
Когда вы отправляете запрос на запись, он обрабатывается и записывается на главном узле, а затем асинхронно (или синхронно в зависимости от конфигурации) реплицируется на все подчиненные узлы.

4. Шардирование базы данных
Шардинг — это очень сложная процедура. Старайтесь избегать этого в реальной жизни и делайте это только в том случае, если всего вышеперечисленного недостаточно и 
требуется дальнейшее масштабирование.
Шардинг похож на партиционирование, что мы видели выше. Но вместо того, чтобы размещать разные таблицы на одном сервере, мы размещаем их на разных серверах.
![img.png](../photo/img.png)
На изображении выше вы видите, что мы разделили таблицу на 3 части и поместили их на 3 разных сервера. Эти серверы обычно называют шардами.
Здесь мы выполнили шардирование на основе идентификаторов, поэтому этот столбец с идентификаторами называется ключом шардирования.
Каждый раздел хранится на независимом сервере баз данных (называемом сегментом/шардом). Таким образом, теперь вы можете масштабировать этот сервер по отдельности в соответствии с 
5. вашими потребностями, например, используя архитектуру «ведущий-ведомый» для одного из шардов, на который поступает много запросов.

Почему шардирование является сложной задачей?
При партиционирование(сохранении фрагментов таблицы на одном сервере БД) вам не нужно беспокоиться о том, из какой таблицы выполнять запрос. PostgreSQL делает это за вас. Но при 
шардирование (сохранении фрагментов таблицы на разных серверах БД) вам нужно обрабатывать это на уровне приложения. Вам нужно написать код таким образом, чтобы при запросе от идентификатора 
1 до 2 он отправлялся в БД-1, а при запросе от идентификатора 5 до 6 — в БД-3. Кроме того, при добавлении новой записи вам нужно вручную обработать логику в коде приложения, чтобы определить, 
в какой шард вы собираетесь добавить эту новую запись.

Стратегии шардирования:
1. Шардирование на основе диапазонов(Range-Based Sharding)
   Данные делятся на сегменты на основе диапазонов значений в ключе сегментирования.
2. Шардирование на основе хеширования(Hash-Based Sharding)
   К ключу шардирования применяется хеш-функция и результат определяет шард.
3. Географическое шардирование(Geographic/Entity-Based Sharding)
   Данные разделяются на основе логической группировки, например по региону.

Недостатки шардирования:
1. Сложно реализовать, потому что вам придётся самостоятельно писать логику, чтобы знать, из какого шарда выполнять запрос и в какой шард записывать данные.
2. Разделы хранятся на разных серверах/шардах. Поэтому при выполнении объединений вам приходится извлекать данные из разных шардов, чтобы выполнить объединение с разными таблицами. Это дорогостоящая операция.
3. Вы теряете согласованность. Поскольку разные части данных находятся на разных серверах. Поэтому поддерживать согласованность сложно.

## Что_такое_шардинг

Шардирование — это метод горизонтального разделения базы данных на меньшие, более управляемые части (шарды), которые распределяются между разными серверами. 
Каждый шард содержит подмножество данных и работает независимо, что позволяет повысить производительность, масштабируемость и отказоустойчивость системы.
горизонтальное партиционирование — это когда все таблицы, на которые разделена основная таблица, лежат в одной и той же схеме, а когда на разных машинах —это уже шардирование.
Зачем нужно шардирование?
🔹 Масштабируемость – когда данные не помещаются на одном сервере.
🔹 Производительность – уменьшается нагрузка на каждый узел.
🔹 Геораспределение – данные можно размещать ближе к пользователям.
🔹 Отказоустойчивость – при падении одного шарда остальные продолжают работать.

Виды шардирования:
1. Горизонтальное шардирование (Horizontal Sharding)
   Данные делятся по строкам таблицы. Например:
   - Пользователи с ID 1–1000 → Шард 1
   - Пользователи с ID 1001–2000 → Шард 2
2. Вертикальное шардирование (Vertical Sharding)
   Разделение по столбцам (редко называется шардированием, чаще – партиционированием).
   Например, одна таблица разбивается на две:
   - users(id, name, email) → Шард 1
   - users_profile(id, bio, address) → Шард 2

Проблемы и сложности шардирования:
⚠ Сложность запросов JOIN – если данные в разных шардах, JOIN работает медленно.
⚠ Транзакции между шардами – сложно обеспечить ACID.
⚠ Ребалансировка – при добавлении новых шардов нужно перераспределять данные.
⚠ Hotspots – неравномерная нагрузка, если ключ шардирования выбран плохо.

## Как_настроить_шардинг_в_базе_данных

Citus — расширение PostgreSQL для горизонтального шардирования.
1. Установите Citus
2. Добавьте расширение в PostgreSQL
3. Добавьте worker-узлы
4. Создайте шардированную таблицу
5. Проверить распределение

## Какой_подход_лучше_для_шардинга

1. Hash-Based Sharding (Хеш-шардирование)
   Как работает:
   - Ключ шардирования (например, user_id) пропускается через хеш-функцию (например, MD5, SHA-256).
   - Результат определяет, в какой шард попадут данные.
   Плюсы:
   ✔ Равномерное распределение данных (меньше риска hotspots).
   ✔ Простота реализации.
   Минусы:
   ❌ Невозможно выполнять запросы по диапазонам (например, WHERE date BETWEEN ...).
   ❌ Ребалансировка сложна при добавлении новых шардов.
   Когда использовать:
   - Для равномерно распределённых ключей (ID пользователей, UUID).

2. Range-Based Sharding (Диапазонное шардирование)
   Как работает:
   - Данные делятся по диапазонам ключей (например, A-F, G-M, N-Z).
   Плюсы:
   ✔ Поддержка запросов по диапазонам (WHERE age > 18).
   ✔ Простота управления (легко определить, где лежат данные).
   Минусы:
   ❌ Риск неравномерной нагрузки (hotspots, если данные сконцентрированы в одном диапазоне).
   Когда использовать:
   - Для временных данных (даты, временные метки).
   Пример: шардирование логов по месяцам.

3. Directory-Based Sharding (Шардирование через справочник)
   Как работает:
   - Внешняя служба (например, ZooKeeper) хранит маппинг ключей на шарды.
   Плюсы:
   ✔ Гибкость (можно менять правила без перераспределения данных).
   ✔ Поддержка сложных правил.
   Минусы:
   ❌ Дополнительная точка отказа (справочник должен быть высокодоступным).
   ❌ Задержки из-за обращения к справочнику.
   Когда использовать:
   - Для сложных схем шардирования (например, мультитенантные приложения).
   Пример: Vitess (MySQL).

4. Geo-Sharding (Географическое шардирование)
   Как работает:
   - Данные распределяются по физическому расположению (страна, регион).
   Плюсы:
   ✔ Низкие задержки для локальных пользователей.
   ✔ Соответствие GDPR и другим регуляторным требованиям.
   Минусы:
   ❌ Сложность синхронизации между регионами.
   Когда использовать:
   - Глобальные приложения (соцсети, маркетплейсы).
   Пример: Cloudflare, Discord.

## Что_такое_партиционирование_таблицы

Партиционирование – это метод разделения больших (исходя из количества записей, а не столбцов) таблиц на много маленьких. И желательно, чтобы это происходило прозрачным для приложения способом.
Зачем нужно партиционирование?
1. Ускорение запросов (чтение только нужных партиций)
2. Упрощение управления большими таблицами
3. Оптимизация операций удаления/архивирования данных
4. Улучшение производительности при параллельной обработке

Типы партиционирования:
1. Горизонтальное (по строкам)
   Наиболее распространенный тип. Данные разделяются по значениям определенного столбца.
2. Вертикальное (по столбцам)
   Редко используемый метод, где разные столбцы хранятся отдельно.

Стратегии партиционирования:
1. По диапазону (RANGE)
   Плюсы:
   - Идеально для временных данных
   - Простое удаление старых данных (DROP PARTITION)
   Минусы:
   - Возможность неравномерного распределения
2. По списку (LIST)
   Плюсы:
   - Хорошо для категориальных данных
   - Явное управление распределением
3. По хешу (HASH)
   Плюсы:
   - Равномерное распределение
   - Хорошо для балансировки нагрузки
   Минусы:
   - Невозможность целевого запроса конкретной партиции

Давайте разберемся в их достоинствах и недостатках:
1. партиционирование по дате:
   - достоинства:
     1. легко понять;
     2. количество строк в данной таблице будет достаточно стабильным;
   - недостатки:
     1. требует поддержки – время от времени нам придётся добавлять новые партиции;
     2. поиск по имени пользователя или id потребует сканирования всех партиций;
2. партиционирование по id:
  - достоинства:
    1. легко понять;
    2. количество строк в партиции будет на 100% стабильным;
  - недостатки:
    1. требует поддержки – время от времени нам придётся добавлять новые партиции;
    2. поиск по имени пользователя или id потребует сканирования всех партиций;
3. партиционирование по первой букве имени пользователя:
  - достоинства:
    1. легко понять;
    2. никакой поддержки – есть строго определенный набор партиций и нам никогда не придется добавлять новые;
  - недостатки:
    1. количество строк в партициях будет стабильно расти;
    2. в некоторых партициях будет существенно больше строк, чем в других (больше людей с никами, начинающимися на “t*", чем на “y*");
    3. поиск по id потребует сканирования всех партиций;
4. партиционирование по хэшу имени пользователя:
  - достоинства:
    1. никакой поддержки – есть строго определенный набор партиций и нам никогда не придется добавлять новые;
    2. строки будут равно распределяться между партициями;
  - недостатки:
    1. количество строк в партициях будет стабильно расти;
    2. поиск по id потребует сканирования всех партиций;
    3. поиск по имени пользователя будет сканировать только одну партицию, но только при использовании дополнительных условий.


## Как_настроить_партиционирование_таблицы

`-- Создание партиционированной таблицы
CREATE TABLE measurement (
city_id INT NOT NULL,
logdate DATE NOT NULL,
peaktemp INT
) PARTITION BY RANGE (logdate);

-- Добавление партиций
CREATE TABLE measurement_y2023m01 PARTITION OF measurement
FOR VALUES FROM ('2023-01-01') TO ('2023-02-01');

-- Автоматическое создание партиций
CREATE EXTENSION pg_partman;`

## Что_такое_отказоустойчивость_базы_данных

Patroni — набор скриптов на python для автоматизации переключения ведущей роли сервера баз данных PostgreSQL на реплику. Также может хранить, 
изменять и применять параметры самой СУБД PostgreSQL. Получается, нет необходимости поддерживать актуальность конфигурационных файлов PostgreSQL на каждом сервере отдельно.
В PostgreSQL существуют роли серверов: primary — экземпляр с возможностью записи/чтения данных; replica — экземпляр с возможностью только чтения данных, постоянно синхронизируется с primary. 
Эти роли при работе PostgreSQL статичны и при сбое сервера с ролью primary необходимо, чтобы администратор БД вручную повысил роль replica до primary.
Patroni создает отказоустойчивые кластеры, то есть объединяет серверы с ролями primary и replica.
При синхронной репликации PostgreSQL работает так, что primary всегда ожидает записи изменений на реплике. Если синхронная реплика окажется недоступной, primary не будет писать в себя изменения, 
он будет доступен только на чтение.
У Рatroni этот функционал называется standby_cluster. Он позволяет использовать кластер Рatroni на удалённой площадке в качестве асинхронной реплики. При потере основной площадки, 
на резервной кластер Рatroni начнет работать так, как будто это основная площадка.

Одна из нод кластера резервной площадки называется Standby Leader. Он является асинхронной репликой primary-ноды основной площадки. Две оставшиеся ноды кластера резервной площадки получают данные 
со Standby Leader. Так воплощается каскадная репликация, снижающая объём трафика между технологическими площадками.

## Как_обеспечить_отказоустойчивость_базы_данных

1. Репликация данных
   Master-Slave (Primary-Replica)
     Характеристики:
     - Чтение из реплик, запись только в мастер
     - Автоматическое/ручное переключение при сбое
     - Примеры: MySQL Replication, PostgreSQL Streaming Replication
   Multi-Master
     Характеристики:
     - Запись в любой узел
     - Сложнее в настройке (конфликты записи)
     - Примеры: PostgreSQL BDR, Galera Cluster
2. Кластеризация
3. Шардирование + георепликация

## Что_такое_резервный_сервер_базы_данных

Резервный сервер — синхронизированная реплика основной (primary) БД, которая:
1. Постоянно получает обновления с основного сервера.
2. Может автоматически или вручную стать новым primary при аварии.
3. Обеспечивает непрерывность работы приложения.

Типы резервных серверов:
1. Горячий (hot standby)	Репликация в реальном времени
2. Тёплый (warm standby)	Задержка секунды-минуты
3. Холодный (cold standby)	Требует ручного запуска

Виды репликаций:
1. Логическая репликация (SQL-команды)
   - Пример: PostgreSQL Logical Replication
   - Плюсы: Можно реплицировать только часть таблиц
   - Минусы: Выше нагрузка на CPU

2. Физическая репликация (бинарные WAL-логи)
   - Пример: PostgreSQL WAL Shipping, MySQL Binary Log
   - Плюсы: Точная копия, меньше нагрузки
   - Минусы: Требует одинаковую версию СУБД

3. Триггерная репликация (на уровне приложения)
   - Пример: SymmetricDS
   - Плюсы: Кросс-платформенность
   - Минусы: Высокие накладные расходы

## Что_такое_кластер_базы_данных

Кластер БД — это группа серверов баз данных, работающих как единая система для обеспечения:
- Масштабируемости (распределение нагрузки)
- Отказоустойчивости (автоматическое восстановление)
- Высокой доступности (минимальный downtime)

## Что_такое_миграции_базы_данных

Миграции БД - это управляемый процесс изменения структуры базы данных (схемы) и данных при развитии приложения. Вот комплексное руководство по настройке системы миграций.
Ключевые характеристики хорошей системы миграций:
1. Версионность - каждая миграция имеет уникальный номер/идентификатор.
2. Повторяемость - миграции должны давать одинаковый результат на всех окружениях.
3. Обратимость - возможность отката изменений (хотя бы на этапе разработки).
4. История изменений - система отслеживает примененные миграции.

Типы миграций:
1. Структурные (изменение схемы - таблицы, индексы, ограничения).
2. Данные (наполнение справочников, преобразование данных).
3. Скриптовые (специальные операции, например, GRANT прав).

Универсальные инструменты:
1. Flyway (Java, но работает с любым языком)
2. Liquibase (XML/YAML/JSON/SQL миграции)

## Что_такое_архитектура_базы_данных

Архитектура базы данных — это концептуальная структура, которая определяет организацию, хранение, управление и взаимодействие компонентов системы базы данных.
Типы архитектур баз данных:
1. Одноуровневая (монолитная)
   Приложение и БД работают на одном сервере (например, SQLite).
2. Двухуровневая (клиент-серверная)
   Клиентские приложения обращаются к серверу БД (например, PostgreSQL, MySQL).
3. Трехуровневая (веб-приложения)
   Клиент → Сервер приложений → Сервер БД.
4. Распределённая архитектура
   Данные хранятся на нескольких серверах (например, Cassandra, MongoDB).
   Включает шардинг (горизонтальное разделение) и репликацию.
5. Облачные и бессерверные БД
   Управляемые сервисы (Amazon RDS, Google Firestore).

## Какие_принципы_SOLID_применяются_при_разработке_базы_данных

1. Принцип единственной ответственности (Single Responsibility Principle, SRP)
   Каждая таблица/сущность должна отвечать только за одну логическую область.
   Таблица users хранит только данные пользователей (имя, email).
   Таблица orders отвечает только за заказы.
2. Принцип открытости/закрытости (Open/Closed Principle, OCP)
   Сущности БД должны быть открыты для расширения, но закрыты для модификации.
   Добавление новых полей через ALTER TABLE без изменения существующей логики.
   Использование наследования (например, Class Table Inheritance в SQL).
3. Принцип подстановки Барбары Лисков (Liskov Substitution Principle, LSP)
   Подтипы (наследуемые таблицы) должны быть взаимозаменяемы с базовыми типами.
   Таблица employees наследует все поля users и добавляет salary.
   Запросы к users должны работать и для employees.
4. Принцип разделения интерфейсов (Interface Segregation Principle, ISP)
   Клиенты (приложения) не должны зависеть от интерфейсов (таблиц), которые они не используют.
   Разделение users на:
   - user_auth (логин/пароль)
   - user_profile (имя, аватар)
   Приложение для аутентификации использует только user_auth.
5. Принцип инверсии зависимостей (Dependency Inversion Principle, DIP)
   Модули высокого уровня (приложение) не должны зависеть от модулей низкого уровня (БД).
   Использование репозиториев и ORM (Hibernate, SQLAlchemy).
   Абстракция доступа к данным через интерфейсы.

## Что_такое_ER_модель

ER-модель (от англ. Entity-Relationship, "сущность-связь") — это концептуальный способ описания структуры базы данных с помощью графических диаграмм. 
Она помогает визуализировать:
1. Сущности (таблицы),
2. Атрибуты (поля таблиц),
3. Связи между сущностями.

## Что_такое_временная_таблица_Для_чего_она_используется

Временная таблица — это таблица в базе данных, которая существует временно и автоматически удаляется после завершения сеанса работы или транзакции.
`CREATE TEMPORARY TABLE temp_orders AS
SELECT * FROM orders WHERE order_date > '2023-01-01';`

## Что_лучше_использовать_JOIN_или_подзапросы

JOIN (соединения)
Когда использовать:
✔ Для объединения данных из нескольких таблиц.
✔ Когда нужны данные из связанных таблиц в одном запросе.
✔ Для оптимизации производительности (часто JOIN работает быстрее подзапросов).
Плюсы:
- Обычно быстрее, особенно при правильных индексах.
- Чище и понятнее для сложных связей.
- Лучше масштабируется на большие таблицы.
Минусы:
- Может усложняться при множественных соединениях.
- Иногда приводит к дублированию данных (если не использовать DISTINCT).

Подзапросы (Subqueries)
Когда использовать:
✔ Когда нужно изолировать логику (например, фильтрацию или агрегацию).
✔ Для пошаговой обработки данных.
✔ В условиях WHERE, HAVING, SELECT.
Плюсы:
- Удобны для поэтапной логики.
- Могут быть более читаемыми в простых случаях.
- Позволяют использовать агрегатные функции (MAX, MIN, AVG).
Минусы:
- Могут быть медленнее, особенно NOT IN и коррелированные подзапросы.
- Сложнее оптимизируются СУБД.

## Что_делает_оператор_MERGE

MERGE (также известный как "UPSERT") — это мощный оператор, который позволяет выполнять несколько операций (вставку, обновление, удаление) 
в одной инструкции на основе условия совпадения данных.

## Что_такое_курсор

Курсор — это объект базы данных, который позволяет построчно обрабатывать результаты SQL-запроса. Он действует как итератор, позволяя перебирать 
записи из набора данных и выполнять операции над каждой строкой отдельно.
Для чего используются курсоры?
Курсоры применяются, когда нужно:
  Обрабатывать данные построчно (например, сложные расчеты для каждой записи).
  Выполнять условные операции над отдельными строками.
  Интегрировать SQL с процедурным кодом (например, в хранимых процедурах или триггерах).

Типы курсоров:
1. Статические (STATIC)
   Создают "снимок" данных на момент открытия курсора.
   Изменения в таблице не влияют на курсор.
   Пример: DECLARE cur CURSOR STATIC FOR SELECT * FROM employees.
2. Динамические (DYNAMIC)
   Отражают изменения в реальном времени.
   Медленнее статических, но актуальны для часто изменяемых данных.
3. Набор ключей (KEYSET)
   Фиксируют список идентификаторов на момент открытия.
   Позволяют видеть изменения в существующих строках, но не новые записи.
4. Быстрые (FAST_FORWARD)
   Оптимизированы для однократного прохода в прямом направлении.
   Не поддерживают прокрутку назад.

## Какое_назначение_у_операторов_PIVOT_и_UNPIVOT_в_Transact_SQL

Операторы PIVOT и UNPIVOT в Transact-SQL предназначены для преобразования данных из строк в столбцы и наоборот, что упрощает анализ и представление информации.
1. PIVOT
   Назначение: Преобразует уникальные значения из одного столбца в несколько столбцов, агрегируя данные.
   Когда использовать:
   - Когда нужно свести строки в столбцы (например, для создания сводных таблиц).
   - Для агрегации данных с группировкой по определенным полям.

2. UNPIVOT
   Назначение: Преобразует столбцы в строки, "разворачивая" данные.
   Когда использовать:
   - Когда нужно нормализовать данные (например, если данные хранятся в виде матрицы).
   - Для обратного преобразования PIVOT.

## Расскажите_об_основных_функциях_ранжирования_в_Transact_SQL

1. ROW_NUMBER() – если нужна строгая уникальная нумерация (например, для пагинации).
   Назначение: Присваивает уникальный порядковый номер каждой строке в результирующем наборе.
   Особенности:
   - Номера идут последовательно (1, 2, 3, ...).
   - Если значения в PARTITION BY одинаковые, номера всё равно будут разными.
2. RANK() – если важно учитывать пропуски (например, спортивные рейтинги).
   Назначение: Присваивает ранг с пропусками (если есть одинаковые значения).
   Особенности:
   - Если значения одинаковые, им присваивается один ранг, а следующий ранг пропускается.
   - Пример: 1, 2, 2, 4 (после двух одинаковых значений следующий ранг — 4).
3. DENSE_RANK() – если нужен ранг без пропусков (например, ранжирование товаров по продажам).
   Назначение: Присваивает ранг без пропусков (если есть одинаковые значения).
   Особенности:
   - Если значения одинаковые, следующий ранг идёт без пропуска.
   - Пример: 1, 2, 2, 3 (в отличие от RANK, где было бы 1, 2, 2, 4).

## Для_чего_используются_операторы_INTERSECT_EXCEPT_в_Transact_SQL

Операторы INTERSECT и EXCEPT в Transact-SQL используются для работы с множествами данных, позволяя находить пересечения и разности между результатами двух запросов. 
Они похожи на операции с математическими множествами и работают с наборами строк, возвращаемыми SELECT.
1. INTERSECT (Пересечение)
   Назначение: Возвращает только те строки, которые есть в обоих запросах (аналог логического AND).
   Особенности
   - Удаляет дубликаты (как UNION).
   - Структура столбцов в обоих запросах должна совпадать.
   - Порядок столбцов и их типы данных должны быть согласованы.

2. EXCEPT (Разность)
   Назначение: Возвращает строки из первого запроса, которых нет во втором (аналог MINUS в Oracle).
   Особенности
   - Удаляет дубликаты.
   - Порядок запросов важен: A EXCEPT B ≠ B EXCEPT A.
