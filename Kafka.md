<a href="https://mc.yandex.ru/pixel/8711235002931986822?rnd=%aw_random%">
    <img src="https://mc.yandex.ru/pixel/8711235002931986822?rnd=%aw_random%" />        
  </a>&nbsp;&nbsp;
<a href="https://mc.yandex.ru/watch/92801430">
    <img src="https://mc.yandex.ru/watch/92801430" />        
  </a>&nbsp;&nbsp;

Если вам интересно мое резюме: https://github.com/DEBAGanov

# Kafka
- [Kafka](#kafka)
  - [Что такое Kafka. В чем ее преимущества и недостатки?](#Что_такое_Kafka_В_чем_ее_преимущества_и_недостатки)
  - [Какие есть основные компоненты в Kafka?](#Какие_есть_основные_компоненты_в_Kafka)
  - [Какие параметры отвечают за время хранения в кафке и как данные удаляются?](#Какие_параметры_отвечают_за_время_хранения_в_кафке_и_как_данные_удаляются)
  - [Как можно найти сообщение в kafka?](#Как_можно_найти_сообщение_в_kafka)
  - [Как выбирается партиция в которую записываются данные в kafka?](#Как_выбирается_партиция_в_которую_записываются_данные_в_kafka)
  - [Какие типы алгоритмов сжатия есть у кафки и каким параметром настраиваются?](#Какие_типы_алгоритмов_сжатия_есть_у_кафки_и_каким_параметром_настраиваются)
  - [Как в kafka работает подтверждение что данные дошли до брокера. (acks)?](#Как_в_kafka_работает_подтверждение_что_данные_дошли_до_брокера_acks)
  - [Расскажите про Consumer Group?](#Расскажите_про_Consumer_Group)
  - [Что вы можете рассказать по Offset?](#Что_вы_можете_рассказать_по_Offset)
  - [Что такое Rack в контексте Kafka?](#Что_такое_Rack_в_контексте_Kafka)
  - [Для чего необходим Connector API?](#Для_чего_необходим_Connector_API)
  - [Что вы можете рассказать про Kafka Streams?](#Что_вы_можете_рассказать_про_Kafka_Streams)
  - [Что такое Transactions API?](#Что_такое_Transactions_API)
  - [Для чего необходим AdminClient?](#Для_чего_необходим_AdminClient)
  - [Для чего нужен координатор группы?](#Для_чего_нужен_координатор_группы)
  - [Расскажите про Producer?](#Расскажите_про_Producer)
  - [Расскажите как сообщение принимается consumer из kafka?](#Расскажите_как_сообщение_принимается_consumer_из_kafka)
  - [Расскажите про Consumer?](#Расскажите_про_Consumer)
  - [Как Kafka обрабатывает сообщения?](#Как_Kafka_обрабатывает_сообщения)
  - [Что такое Лаг. (Задержка обработки)?](#Что_такое_Лаг_Задержка_обработки)
  - [Для чего нужен subscribe() и poll() и position() методы?](#Для_чего_нужен_subscribe_и_poll_и_position_методы)
  - [Для чего необходимы методы commitSync(), commitAsync()?](#Для_чего_необходимы_методы_commitSync_commitAsync)
  - [Для чего нужен идемпотентный producer?](#Для_чего_нужен_идемпотентный_producer)
  - [Для чего нужен Mirror Maker?](#Для_чего_нужен_Mirror_Maker)
  - [Для чего нужен Streams DSL?](#Для_чего_нужен_Streams_DSL)
  - [Какая есть разница между Kafka и RabbitMQ?](#Какая_есть_разница_между_Kafka_и_RabbitMQ)
  - [Для чего нужен Replication factor?](#Для_чего_нужен_Replication_factor)
  - [Для чего нужен Controller в Kafka кластере?](#Для_чего_нужен_Controller_в_Kafka_кластере)
  - [Что такое Segment и что такое base_segment?](#Что_такое_Segment_и_что_такое_base_segment)
  - [Что такое ISR?](#Что_такое_ISR)
  - [Какие есть гарантии обработки сообщения?](#Какие_есть_гарантии_обработки_сообщения)
  - [Объясните когда в API-интерфейсе производителя возникает исключение QueueFullException?](#Объясните_когда_в_API_интерфейсе_производителя_возникает_исключение_QueueFullException)
  - [Каково оптимальное количество partition для любого Topic и каким параметром задается кол-во партиций?](#Каково_оптимальное_количество_partition_для_любого_Topic_и_каким_параметром_задается_колво_партиций)
  - [Что такое Лидер и Ведомый и в чем их отличие в реплике?](#Что_такое_Лидер_и_Ведомый_и_в_чем_их_отличие_в_реплике)
  - [В чем разница между партициями и репликами в кластере?](#В_чем_разница_между_партициями_и_репликами_в_кластере)
  - [Объясните балансировку нагрузки Kafka?](#Объясните_балансировку_нагрузки_Kafka)
  - [Как в Kafka обеспечивает высокую доступность и отказоустойчивость?](#Как_в_Kafka_обеспечивает_высокую_доступность_и_отказоустойчивость)
  - [Как происходит балансировка нагрузки между потребителями в группе?](#Как_происходит_балансировка_нагрузки_между_потребителями_в_группе)
  - [Что такое Retention Policy?](#Что_такое_Retention_Policy)
  - [Как настроить репликацию?](#Как_настроить_репликацию)
  - [Как управлять производительностью в Kafka?](#Как_управлять_производительностью_в_Kafka)
  - [Что обеспечивает балансировку нагрузки на сервера кафки?](#Что_обеспечивает_балансировку_нагрузки_на_сервера_кафки)
  - [Как можно оптимизировать производительность для обеспечения пропускной способности?](#Как_можно_оптимизировать_производительность_для_обеспечения_пропускной_способности)
  - [Какие типы сериализации данных бывают в кафке и как их обрабатывать?](#Какие_типы_сериализации_данных_бывают_в_кафке_и_как_их_обрабатывать)
  - [Как достигается согласованность данных между репликами?](#Как_достигается_согласованность_данных_между_репликами)
  - [Расскажите про Topik?](#Расскажите_про_Topik)
  - [Из чего состоит Сегмент?](#Из_чего_состоит_Сегмент)
  - [Параметры и их описание в kafka?](#Параметры_и_их_описание_в_kafka)
  - [Что такое Zero copy?](#Что_такое_Zero_copy)
  - [Метрики?](#Метрики)
  - [Что такое KSQL?](#Что_такое_KSQL)

## Что_такое_Kafka_В_чем_ее_преимущества_и_недостатки

Kafka - распределительная система для передачи больших объемов данных с минимальной задержкой.
Преимущества кафки:
1. Высокая производительность.
2. Масштабируемость.
3. Хранение данных.
Из минусов:
1. требование к ресурсам.
2. сложная настройка т.к. за частую параметры по дефолту работают не корректно.

## Какие_есть_основные_компоненты_в_Kafka

1. Producer - некое приложение которое пишет в kafka. 
2. Consumer - приложение которое читает из kafka. 
3. Broker - сервер который хранит и распределяет сообщение(может быть несколько). 
4. Topic - это то как наши данные логически разделены. 
5. Partition - Разделение topic для параллельной обработки данных.
6. Zookeeper - сервис необходимый для управления состоянием кластера и координации брокеров.

## Какие_параметры_отвечают_за_время_хранения_в_кафке_и_как_данные_удаляются

Данные удаляются либо по времени либо по размеру.
1. retention.bytes - по максимальному размеру.
2. retention.ms - по времени.
Следующие параметры отвечают за хранение в кафке.
1. log.retention.hours (сколько часов данные будут храниться в топике).
2. log.retention.minutes (аналогично предыдущему только в минутах).
3. log.retention.ms.
4. log.retention.bytes.
5. log.segment.bytes (Определяет размер сегмента лога в байтах. Сегменты - это части лога).
6. log.segment.ms

## Как_можно_найти_сообщение_в_kafka

У кафки нету встроенных механизмов поиска, однако это можно сделать по offset. Каждое сообщение имеет свой offset. 
Так же можно найти по ключу.

## Как_выбирается_партиция_в_которую_записываются_данные_в_kafka

1. Если задан ключ и мы знаем кол-во партиций то вычисляется hash от ключа при помощи murmur2 и вычисляется по формуле
murmur2(key) % partitions. Если ключ не задан и он равен null то берется способ round_robin(partition) в котором 
распределяется равномерно.

## Какие_типы_алгоритмов_сжатия_есть_у_кафки_и_каким_параметром_настраиваются

Для уменьшения передаваемых данных используются алгоритмы:
1. GZIP - Высокая степень сжатия, требует большие ресурсы. (подходит где важна экономия места а задержки
'не проблема).
2. Snappy - меньшее сжатие но работает быстрее. Подходит где важна низкая задержка и высокая производительность.
3. LZ4 - Компромис между степенью сжатия и скоростью работы.
Параметр сжатия compression.type

## Как_в_kafka_работает_подтверждение_что_данные_дошли_до_брокера_acks

Параметр acks определяет степень подтверждения данных и состоит из 3-х типов:
1. acks: 0 - продюсер отправил данные и не ждет подтверждения. Брокер их получил по сети и продюсер считает что они не должны 
потеряться. В этом случае если реплика умрет которая была лидером и т.к. данные не были реплецированы то данные могут потеряться.
2. acks: 1 - Данные так же пишутся в брокер лидера. Брокер подтвержает что их принял и то что они попали на диски и вернул 
результат. Особенность то что мы не знаем реплецировались ли эти данные.
3. acks: all - В данном случае мы ждем подтверждение репликации наших данных по всем репликам. Есть минус то что если одна из 
реплик не будет работать то мы будем сидеть и ждать ответа. Для этого есть параметр min.insync.replicas = 2. 
Означает кол-во реплик которых необходимо для потверждения.

## Расскажите_про_Consumer_Group

Kafka использует концепцию для возможности работы вместе несколькими consumer. Они параллельно обрабатывают данные из топиков. 
Каждый consumer в группе обрабатывает только часть данных из топика обеспечивая масштабируемость и балансировку нагрузки. 
Все сообщения из одного Topic делятся между всеми consumer в группе. Так же в нем хранятся Offsets. Если несколько consumer 
в группе то kafka гарантирует что каждая партиция будет обрабатываться только одним consumer. Если один из consumer выйдет из 
строя то его партиция будет распределена между другими consumer в этой группе.

## Что_вы_можете_рассказать_по_Offset

Offset - индификатор который присвается каждому сообщению в партиции топика. Он указывает на позицию смещения чтобы consumer 
знал с какого места необходимо читать данные. Они назначаются в порядке добавления. Когда Consumer отправляет данные то этим 
данным назначается offset который увеличивается на единицу, а consumer читает с offset который был последним подтвержденным в 
отправке. Offset уникальные в рамках одной партиции.

## Что_такое_Rack_в_контексте_Kafka

Rack в Kafka – это логическая группа брокеров, обычно соответствующая дата-центру или зоне доступности. Когда у брокеров указан 
broker.rack, Kafka распределяет реплики партиций так, чтобы они находились в разных rack'ах. Это повышает отказоустойчивость: при 
падении целого дата-центра данные останутся доступны в других зонах. Например, в AWS это позволяет размещать реплики в разных 
AZ (us-east-1a, us-east-1b).

## Для_чего_необходим_Connector_API

Connector API — это часть Kafka Connect, предназначенная для удобной интеграции Kafka с внешними системами. Он избавляет от 
необходимости писать кастомный код для передачи данных, предоставляя готовые коннекторы (например, для баз данных, S3 или Elasticsearch). 
Например, с его помощью можно настроить автоматическую загрузку данных из PostgreSQL в Kafka (Source Connector) и выгрузку из Kafka в 
S3 (Sink Connector). Это особенно полезно в ETL-пайплайнах, где важно стандартизированное и надёжное перемещение данных.

## Что_вы_можете_рассказать_про_Kafka_Streams

Kafka Streams — это библиотека для обработки потоковых данных в реальном времени, встроенная в Apache Kafka. Она позволяет разрабатывать 
stateful- и stateless-приложения, которые читают данные из Kafka-топиков, обрабатывают их и записывают результаты обратно в Kafka.
Назначение:
1. Обработка данных в реальном времени (аналогично Apache Flink, Spark Streaming, но без внешних кластеров).
2. Микросервисная архитектура: Каждое приложение работает автономно, масштабируется независимо.
3. Exactly-once processing (гарантированная однократная обработка).

Ключевые абстракции:
1. KStream – поток записей (ключ-значение), аналог бесконечной таблицы.
2. KTable – "снимок" данных на момент времени (апдейтится при новых сообщениях).
3. GlobalKTable – полная копия данных на всех нодах (для быстрых lookup-джойнов).

Структура ответа:
1. Определение: "Kafka Streams – это библиотека для потоковой обработки данных прямо в Kafka".
2. Основные абстракции: KStream, KTable, State Stores.
3. Примеры операций: фильтрация, агрегация, джойны.
4. Плюсы/минусы: простота vs. ограниченная функциональность.
5. Кейсы: "Использовали для real-time аналитики пользовательских событий".

Дополнительно (если спросят):
1. Чем отличается от Kafka Consumer API? (Consumer API – низкоуровневый, Kafka Streams – высокоуровневая обработка).
2. Как работает Interactive Queries? (REST-доступ к state stores).
3. Как обеспечивается fault tolerance? (репликация state-топиков).

https://habr.com/ru/articles/747658/

## Что_такое_Transactions_API

Позволяет обеспечить атомарность и согласованность данных. Гарантирует что группа сообщений будет либо полностью записана либо 
не записана вовсе. У него так же есть Атомарность, согласованность, изоляция.
Транзакции работают:
1. инициализация происходит при помощи initTransactions()
2. начала транзакции с помощью beginTransaction().
3. отправка сообщения
4. фиксация транзакции commitTransaction().
5. откат транзакции abortTransaction()

Структура ответа:
1. Определение: "Transactions API позволяет группировать операции в атомарные блоки".
2. Проблемы без транзакций: частичные записи, дубли.
3. Гарантии: атомарность, изоляция, идемпотентность.
4. Пример: "Использовали для платежной системы, чтобы избежать расхождений в данных".
5. Ограничения: производительность, только Producer.

## Для_чего_необходим_AdminClient

Клиент предоставляет операции для управления топиками, брокерами, конфигурацией и другими объектами в kafka. Может создавать, 
удалять, описывать топки, получать инфу о кластере

## Для_чего_нужен_координатор_группы

"Координатор группы в Kafka управляет consumer-группами: распределяет партиции, следит за активностью consumer'ов через heartbeats 
и хранит оффсеты в топике __consumer_offsets. Например, если consumer падает, координатор перераспределяет его партиции между оставшимися."
Тоесть все Consumer ходят к ней и берут данные из нее. там есть еще параметр group.id которым мы можем указать к какой группе ходить. 
координатор группы отвечает за управление группами consumer. Назначает партиции consumers внутри группы и управляет фиксацией смещения. 
Когда consumer присоединяется к группе или покидает ее, координатор группы запускает перебалансировку для переназначения партиций среди 
оставшихся consumer.

Чем отличается Group Coordinator от Transaction Coordinator?
Group Coordinator работает с consumer-группами, а Transaction Coordinator — с транзакциями producer'ов.

Как Kafka выбирает координатора для группы?
Через хеширование group.id и выбор брокера-лидера для __consumer_offsets.

Что такое Sticky Assignor?
Алгоритм ребалансировки, минимизирующий перераспределение партиций.

## Расскажите_про_Producer

Продюсер состоит из ключа и значения. Выбор в какую партицию положить у продюссера есть два способа:
1. Если задан ключ и мы знаем кол-во партиций то вычисляется hash от ключа при помощи murmur2 и вычисляется по формуле 
murmur2(key) % partitions.
2. Если ключь не задан и он равен null то берется способ round_robin(partition).
Этапы работы producer:
1. Когда мы передаем данные в метод producer.send() они попадают в metadata. В metadata определяется в какой топик и в какую 
для него партицию попадет сообщение.
2. Serializer. В нем происходит сериализация сообщения key.serializer, value.serializer.
3. Partitioner - определяет в какую партицию должны попасть данные
4. RecordAccumulator - штука в которой для каждой топик, партиции создается такая очередь. Очередь из сообщений которые готовятся 
к отправке. Тут данные объединяются в пачки и уже пачками отправляются. Так же тут происходит процесс сжатия.
5. Sender Thread - поток отправки. Правила по которым забираются данные из RecordAccumulator в отправку происходит:
1. drain batches - когда пачки заполнились или пролежали долго.
2. make requests - все пачки эти записываются в request.
3. poll connections -
4. fire callbacks - можно каждую пачку снабдить callback чтобы посмотреть ответ.

## Расскажите_как_сообщение_принимается_consumer_из_kafka

1. Consumer подключается к брокерам и присоединяется к consumer-group. Там он получает инфу о партиции топика с которого будет читать.
2. Consumer подписывается на топик с помощью метода subscribe().
3. Consumer вызывает метод poll() для получения новых сообщений.
4. Consumer обрабатывает сообщения.
5. После обработки consumer подтверждает ее с помощью commit(). Это обновляет offset.
6. После этого consumer завершает обработку и выходит из consumer group закрывая соединение с Kafka.

## Расскажите_про_Consumer

Consumer использует pull-модель для извлечения сообщений. Consumer запрашивает пачки сообщений у брокеров.
Consumer состоит из:
1. ConsumerMetadata - состояние кластера, информация кто лидер.
2. SubscriptionState - подписка какой Consumer должен читать из каких партиций.
3. ConsumerNetworkClient
4. Fetcher - отвечает за чтение данных с какой позиции и какое кол-во
5. ConsumerCoordinator.
Как Consumer работает:
1. Есть два принципа работы consumer:
1. assign - явно говорим которые TopicPartition будем читать (партиции а не топики). Это надо когда всю координацию чтения 
хотим отвечать сами а не доверять кафке.
2. subscribe - можно сказать что хотим читать из какогото множества топиков, который может автоматически подтягивать новые партиции.
Происходит чтение данных Consumer так:
1. consumer делает assign к subscriptions.
2. в subscriptions мы говорим что именно хотим получить.
3. metadata просим обновить там метаданные.
4. надо понять с какого этапа нам надо начинать читать данные для этого делаем seek метод.
Их есть 3 -
a) seekToBeginning - читать сначала наши топики,
b) seekToEnd - читать с конца нашги топики,
c) seek - явно задать внешний offset.
5. идем в fetcher - валидирует запрос (проверяет offset и т.д. что было в предыдущих пунктах). Ходит он за этими знаниями в 
Subscriptions и делает send в кафку. Запрос в кафку не уходит он только добавляется в очередь.
6. После этого в consumer в poll в цикле мы будем пытаться получить данные внутри fetcher которые лежат, дальше запрос улетает в 
network client где проверяется соединение с данными. После этого делается в запрос к кафке. Вконце уже идет опять консюмер к 
fetcher и запрашивает уже данные которые вернула кафка.

## Как_Kafka_обрабатывает_сообщения

Kafka поддерживает два основных способа обработки сообщения:
1. Queue - каждое сообщение обрабатывается одним consumer в группе. Это достигается за счет наличия в группе нескольких consumers 
каждый из которых считает данные из отдельных партиций.
2. Publish-Subscribe - все сообщения обрабатываются всеми consumers. Это достигается за счет того что каждый consumer находится в 
своей собственной группе.

## Что_такое_Лаг_Задержка_обработки

Задержка это разница между offset последнего созданного сообщения и offset последнего полученного сообщения которое смог прочитать 
consumer. Вкратце это разница между последним опубликованным и прочитанным сообщением.

## Для_чего_нужен_subscribe_и_poll_и_position_методы

subscribe() - используется ля подписки на топики.
poll() - извлекает данные из топиков.
position() - возвращает смещение следующей записи которая будет извлечена для данной партиции.

## Для_чего_необходимы_методы_commitSync_commitAsync

1. commitSync() - синхронно фиксирует последнее смещение возращенное poll(). Он будет повторять попытку до тех пор пока не 
завершиться успешно или не столкнется с непроверяемой ошибкой.
2. commitAsync() - асинхронно фиксирует смещения. Он не повторяет попытку при сбое, что делает более быстрым но менее надежным.

## Для_чего_нужен_идемпотентный_producer

Этот продюсер гарантирует exactly-once гарантию доставки (доставка будет точно один раз), предотвращая дублирование записей на 
случае повторных попыток отправки сообщений.

## Для_чего_нужен_Mirror_Maker

MirrorMaker — это инструмент от Apache Kafka, предназначенный для репликации данных между разными Kafka-кластерами.
Инструмент позволяющий реплицировать данные между кластерами, потенциально находящихся в разных дата-центрах. Он работает, 
потребляя данные из одного кластера и передавая в другой. Можно использовать для создания резервной копии данных, объединения 
данных из нескольких дата-центров в единое хранилище или для переноса данных между кластерами.
MirrorMaker состоит из:
1. Consumer – читает данные из исходного кластера (source).
2. Producer – записывает данные в целевой кластер (target).

Режимы работы:
1. Active-Active: Данные реплицируются в обе стороны (нужно два MirrorMaker).
2. Active-Passive: Односторонняя репликация (например, prod → backup).

Ограничения MirrorMaker:
❌ Нет поддержки транзакций (может терять сообщения при сбоях).
❌ Ручное управление оффсетами (в старых версиях).
❌ Задержки репликации (не подходит для real-time синхронизации).

Как избежать циклической репликации в Active-Active?
Использовать фильтрацию топиков или message.timestamp.type=LogAppendTime.

Как мониторить задержки репликации?
Через метрики Consumer Lag (например, в Prometheus).

## Для_чего_нужен_Streams_DSL

Streams DSL (Domain-Specific Language) — это высокоуровневый API в Kafka Streams, позволяющий декларативно описывать потоковую 
обработку данных с помощью готовых операторов (вроде filter, map, join, aggregate)

Основные цели:
1. Упрощение разработки потоковых приложений (меньше кода vs. Processor API).
2. Готовые паттерны для ETL, агрегаций, джойнов.
3. Интеграция с Kafka без низкоуровневого управления партициями/оффсетами.

Ключевые возможности:
1. Stateless-операции: filter, map, flatMap.
2. Stateful-операции: aggregate, count, reduce, windowed joins.
3. Табличные преобразования: KTable, GlobalKTable.

Основные абстракции:
"Работает с KStream (поток данных) и KTable (изменяемое состояние)."

Примеры:
"Использовали для real-time агрегации логов или джойнов платежей и заказов."

Плюсы/минусы:
"Упрощает разработку, но менее гибкий, чем Processor API."

Чем KTable отличается от GlobalKTable?
GlobalKTable реплицируется на все ноды и не требует репартиционирования для джойнов.

Как работает Exactly-once в Streams DSL?
Через транзакции и идемпотентные producer'ы (настройка processing.guarantee="exactly_once_v2").

Когда выбрать Processor API вместо DSL?
Если нужны нестандартные StateStores или сложная логика ветвления.

## Какая_есть_разница_между_Kafka_и_RabbitMQ

1. RabbitMQ - использует очереди сообщений. Kafka - использует топки и партиции.
2. RabbitMQ - не хранит сообщения. Kafka - сохраняет сообщение в топиках.
3. RabbitMQ - может повторно отправить сообщение в случае если consumer не подтвердил его получении. Kafka - сообщение хранит на 
диске и можно считать в любое время.
4. RabbitMQ - один consumer получает одно сообщение. Kafka - consumers читают сообщения независимо друг от друга.

## Для_чего_нужен_Replication_factor

Параметр который указывает на какое кол-во реплик будет разбит топик. При создании топика указывается кол-во реплик если допустим 
их == 3 то кафка создаст три копии данных каждой партиции топика.

## Для_чего_нужен_Controller_в_Kafka_кластере

Контроллер - брокер отвечает за конфигурацию кластера. Куда данные можно писать а куда нельзя, кто с кого должен реплицировать. 
назначение лидеров партиции, создание и удаление топиков.

## Что_такое_Segment_и_что_такое_base_segment

Segment - это разделение партиции топика, которая необходима для хранении и удалении данных. Каждый сегмент это отдельный файл 
на диске. размер сегмента регулируется параметром log.segment.bytes. Когда размер этого параметра заканчивается то создается 
новый сегмент. Время жизни сегмента задается параметром log.retention.hours. base_segment - это первый сегмент в партиции в 
который записываются новые данные.

## Что_такое_ISR

ISR - это синхронизированные реплики, тоесть они синхронизированны с лидером и считаются актуальными. В кафке есть лидер а есть 
фолловеры, и тоесть это те фолловеры которые успешно синхронизировались с лидером. Основые параметры. 
replica.lag.time.max.ms - максимальное время в течении которого реплика может остсвать от лидера. 
min.insync.replicas - минимальное колво реплик в ISR которые должны быть доступны для записи.

## Какие_есть_гарантии_обработки_сообщения

Есть две гарантии обработки. 
1. at least once.(commit до обработки) - минимум один раз. Сообщение будет точно доставлено но может быть более одного раза. 
Это достигается: Продюсер ждет подтверждение от брокера перед тем как считать сообщение отправленным, потребитель фиксирует 
оффсет только после успешной обработки сообщения.
2. At most once.(commit после обработки) - максимум один раз. Сообщение может быть потеряно но ни когда не будет доставлено более 
1 раза. Это достигается тем что продюсер отправляет сообщение и не ждет подтверждения. Потребитель читает сообщение и сразу 
фиксирует offset даже если обработка не завершена.
3. Exactly once (ровно один раз) - сообщение будет доставлено и обработано один раз. Достигается при помощи идемпотентного 
продюсера для предотвращения дублирования сообщений. Использует транзакции для атомарного чтения и записи.

## Объясните_когда_в_API_интерфейсе_производителя_возникает_исключение_QueueFullException

Ошибка может возникнуть когда Producer отправляет данные с такой скоростью которой Брокер не может обработать. В этом случае можем 
добавить больше брокеров

## Каково_оптимальное_количество_partition_для_любого_Topic_и_каким_параметром_задается_колво_партиций

Кол-во партиций регулируется параметром replication.factor. Если у нас он равен 3 то это означает что при трех брокерах у нас 
партиции равнормерно разъедутся. Оптимальное кол-во partition должно быть равно кол-во consumer.

## Что_такое_Лидер_и_Ведомый_и_в_чем_их_отличие_в_реплике

Broker 1 – leader для партиции 0, тоесть для каждой такой партиции в этом кластере выбирается лидер.

## В_чем_разница_между_партициями_и_репликами_в_кластере

Основное отличие в том что партиции используются для увеличения пропускной способности, а реплики напротив используются для 
обеспечения отказоустойчивости в кластере.

## Объясните_балансировку_нагрузки_Kafka

У нас есть лидеры и фолловеры которые обеспечиваются балансировку. В лидера данные пишутся а в фолловеры данные реплецируются. 
В случае если лидер становится не доступен то данные не теряются и лидером назначается одним из фолловеров

## Как_в_Kafka_обеспечивает_высокую_доступность_и_отказоустойчивость

Можно
1. Сделать репликацию данных.
2. Распределить партиции между брокерами.

## Как_происходит_балансировка_нагрузки_между_потребителями_в_группе

Это происходит автоматически на стороне кафки. Если добавляется дополнительный потребитель, то происходит ребаланс. В эттом случает
отправляется запрос координатору группы. Координатор группы выбирает лидера группы который распределяет партиции между 
потребителями. Лидер группы получает список всех партиций топика и распределяет. Распределение происходит по типу range or 
round-robin. Основной минус в том что происходят задержки во время ребаланса.

## Что_такое_Retention_Policy

Параметр определяет как долго хранятся сообщения в топиках. Сообщения могут удаляться по времени либо по размеру. Кафка хранит 
сообщения в логах которые представляют себя файлы на дисках. Когда сегмент достигает лимита по времени или размеру то кафка удаляет 
или архивирует его.

## Как_настроить_репликацию

Репликация настраивается через параметр replication.factor, который определяет кол-во копий для каждой партиции. Допустим если 
укажем replication.factor=4 чтобы данные хранились на четырех брокерах. Так же важен параметр min.insync.replicas - который 
гарантирует за успешную запись в случае если одна из реплик не отвечает

## Как_управлять_производительностью_в_Kafka

Необходимо настроить мониторинг для нахождения мест где мы можем тормозить. Так же грамотно настроить брокеры - это равномерное 
распредление партиций между брокерами, проверка параметров replication.factor, 'min.insync.replicas. котореы отвечают за настройку 
репликации. Так же на стороне продюсера можно проверить размер пачек отправляемых отвечает параметр batch.size., задержка отправки 
linger.ms, степень сжатия - compression.type. На консюмере проверить параметры как размер выборки - fetch.max.bytes, кол-во потоков 
num.consumer.threads.

## Что_обеспечивает_балансировку_нагрузки_на_сервера_кафки

Балансировка нагрузки обеспечивается за счет партиционирования, репликации и групп потребителей. Партиции распределяются между 
брокерами для параллельной обработки.

## Как_можно_оптимизировать_производительность_для_обеспечения_пропускной_способности

Для оптимизации производительности можно изменить настройки параметров брокера (увеличение колво партиций, потока ввода-вывода), 
оптимизация продюсеров через пакетную отправку и асинхронную обработку, мб увеличить колво консюмеров. может быть изменить тип 
сжатия данных, посмотреть на мониторинг какая из систем тормозит.

## Какие_типы_сериализации_данных_бывают_в_кафке_и_как_их_обрабатывать

Данные в кафке передаются в виде байтов. Используются примитивные типы как String, Integer. Так и JSON Avro, Protobuf.
Avro - бинарный формат сериализации, поддерживающий схемы данных. 
Protobuf - Тоже бинарный формат сериализации только требующий предварительного определения схемы в .proto файлах.

## Как_достигается_согласованность_данных_между_репликами

Согласованность достигается за счет репликации партиций, где одна является лидером а другие фолловерами, которые синхронизируются 
с лидером. В лидера все пишут. Уровень надежности получения данных регулируется через параметр acks

## Расскажите_про_Topik

Топик состоит из партиций где запись происходит в конец. У каждой записи есть свой Offset. Начинается он с 0. Каждая партиция
делится на сегменты. В данном случае 5 по 9 индекс это сегмент второй, а с 0 по 4 это первый сегмент. Base offset - это номер с 
которого начинается чтение в сегменте.

## Из_чего_состоит_Сегмент

Сегмент это часть данных которые хранятся в партиции.
Он состоит из:
1. файл данных (log_segment) в которых содержаться сами сообщения.
2. индексного файла (index.file) для быстро поиска по смещениям.
3. файла временных меток (timeIndex file) для поиска по времени.

## Параметры_и_их_описание_в_kafka

1. auto.create.topics.enable -
2. auto.offset.reset -
3. allow.auto.create.topics=true - настройка отвечает создавать ли автоматически топик в кафке если его там нету 
(если отключить то решает проблему чтобы не создавался автоматически топик с кривыми настройками)
4. batch.size - .
5. buffer.memory - .
6. compression.type - .
7. default.replication.factor - .
8. min.insync.replicas - .
9. max.request.size - .
10. max.partition.fetch.bytes - .
11. max.block.ms - .
12. max.block.ms - время блокировки метода produce.send().
13. max.partition.fetch.bytes - 
14. max.in.flight.requests.per.connection - .
15. max.poll.records - .
16. message.max.bytes - .
17. request.timeout.ms - .
18. replica.fetch.response.max.bytes - .
19. replica.fetch.min.bytes - .
20. replica.fetch.max.bytes - сколько байтов максимум должен забрать фолловер с лидера из одной партиции.
21. unclean.leader.election.enable - .
22. linger.ms - .
23. fetch.max.bytes - какое максимально значение должен вернуть брокер
24. fetch.min.bytes - какое минимальное значение должен вернуть брокер

## Что_такое_Zero_copy

Необходима для повышения производительности за счет уменьшения копирования данных между буферами памяти. В данном случае кафка 
использует механизмы операционной системы такие как sendfile или mmap для передачи данных напрямую из файловой системы в сетевой 
интерфейс. Тоесть когда потребитель запрашивает данные у брокера то брокер использует sendfile для отправки данных напрямую из 
лог-файлов на диск в сетевой сокет.

## Метрики

1. Compression: 
1.1. compression-rate-avg - показывает сжатие наших данных, чем ниже тем лучше
2. Buffer pool:
2.1. buffer-available-bytes - сколько еще можно попросить место у буфера под новые пачки
2.2. bufferpool-wait-ratio - сколько в среднем воркер тредов находится в режиме ожидания свободного места.
3. RecordAccumulator:
3.1. record-queue-time-avg - среднее время ожидания пачки в блоке recordAccumulator. Как только пачка была создан до того как блок 
Sender эту пачку забрал.
3.2. batch-size-avg - средний размер пачки от recordAccumulator к блоку отдачи request в Sender.
4. Make request (этап формирования request):
4.1. request-size-avg - средний размер request(точнее каждый отдельный запрос к брокеру)
4.2. records-per-request-avg - это если интересно посмотреть в штуках сообщения
5. Этап запроса к брокерам:
5.1. request-rate - как часто формируются запросы к брокеру.
5.2. record-send-rate - сколько в штуках сообщений мы отправляем в секунду
5.3. outgoing-byte-rate - та же самая метрика что выше только не вштуках а в байтах можем узнать
6. Poll connections (время ответа от брокера):
6.1. request-latency-avg - среднее значение ответа от брокера.
7. В блоке Sender Thread разделен на этапы Drain batches -> make requests -> poll connections -> fire callbacks и эти итерации 
делаются циклом и следующая метрика показывается как часто выполняются эти операции
7.1. select-rate - с какой частотой выполняются итерация оппераций внутри sender thread
8. Метрика производительности:
8.1. Throughput (в байтах) = outgoing-byte-rate / compression-rate-avg так же ее можно посчитать 
request-rate * request-size-avg / compression-rate-avg
8.2. Throughput (в штуках) = record-sender-rate.
9. Латентность: Total Latency = Worker Latency + Sender Latency + CallBack Latency.
9.1. Worker Latency - время выполнения producer.send()
9.2. Sender Latency - время до получения ответа от брокера. (время от поступления данных в producer.send() до момента ответа от 
брокера. Sender Latency = (record-queue-time-avg /2) + request-latency-avg; первая часть это время которое данные пролежали в 
RecordAccumulator, а вторая часть это сколько выполнялся запрос к брокеру.
9.3. Callback Latency - когда ответ брокера получили и получили ответ что данные в брокер записали.

## Что_такое_KSQL

это потоковый SQL движок обработки данных в реальном времени для Apache Kafka
